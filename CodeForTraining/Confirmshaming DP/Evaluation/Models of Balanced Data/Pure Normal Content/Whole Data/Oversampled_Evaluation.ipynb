{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirmshaming Classifier Evaluation\n",
    "\n",
    "This script is used for the model evaluation for Confirmshaming Classifier.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Testing Dataset \"old_normal.csv\"\n",
    "\n",
    "---\n",
    "Import the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zip-through cadet collar with chin guard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zip Up Belted PU Moto Jacket</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Youth Core Performance Soft Shell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your Watchlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your Video Purchases &amp; Rentals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    content  Classification\n",
       "0  Zip-through cadet collar with chin guard               1\n",
       "1              Zip Up Belted PU Moto Jacket               1\n",
       "2         Youth Core Performance Soft Shell               1\n",
       "3                            Your Watchlist               1\n",
       "4            Your Video Purchases & Rentals               1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('old_normal.csv')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`check the dataset information`\n",
    "\n",
    "There are 3024 NOT NULL instances of content strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3024 entries, 0 to 3023\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         3024 non-null   object\n",
      " 1   Classification  3024 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "1    3024\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['Classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bernoulli Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Duplicate Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'alpha': 0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0   32]\n",
      " [   1 2992]]\n",
      "\n",
      "Accuracy: 0.9894179894179894\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  32 2992]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### SMOTE Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'alpha': 0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0    6]\n",
      " [   1 3018]]\n",
      "\n",
      "Accuracy: 0.998015873015873\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [   6 3018]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Duplicate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 100, 'estimator__multi_class': 'auto', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(), 'n_jobs': -1, 'param_grid': {'penalty': ['l1', 'l2'], 'solver': ['lbfgs', 'newton-cg', 'sag']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0    6]\n",
      " [   1 3018]]\n",
      "\n",
      "Accuracy: 0.998015873015873\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [   6 3018]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/lr_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### SMOTE Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 100, 'estimator__multi_class': 'auto', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(), 'n_jobs': -1, 'param_grid': {'penalty': ['l1', 'l2'], 'solver': ['lbfgs', 'newton-cg', 'sag']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0    3]\n",
      " [   1 3021]]\n",
      "\n",
      "Accuracy: 0.9990079365079365\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [   3 3021]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/lr_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Support Vector Machine Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### Duplicate Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'C': 0.1, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0    8]\n",
      " [   1 3016]]\n",
      "\n",
      "Accuracy: 0.9973544973544973\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [   8 3016]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/svm_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### SMOTE Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'C': 0.1, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0    5]\n",
      " [   1 3019]]\n",
      "\n",
      "Accuracy: 0.9983465608465608\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [   5 3019]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/svm_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Duplicate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0    3]\n",
      " [   1 3021]]\n",
      "\n",
      "Accuracy: 0.9990079365079365\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [   3 3021]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### SMOTE Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 50, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0    2]\n",
      " [   1 3022]]\n",
      "\n",
      "Accuracy: 0.9993386243386243\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [   2 3022]]\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
