{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Formation\n",
    "\n",
    "Given a Pattern String as an input, we want to know if it contains dark pattern in it. We use a balanced dataset cotaining all the instances in the Princeton dataset which are all dark patterns, and the instances in the 'normie.csv' file which are labeled as NOT dark patterns. Hence we have a balanced dataset consisting of pattern strings with dark pattern and without park patterns.\n",
    "\n",
    "Then we use this labeled dataset to build and train supervised machine learning models, and select most suitable ones for our project.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "---\n",
    "Import the merged dataset, and explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('enriched_confirm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ends in 07:42:09</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ends in 07:37:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ends in 02:27:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ends in 04:17:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ends in 01:57:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pattern String classification\n",
       "0  Ends in 07:42:09       Not_Dark\n",
       "1  Ends in 07:37:10       Not_Dark\n",
       "2  Ends in 02:27:10       Not_Dark\n",
       "3  Ends in 04:17:10       Not_Dark\n",
       "4  Ends in 01:57:10       Not_Dark"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`check the dataset information`\n",
    "\n",
    "There are 7952 NOT NULL instances of pattern strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8187 entries, 0 to 8186\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Pattern String  8187 non-null   object\n",
      " 1   classification  8187 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 128.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "Not_Dark    7994\n",
      "Dark         193\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the content into lowercase\n",
    "\n",
    "data['Pattern String'] = data['Pattern String'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the tags:\n",
      "Not_Dark    7755\n",
      "Dark         180\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For later training the model, we should remove the duplicate input to reduce overfitting.\n",
    "\n",
    "data = data.drop_duplicates(subset=\"Pattern String\")\n",
    "\n",
    "print('\\nDistribution of the tags:\\n{}'.format(data['classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='classification'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution graph\n",
    "\n",
    "target = data.groupby('classification')['classification'].count()\n",
    "target.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test dataset as a ratio of 80%/20% (train/test).\n",
    "\n",
    "string_train, string_test, dark_train, dark_test = train_test_split(\n",
    "    data['Pattern String'], data[\"classification\"], train_size = .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the target vales into integers` --- 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(dark_train)\n",
    "y_train = encoder.transform(dark_train)\n",
    "y_test = encoder.transform(dark_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dark': 0, 'Not_Dark': 1}\n"
     ]
    }
   ],
   "source": [
    "# check the mapping of encoding results (from 0 to 1 representing 'Dark', 'Not Dark')\n",
    "\n",
    "integer_mapping = {label: encoding for encoding, label in enumerate(encoder.classes_)}\n",
    "print(integer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Dark' 149]\n",
      " ['Not_Dark' 6199]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the training pattern classification with pattern classification names.\n",
    "\n",
    "(unique, counts) = np.unique(dark_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  149]\n",
      " [   1 6199]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded training pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   31]\n",
      " [   1 1556]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded testing pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the textual features into series of vector of numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6348, 5662), (1587, 5662))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the word count vector of the pattern string to encode the pattern string.\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "tv.fit(string_train)\n",
    "\n",
    "x_train = tv.transform(string_train)\n",
    "x_test = tv.transform(string_test)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presence_TfidfVectorizer.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the CountVectorizer to disk\n",
    "\n",
    "joblib.dump(tv, 'presence_TfidfVectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## SMOTE Applyed\n",
    "\n",
    "SMOTE (Synthetic Minority Oversampling Technique) generates new samples in the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "smote = SMOTE(sampling_strategy = 'minority', random_state = 22)\n",
    "\n",
    "x_train_sm, y_train_sm = smote.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (12398, 5662), numpy.ndarray, (12398,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train_sm), x_train_sm.shape, type(y_train_sm), y_train_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 6199]\n",
      " [   1 6199]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded training pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_train_sm, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Rough Idea about the effect of different classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four models are tested:\n",
    "# -- Logistic Regression\n",
    "# -- Linear Support Vector Machine\n",
    "# -- Random Forest\n",
    "# -- Bernoulli Naive Bayes\n",
    "\n",
    "classifiers = [LogisticRegression(), LinearSVC(), RandomForestClassifier(), BernoulliNB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### `Using Not Oversampled Training Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "pre = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    pre.append(metrics.precision_score(y_test, y_pred, pos_label=0))\n",
    "    cm.append(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.987\n",
      "LogisticRegression() precision: 0.917\n",
      "Confusion Matrix: [[  11   20]\n",
      " [   1 1555]]\n",
      "LinearSVC() accuracy: 0.994\n",
      "LinearSVC() precision: 0.957\n",
      "Confusion Matrix: [[  22    9]\n",
      " [   1 1555]]\n",
      "RandomForestClassifier() accuracy: 0.994\n",
      "RandomForestClassifier() precision: 1.000\n",
      "Confusion Matrix: [[  21   10]\n",
      " [   0 1556]]\n",
      "BernoulliNB() accuracy: 0.980\n",
      "BernoulliNB() precision: 0.000\n",
      "Confusion Matrix: [[   0   31]\n",
      " [   0 1556]]\n"
     ]
    }
   ],
   "source": [
    "# List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(\"{} accuracy: {:.3f}\".format(classifiers[i],acc[i]))\n",
    "    print(\"{} precision: {:.3f}\".format(classifiers[i],pre[i]))\n",
    "    print(\"Confusion Matrix: {}\".format(cm[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### `Using Oversampled Training Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "pre = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(x_train_sm, y_train_sm)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    pre.append(metrics.precision_score(y_test, y_pred, pos_label=0))\n",
    "    cm.append(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.993\n",
      "LogisticRegression() precision: 0.885\n",
      "Confusion Matrix: [[  23    8]\n",
      " [   3 1553]]\n",
      "LinearSVC() accuracy: 0.992\n",
      "LinearSVC() precision: 0.880\n",
      "Confusion Matrix: [[  22    9]\n",
      " [   3 1553]]\n",
      "RandomForestClassifier() accuracy: 0.994\n",
      "RandomForestClassifier() precision: 1.000\n",
      "Confusion Matrix: [[  21   10]\n",
      " [   0 1556]]\n",
      "BernoulliNB() accuracy: 0.994\n",
      "BernoulliNB() precision: 0.862\n",
      "Confusion Matrix: [[  25    6]\n",
      " [   4 1552]]\n"
     ]
    }
   ],
   "source": [
    "# List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(\"{} accuracy: {:.3f}\".format(classifiers[i],acc[i]))\n",
    "    print(\"{} precision: {:.3f}\".format(classifiers[i],pre[i]))\n",
    "    print(\"Confusion Matrix: {}\".format(cm[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bernoulli Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bnb = BernoulliNB().fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = clf_bnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bnb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Bernoulli Naive Bayes classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9936988027725268\n",
      "Precision: 0.8620689655172413\n",
      "Confusion Matrix:\n",
      " [[  25    6]\n",
      " [   4 1552]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   29],\n",
       "       [   1, 1558]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of BernoulliNB classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0,1], \n",
    "              'fit_prior':[True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_bnb,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:555: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_bnb = gs.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_fit_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_alpha param_fit_prior\n",
       "0                1         0.999274           0            True\n",
       "1                1         0.999274           0           False\n",
       "2                3         0.998952           1            True\n",
       "3                3         0.998952           1           False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_bnb.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_alpha', 'param_fit_prior']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0, 'fit_prior': True}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   21]\n",
      " [   1 1566]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_bnb.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9924385633270322\n",
      "Precision: 0.9523809523809523\n",
      "Confusion Matrix:\n",
      " [[  20   11]\n",
      " [   1 1555]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best BernoulliNB model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bnb_presence_classifier.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_bnb, 'bnb_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SVM Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = LinearSVC().fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_pred = clf_svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': True,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Random Forest classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9924385633270322\n",
      "Precision: 0.88\n",
      "Confusion Matrix:\n",
      " [[  22    9]\n",
      " [   3 1553]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   25],\n",
       "       [   1, 1562]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of SVM classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.1,1,10,100],\n",
    "              'penalty':['l1','l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_svm,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.99943539        nan 0.99959671        nan 0.99975806\n",
      "        nan 0.9995161 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_svm = gs.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_C\n",
       "0                1         0.999758            l2      10\n",
       "1                2         0.999597            l2       1\n",
       "2                3         0.999516            l2     100\n",
       "3                4         0.999435            l2     0.1\n",
       "4                5              NaN            l1     0.1\n",
       "5                6              NaN            l1       1\n",
       "6                7              NaN            l1      10\n",
       "7                8              NaN            l1     100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_svm.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   26]\n",
      " [   1 1561]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_svm.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9955891619407687\n",
      "Precision: 0.9615384615384616\n",
      "Confusion Matrix:\n",
      " [[  25    6]\n",
      " [   1 1555]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best SVM model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_presence_classifier.joblib']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_svm, 'svm_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression().fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = clf_lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Logistic Regression classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9930686830497795\n",
      "Precision: 0.8846153846153846\n",
      "Confusion Matrix:\n",
      " [[  23    8]\n",
      " [   3 1553]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   26],\n",
       "       [   1, 1561]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of Logistic Regression classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty':['l1','l2'], \n",
    "              'solver':['lbfgs','newton-cg','sag']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_lr,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.99911284 0.99911284 0.99911284]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_lr = gs.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_solver\n",
       "0                1         0.999113            l2        lbfgs\n",
       "1                1         0.999113            l2    newton-cg\n",
       "2                1         0.999113            l2          sag\n",
       "3                4              NaN            l1        lbfgs\n",
       "4                5              NaN            l1    newton-cg\n",
       "5                6              NaN            l1          sag"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_lr.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_solver']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   26]\n",
      " [   1 1561]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_lr.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9930686830497795\n",
      "Precision: 0.8846153846153846\n",
      "Confusion Matrix:\n",
      " [[  23    8]\n",
      " [   3 1553]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best Logistic Regression model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_presence_classifier.joblib']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_lr, 'lr_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier().fit(x_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = clf_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Random Forest classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9936988027725268\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      " [[  21   10]\n",
      " [   0 1556]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   21],\n",
       "       [   1, 1566]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of Random Forest classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'bootstrap':[True,False], \n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[10,20,30,40,50, None],\n",
    "              'min_samples_leaf':[1,2,4],\n",
    "              'min_samples_split':[2,5,10],\n",
    "              'n_estimators':[100,200,300]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_rf,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    }
   ],
   "source": [
    "best_rf = gs.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>644</td>\n",
       "      <td>0.987821</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>645</td>\n",
       "      <td>0.987257</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>0.987176</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>647</td>\n",
       "      <td>0.987095</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>648</td>\n",
       "      <td>0.987014</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank_test_score  mean_test_score param_bootstrap param_criterion  \\\n",
       "0                  1         0.999516            True         entropy   \n",
       "1                  1         0.999516           False            gini   \n",
       "2                  3         0.999435            True         entropy   \n",
       "3                  3         0.999435            True         entropy   \n",
       "4                  3         0.999435            True         entropy   \n",
       "..               ...              ...             ...             ...   \n",
       "643              644         0.987821           False            gini   \n",
       "644              645         0.987257           False         entropy   \n",
       "645              646         0.987176            True         entropy   \n",
       "646              647         0.987095           False         entropy   \n",
       "647              648         0.987014            True         entropy   \n",
       "\n",
       "    param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0                50                      1                      10   \n",
       "1                50                      1                      10   \n",
       "2                50                      1                      10   \n",
       "3                50                      1                       5   \n",
       "4                50                      1                       5   \n",
       "..              ...                    ...                     ...   \n",
       "643              10                      4                       5   \n",
       "644              10                      2                       2   \n",
       "645              10                      1                       5   \n",
       "646              10                      1                       5   \n",
       "647              10                      2                       2   \n",
       "\n",
       "    param_n_estimators  \n",
       "0                  200  \n",
       "1                  100  \n",
       "2                  300  \n",
       "3                  200  \n",
       "4                  100  \n",
       "..                 ...  \n",
       "643                100  \n",
       "644                100  \n",
       "645                100  \n",
       "646                100  \n",
       "647                100  \n",
       "\n",
       "[648 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_rf.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_bootstrap', 'param_criterion','param_max_depth','param_min_samples_leaf','param_min_samples_split','param_n_estimators']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 50,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   21]\n",
      " [   1 1566]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_rf.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9936988027725268\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      " [[  21   10]\n",
      " [   0 1556]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best Random Forest model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_presence_classifier.joblib']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_rf, 'rf_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Check original training data and the oversampled training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5471)\t0.4537252518909053\n",
      "  (0, 5126)\t0.32013550208900166\n",
      "  (0, 4166)\t0.43885450231021905\n",
      "  (0, 3383)\t0.3432401833548341\n",
      "  (0, 2929)\t0.3841408222680057\n",
      "  (0, 2313)\t0.27707371574237194\n",
      "  (0, 282)\t0.3961130433895392\n",
      "  (1, 4700)\t0.7881018818130937\n",
      "  (1, 3151)\t0.6155448187440623\n",
      "  (2, 4076)\t0.4332501333912707\n",
      "  (2, 1430)\t0.5442331791450861\n",
      "  (2, 461)\t0.7184041819436178\n",
      "  (3, 5246)\t0.4309653313325684\n",
      "  (3, 4741)\t0.3846520234159301\n",
      "  (3, 3772)\t0.3379726160754003\n",
      "  (3, 2845)\t0.41316556118070874\n",
      "  (3, 2161)\t0.38925502581091154\n",
      "  (3, 1909)\t0.4794381699341085\n",
      "  (4, 5086)\t0.35967953084051385\n",
      "  (4, 3606)\t0.3429407018732715\n",
      "  (4, 3090)\t0.42953951727496975\n",
      "  (4, 2421)\t0.5152525476868184\n",
      "  (4, 2339)\t0.39161735058350644\n",
      "  (4, 1872)\t0.386870489978752\n",
      "  (5, 3741)\t0.5386101018259077\n",
      "  :\t:\n",
      "  (6340, 2219)\t0.5543835301431879\n",
      "  (6341, 5584)\t0.3569734851489754\n",
      "  (6341, 5491)\t0.3569734851489754\n",
      "  (6341, 5088)\t0.43258108796700573\n",
      "  (6341, 3081)\t0.30898989650607306\n",
      "  (6341, 1319)\t0.4142327689310242\n",
      "  (6341, 1172)\t0.4142327689310242\n",
      "  (6341, 1143)\t0.34548680767738404\n",
      "  (6342, 3690)\t0.5366870598672603\n",
      "  (6342, 3046)\t0.5317544418641729\n",
      "  (6342, 2684)\t0.6551367897842082\n",
      "  (6343, 4015)\t0.6220450839255477\n",
      "  (6343, 2084)\t0.5081378612188878\n",
      "  (6343, 562)\t0.5956977652803076\n",
      "  (6344, 5481)\t0.8216579048481341\n",
      "  (6344, 52)\t0.5699809535419361\n",
      "  (6345, 373)\t0.8067719397722528\n",
      "  (6345, 52)\t0.5908629597428803\n",
      "  (6346, 5531)\t0.39150129327259714\n",
      "  (6346, 4972)\t0.4677372167574052\n",
      "  (6346, 4310)\t0.5427632316967526\n",
      "  (6346, 1458)\t0.3939460586813393\n",
      "  (6346, 1168)\t0.4220938409802446\n",
      "  (6347, 5333)\t0.7985845413959362\n",
      "  (6347, 5330)\t0.6018826548783761\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5471)\t0.4537252518909053\n",
      "  (0, 5126)\t0.32013550208900166\n",
      "  (0, 4166)\t0.43885450231021905\n",
      "  (0, 3383)\t0.3432401833548341\n",
      "  (0, 2929)\t0.3841408222680057\n",
      "  (0, 2313)\t0.27707371574237194\n",
      "  (0, 282)\t0.3961130433895392\n",
      "  (1, 4700)\t0.7881018818130937\n",
      "  (1, 3151)\t0.6155448187440623\n",
      "  (2, 4076)\t0.4332501333912707\n",
      "  (2, 1430)\t0.5442331791450861\n",
      "  (2, 461)\t0.7184041819436178\n",
      "  (3, 5246)\t0.4309653313325684\n",
      "  (3, 4741)\t0.3846520234159301\n",
      "  (3, 3772)\t0.3379726160754003\n",
      "  (3, 2845)\t0.41316556118070874\n",
      "  (3, 2161)\t0.38925502581091154\n",
      "  (3, 1909)\t0.4794381699341085\n",
      "  (4, 5086)\t0.35967953084051385\n",
      "  (4, 3606)\t0.3429407018732715\n",
      "  (4, 3090)\t0.42953951727496975\n",
      "  (4, 2421)\t0.5152525476868184\n",
      "  (4, 2339)\t0.39161735058350644\n",
      "  (4, 1872)\t0.386870489978752\n",
      "  (5, 3741)\t0.5386101018259077\n",
      "  :\t:\n",
      "  (12394, 1872)\t0.3581354414670067\n",
      "  (12394, 3606)\t0.3174685659511916\n",
      "  (12394, 4463)\t0.36723591483812973\n",
      "  (12394, 5086)\t0.3329641078886325\n",
      "  (12394, 5145)\t0.275773306445836\n",
      "  (12394, 5460)\t0.3863177052113926\n",
      "  (12395, 2368)\t0.47586037858474284\n",
      "  (12395, 3090)\t0.4881413974018267\n",
      "  (12395, 3606)\t0.3897279451734789\n",
      "  (12395, 3848)\t0.018641125444600948\n",
      "  (12395, 4054)\t0.4532537265879319\n",
      "  (12395, 5086)\t0.40875044493037377\n",
      "  (12396, 1716)\t0.11284705774031009\n",
      "  (12396, 1872)\t0.09686317682613249\n",
      "  (12396, 5086)\t0.09005520684314425\n",
      "  (12396, 5460)\t0.10448549866406942\n",
      "  (12396, 1470)\t0.5031592569940329\n",
      "  (12396, 1782)\t0.5267243657577884\n",
      "  (12396, 3606)\t0.36403425252559435\n",
      "  (12397, 1830)\t0.18127595934932975\n",
      "  (12397, 1716)\t0.347491823930979\n",
      "  (12397, 1872)\t0.43438102492256647\n",
      "  (12397, 3606)\t0.3850563364901719\n",
      "  (12397, 5086)\t0.4038508164806039\n",
      "  (12397, 5460)\t0.46856317835529837\n"
     ]
    }
   ],
   "source": [
    "print(x_train_sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
