{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Models Evaluation\n",
    "\n",
    "This script is used for the model evaluation for Random Forest.\n",
    "\n",
    "The dataset is made up of web scraping data from 20 website pages containing dark patterns.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "---\n",
    "Import the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your price for this item is $ 89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your price for this item is $ 79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your price for this item is $ 55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your price for this item is $ 49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your price for this item is $ 21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            content  Classification\n",
       "0  Your price for this item is $ 89               1\n",
       "1  Your price for this item is $ 79               1\n",
       "2  Your price for this item is $ 55               1\n",
       "3  Your price for this item is $ 49               1\n",
       "4  Your price for this item is $ 21               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`check the dataset information`\n",
    "\n",
    "There are 3694 NOT NULL instances of content strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3694 entries, 0 to 3693\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         3694 non-null   object\n",
      " 1   Classification  3694 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 57.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "1    3344\n",
      "0     350\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['Classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3694 entries, 0 to 3693\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         3694 non-null   object\n",
      " 1   Classification  3694 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 86.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# For later training the model, we should remove the duplicate input to reduce overfitting.\n",
    "\n",
    "data = data.drop_duplicates(subset=\"content\")\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            content  Classification\n",
      "0  Your price for this item is $ 89               1\n",
      "1  Your price for this item is $ 79               1\n",
      "2  Your price for this item is $ 55               1\n",
      "3  Your price for this item is $ 49               1\n",
      "4  Your price for this item is $ 21               1\n",
      "\n",
      "Distribution of the tags:\n",
      "1    3344\n",
      "0     350\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))\n",
    "\n",
    "print('\\nDistribution of the tags:\\n{}'.format(data['Classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the target vales into integers` --- 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Classification']\n",
    "X = data['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "# check the mapping of encoding results (from 0 to 1 representing 'Dark', 'Not Dark')\n",
    "\n",
    "integer_mapping = {label: encoding for encoding, label in enumerate(encoder.classes_)}\n",
    "print(integer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  350]\n",
      " [   1 3344]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the pattern classification with pattern classification names.\n",
    "\n",
    "(unique, counts) = np.unique(Y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  350]\n",
      " [   1 3344]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 4\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  390]\n",
      " [   1 3304]]\n",
      "\n",
      "Accuracy: 0.9870059556036817\n",
      "Precision: 0.8871794871794871\n",
      "Confusion Matrix:\n",
      " [[ 346    4]\n",
      " [  44 3300]]\n",
      "\n",
      "Precison: 0.887\n",
      "Recall: 0.989\n",
      "F1 Score: 0.935\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V4/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V4/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V4.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V4.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 5\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  385]\n",
      " [   1 3309]]\n",
      "\n",
      "Accuracy: 0.986735246345425\n",
      "Precision: 0.8909090909090909\n",
      "Confusion Matrix:\n",
      " [[ 343    7]\n",
      " [  42 3302]]\n",
      "\n",
      "Precison: 0.891\n",
      "Recall: 0.980\n",
      "F1 Score: 0.933\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V5/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V5/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V5.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V5.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 6\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  372]\n",
      " [   1 3322]]\n",
      "\n",
      "Accuracy: 0.9902544667027612\n",
      "Precision: 0.9220430107526881\n",
      "Confusion Matrix:\n",
      " [[ 343    7]\n",
      " [  29 3315]]\n",
      "\n",
      "Precison: 0.922\n",
      "Recall: 0.980\n",
      "F1 Score: 0.950\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V6/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V6/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V6.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V6.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 7\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  331]\n",
      " [   1 3363]]\n",
      "\n",
      "Accuracy: 0.976448294531673\n",
      "Precision: 0.8972809667673716\n",
      "Confusion Matrix:\n",
      " [[ 297   53]\n",
      " [  34 3310]]\n",
      "\n",
      "Precison: 0.897\n",
      "Recall: 0.849\n",
      "F1 Score: 0.872\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V7/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V7/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V7.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V7.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 8\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  394]\n",
      " [   1 3300]]\n",
      "\n",
      "Accuracy: 0.9821331889550623\n",
      "Precision: 0.8604060913705583\n",
      "Confusion Matrix:\n",
      " [[ 339   11]\n",
      " [  55 3289]]\n",
      "\n",
      "Precison: 0.860\n",
      "Recall: 0.969\n",
      "F1 Score: 0.911\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V8/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V8/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V8.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V8.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- CV -- CountVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  369]\n",
      " [   1 3325]]\n",
      "\n",
      "Accuracy: 0.9899837574445046\n",
      "Precision: 0.924119241192412\n",
      "Confusion Matrix:\n",
      " [[ 341    9]\n",
      " [  28 3316]]\n",
      "\n",
      "Precison: 0.924\n",
      "Recall: 0.974\n",
      "F1 Score: 0.949\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/CV/CountVectorizer/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/CV/CountVectorizer/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-CV-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-CV-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- CV -- TfidfVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  344]\n",
      " [   1 3350]]\n",
      "\n",
      "Accuracy: 0.9924201407688142\n",
      "Precision: 0.9680232558139535\n",
      "Confusion Matrix:\n",
      " [[ 333   17]\n",
      " [  11 3333]]\n",
      "\n",
      "Precison: 0.968\n",
      "Recall: 0.951\n",
      "F1 Score: 0.960\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/CV/TfidfVectorizer/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/CV/TfidfVectorizer/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-CV-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-CV-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- HO -- CountVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [5, 10, 15, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  309]\n",
      " [   1 3385]]\n",
      "\n",
      "Accuracy: 0.9840281537628587\n",
      "Precision: 0.970873786407767\n",
      "Confusion Matrix:\n",
      " [[ 300   50]\n",
      " [   9 3335]]\n",
      "\n",
      "Precison: 0.971\n",
      "Recall: 0.857\n",
      "F1 Score: 0.910\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/HO/CountVectorizer/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/HO/CountVectorizer/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-HO-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-HO-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- HO -- TfidfVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [5, 10, 15, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  316]\n",
      " [   1 3378]]\n",
      "\n",
      "Accuracy: 0.9842988630211154\n",
      "Precision: 0.9620253164556962\n",
      "Confusion Matrix:\n",
      " [[ 304   46]\n",
      " [  12 3332]]\n",
      "\n",
      "Precison: 0.962\n",
      "Recall: 0.869\n",
      "F1 Score: 0.913\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/HO/TfidfVectorizer/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/HO/TfidfVectorizer/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-HO-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-HO-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 10 -- CV\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  321]\n",
      " [   1 3373]]\n",
      "\n",
      "Accuracy: 0.9899837574445046\n",
      "Precision: 0.9875389408099688\n",
      "Confusion Matrix:\n",
      " [[ 317   33]\n",
      " [   4 3340]]\n",
      "\n",
      "Precison: 0.988\n",
      "Recall: 0.906\n",
      "F1 Score: 0.945\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V10/CV/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V10/CV/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-CV.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-CV.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 10 -- HO\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300, 400, 500, 600]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  306]\n",
      " [   1 3388]]\n",
      "\n",
      "Accuracy: 0.9859231185706551\n",
      "Precision: 0.9869281045751634\n",
      "Confusion Matrix:\n",
      " [[ 302   48]\n",
      " [   4 3340]]\n",
      "\n",
      "Precison: 0.987\n",
      "Recall: 0.863\n",
      "F1 Score: 0.921\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V10/HO/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V10/HO/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "# pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.4\n",
    "pred_vec = (clf.predict_proba(cv.transform(data['content']))[ : , 1] >= 0.4).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-HO.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-HO.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
