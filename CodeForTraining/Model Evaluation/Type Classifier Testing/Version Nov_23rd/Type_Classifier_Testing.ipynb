{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type Classifier Evaluation\n",
    "\n",
    "This script is used for the model evaluation for Type Classifier.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# Using Single Line Input for Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"CV/type_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "lr_clf = joblib.load(\"CV/lr_type_classifier.joblib\")\n",
    "rf_clf = joblib.load(\"CV/rf_type_classifier.joblib\")\n",
    "svm_clf = joblib.load(\"CV/svm_type_classifier.joblib\")\n",
    "mnb_clf = joblib.load(\"CV/mnb_type_classifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Predict a signle Line\n",
    "\n",
    "text1 = '30 items has been sold'\n",
    "text2 = '30 items has been sold in the last 3 hours'\n",
    "text3 = 'Item is selling fast, order now!'\n",
    "text4 = 'Five other people are viewing this item.'\n",
    "text5 = '22 sold'\n",
    "text6 = '15 sold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping of the encoded dark pattern types.\n",
    "\n",
    "cat_dic = {0:'Fake Activity', 1:'Fake Countdown', 2:'Fake High-demand', 3:'Fake Limited-time', 4:'Fake Low-stock'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from Logistic Regression Model:\n",
      "\b Fake Activity\n",
      "Prediction from Random Forest Model:\n",
      "\b Fake Activity\n",
      "Prediction from SVM Model:\n",
      "\b Fake Activity\n",
      "Prediction from Multinomial Naive Bayes Model:\n",
      "\b Fake Countdown\n"
     ]
    }
   ],
   "source": [
    "# -----Make predictions on the single text line\n",
    "# apply the pretrained model to the input text\n",
    "\n",
    "# === Text1:\n",
    "pred_lr = lr_clf.predict(cv.transform(pd.Series(text1)))\n",
    "pred_rf = rf_clf.predict(cv.transform(pd.Series(text1)))\n",
    "pred_svm = svm_clf.predict(cv.transform(pd.Series(text1)))\n",
    "pred_mnb = mnb_clf.predict(cv.transform(pd.Series(text1)))\n",
    "\n",
    "print('Prediction from Logistic Regression Model:\\n\\b', cat_dic[int(pred_lr)])\n",
    "print('Prediction from Random Forest Model:\\n\\b', cat_dic[int(pred_rf)])\n",
    "print('Prediction from SVM Model:\\n\\b', cat_dic[int(pred_svm)])\n",
    "print('Prediction from Multinomial Naive Bayes Model:\\n\\b', cat_dic[int(pred_mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from Logistic Regression Model:\n",
      "\b Fake Activity\n",
      "Prediction from Random Forest Model:\n",
      "\b Fake Activity\n",
      "Prediction from SVM Model:\n",
      "\b Fake Activity\n",
      "Prediction from Multinomial Naive Bayes Model:\n",
      "\b Fake Countdown\n"
     ]
    }
   ],
   "source": [
    "# -----Make predictions on the single text line\n",
    "# apply the pretrained model to the input text\n",
    "\n",
    "# === Text2:\n",
    "pred_lr = lr_clf.predict(cv.transform(pd.Series(text2)))\n",
    "pred_rf = rf_clf.predict(cv.transform(pd.Series(text2)))\n",
    "pred_svm = svm_clf.predict(cv.transform(pd.Series(text2)))\n",
    "pred_mnb = mnb_clf.predict(cv.transform(pd.Series(text2)))\n",
    "\n",
    "print('Prediction from Logistic Regression Model:\\n\\b', cat_dic[int(pred_lr)])\n",
    "print('Prediction from Random Forest Model:\\n\\b', cat_dic[int(pred_rf)])\n",
    "print('Prediction from SVM Model:\\n\\b', cat_dic[int(pred_svm)])\n",
    "print('Prediction from Multinomial Naive Bayes Model:\\n\\b', cat_dic[int(pred_mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from Logistic Regression Model:\n",
      "\b Fake High-demand\n",
      "Prediction from Random Forest Model:\n",
      "\b Fake High-demand\n",
      "Prediction from SVM Model:\n",
      "\b Fake High-demand\n",
      "Prediction from Multinomial Naive Bayes Model:\n",
      "\b Fake High-demand\n"
     ]
    }
   ],
   "source": [
    "# -----Make predictions on the single text line\n",
    "# apply the pretrained model to the input text\n",
    "\n",
    "# === Text3:\n",
    "pred_lr = lr_clf.predict(cv.transform(pd.Series(text3)))\n",
    "pred_rf = rf_clf.predict(cv.transform(pd.Series(text3)))\n",
    "pred_svm = svm_clf.predict(cv.transform(pd.Series(text3)))\n",
    "pred_mnb = mnb_clf.predict(cv.transform(pd.Series(text3)))\n",
    "\n",
    "print('Prediction from Logistic Regression Model:\\n\\b', cat_dic[int(pred_lr)])\n",
    "print('Prediction from Random Forest Model:\\n\\b', cat_dic[int(pred_rf)])\n",
    "print('Prediction from SVM Model:\\n\\b', cat_dic[int(pred_svm)])\n",
    "print('Prediction from Multinomial Naive Bayes Model:\\n\\b', cat_dic[int(pred_mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from Logistic Regression Model:\n",
      "\b Fake Activity\n",
      "Prediction from Random Forest Model:\n",
      "\b Fake Activity\n",
      "Prediction from SVM Model:\n",
      "\b Fake Activity\n",
      "Prediction from Multinomial Naive Bayes Model:\n",
      "\b Fake Activity\n"
     ]
    }
   ],
   "source": [
    "# -----Make predictions on the single text line\n",
    "# apply the pretrained model to the input text\n",
    "\n",
    "# === Text4:\n",
    "pred_lr = lr_clf.predict(cv.transform(pd.Series(text4)))\n",
    "pred_rf = rf_clf.predict(cv.transform(pd.Series(text4)))\n",
    "pred_svm = svm_clf.predict(cv.transform(pd.Series(text4)))\n",
    "pred_mnb = mnb_clf.predict(cv.transform(pd.Series(text4)))\n",
    "\n",
    "print('Prediction from Logistic Regression Model:\\n\\b', cat_dic[int(pred_lr)])\n",
    "print('Prediction from Random Forest Model:\\n\\b', cat_dic[int(pred_rf)])\n",
    "print('Prediction from SVM Model:\\n\\b', cat_dic[int(pred_svm)])\n",
    "print('Prediction from Multinomial Naive Bayes Model:\\n\\b', cat_dic[int(pred_mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from Logistic Regression Model:\n",
      "\b Fake Activity\n",
      "Prediction from Random Forest Model:\n",
      "\b Fake Activity\n",
      "Prediction from SVM Model:\n",
      "\b Fake Activity\n",
      "Prediction from Multinomial Naive Bayes Model:\n",
      "\b Fake Activity\n"
     ]
    }
   ],
   "source": [
    "# -----Make predictions on the single text line\n",
    "# apply the pretrained model to the input text\n",
    "\n",
    "# === Text5:\n",
    "pred_lr = lr_clf.predict(cv.transform(pd.Series(text5)))\n",
    "pred_rf = rf_clf.predict(cv.transform(pd.Series(text5)))\n",
    "pred_svm = svm_clf.predict(cv.transform(pd.Series(text5)))\n",
    "pred_mnb = mnb_clf.predict(cv.transform(pd.Series(text5)))\n",
    "\n",
    "print('Prediction from Logistic Regression Model:\\n\\b', cat_dic[int(pred_lr)])\n",
    "print('Prediction from Random Forest Model:\\n\\b', cat_dic[int(pred_rf)])\n",
    "print('Prediction from SVM Model:\\n\\b', cat_dic[int(pred_svm)])\n",
    "print('Prediction from Multinomial Naive Bayes Model:\\n\\b', cat_dic[int(pred_mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from Logistic Regression Model:\n",
      "\b Fake Activity\n",
      "Prediction from Random Forest Model:\n",
      "\b Fake Activity\n",
      "Prediction from SVM Model:\n",
      "\b Fake Activity\n",
      "Prediction from Multinomial Naive Bayes Model:\n",
      "\b Fake Activity\n"
     ]
    }
   ],
   "source": [
    "# -----Make predictions on the single text line\n",
    "# apply the pretrained model to the input text\n",
    "\n",
    "# === Text6:\n",
    "pred_lr = lr_clf.predict(cv.transform(pd.Series(text6)))\n",
    "pred_rf = rf_clf.predict(cv.transform(pd.Series(text6)))\n",
    "pred_svm = svm_clf.predict(cv.transform(pd.Series(text6)))\n",
    "pred_mnb = mnb_clf.predict(cv.transform(pd.Series(text6)))\n",
    "\n",
    "print('Prediction from Logistic Regression Model:\\n\\b', cat_dic[int(pred_lr)])\n",
    "print('Prediction from Random Forest Model:\\n\\b', cat_dic[int(pred_rf)])\n",
    "print('Prediction from SVM Model:\\n\\b', cat_dic[int(pred_svm)])\n",
    "print('Prediction from Multinomial Naive Bayes Model:\\n\\b', cat_dic[int(pred_mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Testing Dataset  !!!!!!!!!!!!!!!!! TO BE CONTINUED\n",
    "\n",
    "---\n",
    "Import the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your price for this item is $ 89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your price for this item is $ 79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your price for this item is $ 55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your price for this item is $ 49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your price for this item is $ 21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            content  Classification\n",
       "0  Your price for this item is $ 89               1\n",
       "1  Your price for this item is $ 79               1\n",
       "2  Your price for this item is $ 55               1\n",
       "3  Your price for this item is $ 49               1\n",
       "4  Your price for this item is $ 21               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`check the dataset information`\n",
    "\n",
    "There are 3694 NOT NULL instances of content strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3694 entries, 0 to 3693\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         3694 non-null   object\n",
      " 1   Classification  3694 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 57.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "1    3344\n",
      "0     350\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['Classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3694 entries, 0 to 3693\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         3694 non-null   object\n",
      " 1   Classification  3694 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 86.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# For later training the model, we should remove the duplicate input to reduce overfitting.\n",
    "\n",
    "data = data.drop_duplicates(subset=\"content\")\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            content  Classification\n",
      "0  Your price for this item is $ 89               1\n",
      "1  Your price for this item is $ 79               1\n",
      "2  Your price for this item is $ 55               1\n",
      "3  Your price for this item is $ 49               1\n",
      "4  Your price for this item is $ 21               1\n",
      "\n",
      "Distribution of the tags:\n",
      "1    3344\n",
      "0     350\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))\n",
    "\n",
    "print('\\nDistribution of the tags:\\n{}'.format(data['Classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the target vales into integers` --- 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Classification']\n",
    "X = data['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "# check the mapping of encoding results (from 0 to 1 representing 'Dark', 'Not Dark')\n",
    "\n",
    "integer_mapping = {label: encoding for encoding, label in enumerate(encoder.classes_)}\n",
    "print(integer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  350]\n",
      " [   1 3344]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the pattern classification with pattern classification names.\n",
    "\n",
    "(unique, counts) = np.unique(Y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  350]\n",
      " [   1 3344]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bernoulli Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  553]\n",
      " [   1 3141]]\n",
      "\n",
      "Accuracy: 0.941797509474824\n",
      "Precision: 0.6220614828209765\n",
      "Confusion Matrix:\n",
      " [[ 344    6]\n",
      " [ 209 3135]]\n",
      "\n",
      "Precison: 0.622\n",
      "Recall: 0.983\n",
      "F1 Score: 0.762\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V1/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V1/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V1.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V1.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  855]\n",
      " [   1 2839]]\n",
      "\n",
      "Accuracy: 0.8622089875473741\n",
      "Precision: 0.4070175438596491\n",
      "Confusion Matrix:\n",
      " [[ 348    2]\n",
      " [ 507 2837]]\n",
      "\n",
      "Precison: 0.407\n",
      "Recall: 0.994\n",
      "F1 Score: 0.578\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V2/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V2/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V2.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V2.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 4\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  490]\n",
      " [   1 3204]]\n",
      "\n",
      "Accuracy: 0.9593936112615051\n",
      "Precision: 0.7040816326530612\n",
      "Confusion Matrix:\n",
      " [[ 345    5]\n",
      " [ 145 3199]]\n",
      "\n",
      "Precison: 0.704\n",
      "Recall: 0.986\n",
      "F1 Score: 0.821\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V4/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V4/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V4.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V4.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 5\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  492]\n",
      " [   1 3202]]\n",
      "\n",
      "Accuracy: 0.9593936112615051\n",
      "Precision: 0.7032520325203252\n",
      "Confusion Matrix:\n",
      " [[ 346    4]\n",
      " [ 146 3198]]\n",
      "\n",
      "Precison: 0.703\n",
      "Recall: 0.989\n",
      "F1 Score: 0.822\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V5/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V5/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V5.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V5.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 6\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  527]\n",
      " [   1 3167]]\n",
      "\n",
      "Accuracy: 0.9510016242555496\n",
      "Precision: 0.6603415559772297\n",
      "Confusion Matrix:\n",
      " [[ 348    2]\n",
      " [ 179 3165]]\n",
      "\n",
      "Precison: 0.660\n",
      "Recall: 0.994\n",
      "F1 Score: 0.794\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V6/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V6/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V6.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V6.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 7\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  509]\n",
      " [   1 3185]]\n",
      "\n",
      "Accuracy: 0.9547915538711423\n",
      "Precision: 0.6797642436149313\n",
      "Confusion Matrix:\n",
      " [[ 346    4]\n",
      " [ 163 3181]]\n",
      "\n",
      "Precison: 0.680\n",
      "Recall: 0.989\n",
      "F1 Score: 0.806\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V7/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V7/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V7.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V7.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 8\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  458]\n",
      " [   1 3236]]\n",
      "\n",
      "Accuracy: 0.9685977260422306\n",
      "Precision: 0.7554585152838428\n",
      "Confusion Matrix:\n",
      " [[ 346    4]\n",
      " [ 112 3232]]\n",
      "\n",
      "Precison: 0.755\n",
      "Recall: 0.989\n",
      "F1 Score: 0.856\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V8/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V8/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V8.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V8.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- CV -- CountVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  378]\n",
      " [   1 3316]]\n",
      "\n",
      "Accuracy: 0.9875473741201949\n",
      "Precision: 0.9021164021164021\n",
      "Confusion Matrix:\n",
      " [[ 341    9]\n",
      " [  37 3307]]\n",
      "\n",
      "Precison: 0.902\n",
      "Recall: 0.974\n",
      "F1 Score: 0.937\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/CV/CountVectorizer/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/CV/CountVectorizer/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-CV-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-CV-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- CV -- TfidfVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  378]\n",
      " [   1 3316]]\n",
      "\n",
      "Accuracy: 0.9875473741201949\n",
      "Precision: 0.9021164021164021\n",
      "Confusion Matrix:\n",
      " [[ 341    9]\n",
      " [  37 3307]]\n",
      "\n",
      "Precison: 0.902\n",
      "Recall: 0.974\n",
      "F1 Score: 0.937\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/CV/TfidfVectorizer/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/CV/TfidfVectorizer/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-CV-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-CV-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- HO -- CountVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  407]\n",
      " [   1 3287]]\n",
      "\n",
      "Accuracy: 0.9813210611802924\n",
      "Precision: 0.8452088452088452\n",
      "Confusion Matrix:\n",
      " [[ 344    6]\n",
      " [  63 3281]]\n",
      "\n",
      "Precison: 0.845\n",
      "Recall: 0.983\n",
      "F1 Score: 0.909\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/HO/CountVectorizer/presence_CountVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/HO/CountVectorizer/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-HO-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-HO-CountVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 9 -- HO -- TfidfVectorizer\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  382]\n",
      " [   1 3312]]\n",
      "\n",
      "Accuracy: 0.9870059556036817\n",
      "Precision: 0.8952879581151832\n",
      "Confusion Matrix:\n",
      " [[ 342    8]\n",
      " [  40 3304]]\n",
      "\n",
      "Precison: 0.895\n",
      "Recall: 0.977\n",
      "F1 Score: 0.934\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V9/HO/TfidfVectorizer/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V9/HO/TfidfVectorizer/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V9-HO-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V9-HO-TfidfVectorizer.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 10 -- CV\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  369]\n",
      " [   1 3325]]\n",
      "\n",
      "Accuracy: 0.9818624796968056\n",
      "Precision: 0.8834688346883469\n",
      "Confusion Matrix:\n",
      " [[ 326   24]\n",
      " [  43 3301]]\n",
      "\n",
      "Precison: 0.883\n",
      "Recall: 0.931\n",
      "F1 Score: 0.907\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V10/CV/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V10/CV/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-CV.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-CV.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 10 -- HO\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'iid': 'deprecated', 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[   0  362]\n",
      " [   1 3332]]\n",
      "\n",
      "Accuracy: 0.9420682187330807\n",
      "Precision: 0.6878453038674033\n",
      "Confusion Matrix:\n",
      " [[ 249  101]\n",
      " [ 113 3231]]\n",
      "\n",
      "Precison: 0.688\n",
      "Recall: 0.711\n",
      "F1 Score: 0.699\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"V10/HO/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"V10/HO/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content']))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-HO.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-HO.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
