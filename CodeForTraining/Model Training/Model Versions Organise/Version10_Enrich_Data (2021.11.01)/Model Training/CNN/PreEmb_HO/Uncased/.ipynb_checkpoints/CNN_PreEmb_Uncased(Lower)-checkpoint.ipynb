{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CGdb03m8xCQK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "#!pip install -q pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hmb5zplATLnm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7952 entries, 0 to 7951\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Pattern String  7952 non-null   object\n",
      " 1   classification  7952 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 124.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "      Pattern String  classification\n",
       " 0  Ends in 07:42:09               0\n",
       " 1  Ends in 07:37:10               0\n",
       " 2  Ends in 02:27:10               0\n",
       " 3  Ends in 04:17:10               0\n",
       " 4  Ends in 01:57:10               0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('enriched_data.csv')\n",
    "\n",
    "data.info(),data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ends in 07:42:09</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ends in 07:37:10</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ends in 02:27:10</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ends in 04:17:10</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ends in 01:57:10</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pattern String classification\n",
       "0  Ends in 07:42:09           Dark\n",
       "1  Ends in 07:37:10           Dark\n",
       "2  Ends in 02:27:10           Dark\n",
       "3  Ends in 04:17:10           Dark\n",
       "4  Ends in 01:57:10           Dark"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['classification'].replace({0:'Dark',1:'Not_Dark'}, inplace = True)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7902, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the rows where the first letter starting with ignoring characters\n",
    "ignore_str = [',', '.', ';', '{', '}', '#', '/', '?', '@','$','(',')']\n",
    "data = data[~data['Pattern String'].str[0].isin(ignore_str)]\n",
    "\n",
    "# change the input text into lowercase for embedding preparation and later training\n",
    "data['Pattern String'] = data['Pattern String'].str.lower()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6321,), (1581,), (6321,), (1581,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['Pattern String'].values\n",
    "Y = data['classification'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "content_train, content_val, label_train, label_val = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "content_train.shape, content_val.shape, label_train.shape, label_val.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to be specific, we are proud to disclose the exact forms we use:'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the label labels\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency distribution of training y labels:\n",
      " [['Dark' 849]\n",
      " ['Not_Dark' 5472]]\n",
      "The frequency distribution of validation y labels:\n",
      " [['Dark' 195]\n",
      " ['Not_Dark' 1386]]\n",
      "The frequency distribution of training y encoded labels:\n",
      " [[   0  849]\n",
      " [   1 5472]]\n",
      "The frequency distribution of validation y encoded labels:\n",
      " [[   0  195]\n",
      " [   1 1386]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit(label_train)\n",
    "y_train = encoder.transform(label_train)\n",
    "y_val = encoder.transform(label_val)\n",
    "\n",
    "\n",
    "(unique, counts) = np.unique(label_train, return_counts=True)\n",
    "frequencies_y_train_label = np.asarray((unique, counts)).T\n",
    "\n",
    "print('The frequency distribution of training y labels:\\n',frequencies_y_train_label)\n",
    "\n",
    "(unique, counts) = np.unique(label_val, return_counts=True)\n",
    "frequencies_y_val_label = np.asarray((unique, counts)).T\n",
    "\n",
    "print('The frequency distribution of validation y labels:\\n',frequencies_y_val_label)\n",
    "\n",
    "\n",
    "\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies_y_train_encoded = np.asarray((unique, counts)).T\n",
    "\n",
    "print('The frequency distribution of training y encoded labels:\\n',frequencies_y_train_encoded)\n",
    "\n",
    "(unique, counts) = np.unique(y_val, return_counts=True)\n",
    "frequencies_y_val_encoded = np.asarray((unique, counts)).T\n",
    "\n",
    "print('The frequency distribution of validation y encoded labels:\\n',frequencies_y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6321,), (1581,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NncztENMazg8"
   },
   "source": [
    "## Create a vocabulary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5687"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(content_train)    # Updates internal vocabulary based on a list of texts\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(content_train)  # Transforms each text in texts to a sequence of integers with its corresponding integer value from the word_index dictionary\n",
    "X_val = tokenizer.texts_to_sequences(content_val)\n",
    "\n",
    "# The number of unique words in the whole training text\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index for padding\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 1,\n",
       " 'left': 2,\n",
       " 'only': 3,\n",
       " 'to': 4,\n",
       " '1': 5,\n",
       " 'for': 6,\n",
       " 'and': 7,\n",
       " 'this': 8,\n",
       " 'stock': 9,\n",
       " 'the': 10,\n",
       " 'all': 11,\n",
       " '2': 12,\n",
       " 'your': 13,\n",
       " 'on': 14,\n",
       " '5': 15,\n",
       " 'a': 16,\n",
       " 'accessories': 17,\n",
       " 'women': 18,\n",
       " 'eur': 19,\n",
       " 'with': 20,\n",
       " 'up': 21,\n",
       " 'off': 22,\n",
       " 'time': 23,\n",
       " '4': 24,\n",
       " '3': 25,\n",
       " 'of': 26,\n",
       " 'by': 27,\n",
       " 'shein': 28,\n",
       " 'limited': 29,\n",
       " 'hurry': 30,\n",
       " 'new': 31,\n",
       " 'sold': 32,\n",
       " 'sale': 33,\n",
       " '10': 34,\n",
       " 'people': 35,\n",
       " 'you': 36,\n",
       " 'more': 37,\n",
       " 'from': 38,\n",
       " 'dress': 39,\n",
       " 'purchased': 40,\n",
       " 'order': 41,\n",
       " 'item': 42,\n",
       " 'see': 43,\n",
       " 'products': 44,\n",
       " 'shoulder': 45,\n",
       " 'product': 46,\n",
       " 'is': 47,\n",
       " 'home': 48,\n",
       " 'sweater': 49,\n",
       " 'bought': 50,\n",
       " 'us': 51,\n",
       " 'free': 52,\n",
       " '6': 53,\n",
       " '7': 54,\n",
       " 'plus': 55,\n",
       " 'dresses': 56,\n",
       " 'other': 57,\n",
       " 'now': 58,\n",
       " 'have': 59,\n",
       " 'high': 60,\n",
       " '0': 61,\n",
       " '00': 62,\n",
       " 'minutes': 63,\n",
       " 'items': 64,\n",
       " 'out': 65,\n",
       " 'shop': 66,\n",
       " 'shipping': 67,\n",
       " 'smart': 68,\n",
       " 'tv': 69,\n",
       " 'drop': 70,\n",
       " 'are': 71,\n",
       " '9': 72,\n",
       " 'size': 73,\n",
       " 'top': 74,\n",
       " 'neck': 75,\n",
       " 'delivery': 76,\n",
       " 'hours': 77,\n",
       " 'solid': 78,\n",
       " 'or': 79,\n",
       " 'save': 80,\n",
       " 'last': 81,\n",
       " 'box': 82,\n",
       " 'about': 83,\n",
       " 'united': 84,\n",
       " 'sleeve': 85,\n",
       " 'print': 86,\n",
       " 'it': 87,\n",
       " 'black': 88,\n",
       " 'just': 89,\n",
       " 'ends': 90,\n",
       " '99': 91,\n",
       " 'our': 92,\n",
       " 'states': 93,\n",
       " 'cart': 94,\n",
       " 'care': 95,\n",
       " '8': 96,\n",
       " 'set': 97,\n",
       " 'at': 98,\n",
       " 'ago': 99,\n",
       " 'hair': 100,\n",
       " 'price': 101,\n",
       " 'postage': 102,\n",
       " 'parts': 103,\n",
       " 'sets': 104,\n",
       " 'someone': 105,\n",
       " 'amazon': 106,\n",
       " 'days': 107,\n",
       " 'supplies': 108,\n",
       " 'offer': 109,\n",
       " 'coat': 110,\n",
       " 'ring': 111,\n",
       " 'tops': 112,\n",
       " 'pack': 113,\n",
       " '50': 114,\n",
       " 'we': 115,\n",
       " 'low': 116,\n",
       " 'led': 117,\n",
       " 'suit': 118,\n",
       " 'get': 119,\n",
       " 'storage': 120,\n",
       " 'orders': 121,\n",
       " 'baby': 122,\n",
       " 'clothing': 123,\n",
       " '15': 124,\n",
       " 'tools': 125,\n",
       " 'viewed': 126,\n",
       " 'knit': 127,\n",
       " 'pieces': 128,\n",
       " 'buying': 129,\n",
       " 'electric': 130,\n",
       " 'jacket': 131,\n",
       " 'skinny': 132,\n",
       " 'kitchen': 133,\n",
       " 'shoes': 134,\n",
       " 'breasted': 135,\n",
       " 'available': 136,\n",
       " 'deals': 137,\n",
       " 'washing': 138,\n",
       " 'cm': 139,\n",
       " 'trousers': 140,\n",
       " 'tall': 141,\n",
       " '11': 142,\n",
       " 'beauty': 143,\n",
       " 'guide': 144,\n",
       " 'crop': 145,\n",
       " 'usb': 146,\n",
       " 'over': 147,\n",
       " 'bag': 148,\n",
       " '20': 149,\n",
       " 'decor': 150,\n",
       " 'double': 151,\n",
       " 'please': 152,\n",
       " 'power': 153,\n",
       " 'jackets': 154,\n",
       " 'hd': 155,\n",
       " 'petite': 156,\n",
       " 'my': 157,\n",
       " 'gift': 158,\n",
       " '24': 159,\n",
       " 'kg': 160,\n",
       " 'fit': 161,\n",
       " 'reviews': 162,\n",
       " 'front': 163,\n",
       " 'boohoo': 164,\n",
       " 'offers': 165,\n",
       " 'few': 166,\n",
       " 'one': 167,\n",
       " 'machine': 168,\n",
       " '12': 169,\n",
       " '30': 170,\n",
       " 'be': 171,\n",
       " 'white': 172,\n",
       " 'maternity': 173,\n",
       " 'leather': 174,\n",
       " 'was': 175,\n",
       " 'sports': 176,\n",
       " 'today': 177,\n",
       " 'boots': 178,\n",
       " 'satin': 179,\n",
       " 'back': 180,\n",
       " 'cable': 181,\n",
       " 'man': 182,\n",
       " 'style': 183,\n",
       " 'coats': 184,\n",
       " 'view': 185,\n",
       " 'gaming': 186,\n",
       " 'shirts': 187,\n",
       " 'com': 188,\n",
       " 'shorts': 189,\n",
       " 'rs': 190,\n",
       " 'health': 191,\n",
       " 'security': 192,\n",
       " 'bags': 193,\n",
       " 'pc': 194,\n",
       " 'help': 195,\n",
       " '100': 196,\n",
       " 'light': 197,\n",
       " 'pants': 198,\n",
       " 'pocket': 199,\n",
       " 'body': 200,\n",
       " 'beach': 201,\n",
       " 'will': 202,\n",
       " 'quality': 203,\n",
       " 'fashion': 204,\n",
       " '13': 205,\n",
       " 'select': 206,\n",
       " 'long': 207,\n",
       " 'services': 208,\n",
       " 'christmas': 209,\n",
       " 'fast': 210,\n",
       " '18': 211,\n",
       " 'enter': 212,\n",
       " 'detail': 213,\n",
       " 'wheel': 214,\n",
       " '2021': 215,\n",
       " 'add': 216,\n",
       " 'single': 217,\n",
       " 'equipment': 218,\n",
       " 'computer': 219,\n",
       " 'reserved': 220,\n",
       " 'year': 221,\n",
       " 'denim': 222,\n",
       " 'review': 223,\n",
       " '22': 224,\n",
       " 'wide': 225,\n",
       " 'i': 226,\n",
       " 'no': 227,\n",
       " 'video': 228,\n",
       " 'leg': 229,\n",
       " 'mini': 230,\n",
       " 'floral': 231,\n",
       " '14': 232,\n",
       " 'check': 233,\n",
       " '4k': 234,\n",
       " 'buy': 235,\n",
       " 'x': 236,\n",
       " 'soon': 237,\n",
       " 's': 238,\n",
       " 'service': 239,\n",
       " 'recently': 240,\n",
       " 'display': 241,\n",
       " 'packaging': 242,\n",
       " 'jewelry': 243,\n",
       " 'spin': 244,\n",
       " '60': 245,\n",
       " 'cooker': 246,\n",
       " 'laptop': 247,\n",
       " 't': 248,\n",
       " 'star': 249,\n",
       " 'active': 250,\n",
       " 'design': 251,\n",
       " 'business': 252,\n",
       " 'lingerie': 253,\n",
       " 'red': 254,\n",
       " 'under': 255,\n",
       " 'wholesale': 256,\n",
       " 'square': 257,\n",
       " '000': 258,\n",
       " 'anti': 259,\n",
       " 'button': 260,\n",
       " 'glasses': 261,\n",
       " 'digital': 262,\n",
       " 'customer': 263,\n",
       " 'customers': 264,\n",
       " 'blazer': 265,\n",
       " 'payment': 266,\n",
       " 'office': 267,\n",
       " 'lights': 268,\n",
       " 'tvs': 269,\n",
       " 'details': 270,\n",
       " '32': 271,\n",
       " 'waist': 272,\n",
       " 'privacy': 273,\n",
       " '19': 274,\n",
       " '25': 275,\n",
       " 'matte': 276,\n",
       " '1400': 277,\n",
       " 'slim': 278,\n",
       " 'hrs': 279,\n",
       " 'belt': 280,\n",
       " 'skirt': 281,\n",
       " 'natural': 282,\n",
       " 'less': 283,\n",
       " 'than': 284,\n",
       " 'cleaning': 285,\n",
       " 'alibaba': 286,\n",
       " 'returns': 287,\n",
       " 'store': 288,\n",
       " 'pu': 289,\n",
       " 'online': 290,\n",
       " 'devices': 291,\n",
       " 'hem': 292,\n",
       " 'full': 293,\n",
       " 'lace': 294,\n",
       " 'within': 295,\n",
       " 'cookies': 296,\n",
       " 'added': 297,\n",
       " 'ruffle': 298,\n",
       " 'policy': 299,\n",
       " 'trunks': 300,\n",
       " 'mock': 301,\n",
       " 'color': 302,\n",
       " 'best': 303,\n",
       " 'air': 304,\n",
       " 'use': 305,\n",
       " 'cameras': 306,\n",
       " 'their': 307,\n",
       " 'multi': 308,\n",
       " 'easy': 309,\n",
       " 'great': 310,\n",
       " 'cover': 311,\n",
       " 'tie': 312,\n",
       " 'without': 313,\n",
       " 'viewing': 314,\n",
       " 'food': 315,\n",
       " 'can': 316,\n",
       " 'an': 317,\n",
       " 'rear': 318,\n",
       " 'audio': 319,\n",
       " '40': 320,\n",
       " 'hot': 321,\n",
       " 'furniture': 322,\n",
       " 'belted': 323,\n",
       " 'these': 324,\n",
       " 'steel': 325,\n",
       " 'mustang': 326,\n",
       " '09': 327,\n",
       " 'lighting': 328,\n",
       " 'seconds': 329,\n",
       " 'as': 330,\n",
       " 'information': 331,\n",
       " 'code': 332,\n",
       " 'zip': 333,\n",
       " 'site': 334,\n",
       " 'cotton': 335,\n",
       " 'wedding': 336,\n",
       " 'ruched': 337,\n",
       " 'watch': 338,\n",
       " 'contact': 339,\n",
       " 'co': 340,\n",
       " 'wall': 341,\n",
       " 'ultra': 342,\n",
       " 'selling': 343,\n",
       " 'boxes': 344,\n",
       " '00€': 345,\n",
       " 'shirt': 346,\n",
       " 'bath': 347,\n",
       " 'plain': 348,\n",
       " 'loungewear': 349,\n",
       " 'gas': 350,\n",
       " 'right': 351,\n",
       " 'day': 352,\n",
       " 'info': 353,\n",
       " 'islands': 354,\n",
       " 'soft': 355,\n",
       " 'faux': 356,\n",
       " 'necklace': 357,\n",
       " '49': 358,\n",
       " 'wireless': 359,\n",
       " 'john': 360,\n",
       " '2019': 361,\n",
       " 'email': 362,\n",
       " 'minimalist': 363,\n",
       " 'shopping': 364,\n",
       " '43': 365,\n",
       " 'makeup': 366,\n",
       " 'pro': 367,\n",
       " 'wrap': 368,\n",
       " '17': 369,\n",
       " 'cables': 370,\n",
       " 'printer': 371,\n",
       " 'trade': 372,\n",
       " 'cards': 373,\n",
       " 'custom': 374,\n",
       " 'trim': 375,\n",
       " 'cut': 376,\n",
       " 'terms': 377,\n",
       " 'sign': 378,\n",
       " '16': 379,\n",
       " 'clear': 380,\n",
       " 'card': 381,\n",
       " 'device': 382,\n",
       " 'collar': 383,\n",
       " 'trouser': 384,\n",
       " 'type': 385,\n",
       " 'mins': 386,\n",
       " 'first': 387,\n",
       " 'oversized': 388,\n",
       " 'availability': 389,\n",
       " 'make': 390,\n",
       " 'brands': 391,\n",
       " 'oven': 392,\n",
       " 'quick': 393,\n",
       " 'ebay': 394,\n",
       " 'rating': 395,\n",
       " 'jeans': 396,\n",
       " 'brand': 397,\n",
       " 'port': 398,\n",
       " 'vacuum': 399,\n",
       " 'options': 400,\n",
       " 'find': 401,\n",
       " 'checkout': 402,\n",
       " 'popular': 403,\n",
       " 'plastic': 404,\n",
       " 'drive': 405,\n",
       " 'drawstring': 406,\n",
       " '23': 407,\n",
       " 'rib': 408,\n",
       " 'super': 409,\n",
       " 'toys': 410,\n",
       " 'systems': 411,\n",
       " 'pullover': 412,\n",
       " 'how': 413,\n",
       " 'standard': 414,\n",
       " 'adapters': 415,\n",
       " 'cases': 416,\n",
       " 'blue': 417,\n",
       " 'change': 418,\n",
       " 'face': 419,\n",
       " 'search': 420,\n",
       " 'letter': 421,\n",
       " 'hooded': 422,\n",
       " 'range': 423,\n",
       " 'looking': 424,\n",
       " 'metal': 425,\n",
       " 'seller': 426,\n",
       " \"don't\": 427,\n",
       " 'jumpsuits': 428,\n",
       " 'lewis': 429,\n",
       " 'window': 430,\n",
       " 'quantity': 431,\n",
       " '500': 432,\n",
       " 'c': 433,\n",
       " \"men's\": 434,\n",
       " 'that': 435,\n",
       " 'appliances': 436,\n",
       " 'mens': 437,\n",
       " 'accs': 438,\n",
       " 'paper': 439,\n",
       " 'frame': 440,\n",
       " 'hdr': 441,\n",
       " 'china': 442,\n",
       " 'list': 443,\n",
       " 'teddy': 444,\n",
       " 'sweatshirt': 445,\n",
       " 'bar': 446,\n",
       " '54': 447,\n",
       " 'here': 448,\n",
       " 'stainless': 449,\n",
       " 'drives': 450,\n",
       " 'adapter': 451,\n",
       " 'glass': 452,\n",
       " 'nyx': 453,\n",
       " 'portable': 454,\n",
       " 'lounge': 455,\n",
       " 'currently': 456,\n",
       " 'hour': 457,\n",
       " 'lunch': 458,\n",
       " 'machines': 459,\n",
       " 'small': 460,\n",
       " '45': 461,\n",
       " 'most': 462,\n",
       " '70': 463,\n",
       " 'sell': 464,\n",
       " 'has': 465,\n",
       " 'times': 466,\n",
       " '48': 467,\n",
       " 'claimed': 468,\n",
       " '31': 469,\n",
       " 'tailored': 470,\n",
       " 'also': 471,\n",
       " 'uk': 472,\n",
       " 'watches': 473,\n",
       " 'energy': 474,\n",
       " 'bottoms': 475,\n",
       " 'charger': 476,\n",
       " 'demand': 477,\n",
       " 'blouse': 478,\n",
       " 'magnetic': 479,\n",
       " '18x10': 480,\n",
       " 'photo': 481,\n",
       " 'diy': 482,\n",
       " 'integrated': 483,\n",
       " 'alexa': 484,\n",
       " 'removal': 485,\n",
       " 'gifts': 486,\n",
       " 'premium': 487,\n",
       " 'bikini': 488,\n",
       " 'manage': 489,\n",
       " 'skirts': 490,\n",
       " 'not': 491,\n",
       " 'kit': 492,\n",
       " 'guarantee': 493,\n",
       " 'contrast': 494,\n",
       " \"women's\": 495,\n",
       " 'mλn': 496,\n",
       " 'deal': 497,\n",
       " 'dash': 498,\n",
       " 'headphones': 499,\n",
       " 'luxury': 500,\n",
       " 'components': 501,\n",
       " 'socks': 502,\n",
       " 'hoodies': 503,\n",
       " '29': 504,\n",
       " 'puffer': 505,\n",
       " 'wheels': 506,\n",
       " 'men': 507,\n",
       " 'tablets': 508,\n",
       " 'collection': 509,\n",
       " '04': 510,\n",
       " 'skin': 511,\n",
       " 'prices': 512,\n",
       " '46': 513,\n",
       " 'duvet': 514,\n",
       " 'joggers': 515,\n",
       " 'wash': 516,\n",
       " 'control': 517,\n",
       " 'turtleneck': 518,\n",
       " 'discount': 519,\n",
       " 'flash': 520,\n",
       " 'flap': 521,\n",
       " 'built': 522,\n",
       " 'lapel': 523,\n",
       " 'screen': 524,\n",
       " 'battery': 525,\n",
       " 'stars': 526,\n",
       " 'laptops': 527,\n",
       " 'hard': 528,\n",
       " 'learn': 529,\n",
       " 'prime': 530,\n",
       " 'everything': 531,\n",
       " 'car': 532,\n",
       " 'protection': 533,\n",
       " 'organizer': 534,\n",
       " 'page': 535,\n",
       " 'vitamin': 536,\n",
       " 'account': 537,\n",
       " 'memory': 538,\n",
       " 'striped': 539,\n",
       " 'jumpsuit': 540,\n",
       " 'cami': 541,\n",
       " 'earrings': 542,\n",
       " 'megan': 543,\n",
       " 'fox': 544,\n",
       " 'printed': 545,\n",
       " '80': 546,\n",
       " 'go': 547,\n",
       " '35': 548,\n",
       " 'units': 549,\n",
       " 'international': 550,\n",
       " 'eye': 551,\n",
       " 'pattern': 552,\n",
       " 'key': 553,\n",
       " 'made': 554,\n",
       " 'personal': 555,\n",
       " 'expand': 556,\n",
       " 'stand': 557,\n",
       " 'like': 558,\n",
       " 'look': 559,\n",
       " 'sweatshirts': 560,\n",
       " 'cubic': 561,\n",
       " '200': 562,\n",
       " 'two': 563,\n",
       " 'graphic': 564,\n",
       " 'google': 565,\n",
       " 'assistant': 566,\n",
       " 'republic': 567,\n",
       " 'nail': 568,\n",
       " 'toner': 569,\n",
       " 'phones': 570,\n",
       " 'solutions': 571,\n",
       " 'kits': 572,\n",
       " 'logo': 573,\n",
       " 'well': 574,\n",
       " 'split': 575,\n",
       " 'velvet': 576,\n",
       " 'cleaners': 577,\n",
       " 'partners': 578,\n",
       " 'remaining': 579,\n",
       " 'laundry': 580,\n",
       " 'share': 581,\n",
       " 'silicone': 582,\n",
       " 'sleep': 583,\n",
       " 'hdmi': 584,\n",
       " 'massage': 585,\n",
       " 'internet': 586,\n",
       " 'min': 587,\n",
       " 'cartridge': 588,\n",
       " 'vest': 589,\n",
       " 'o': 590,\n",
       " 'supplier': 591,\n",
       " 'mesh': 592,\n",
       " 'party': 593,\n",
       " '¡á': 594,\n",
       " 'large': 595,\n",
       " 'mobile': 596,\n",
       " 'extra': 597,\n",
       " 'need': 598,\n",
       " 'bedding': 599,\n",
       " 'android': 600,\n",
       " 'bed': 601,\n",
       " '36': 602,\n",
       " 'art': 603,\n",
       " 'helpful': 604,\n",
       " 'sex': 605,\n",
       " 'jumper': 606,\n",
       " 'installation': 607,\n",
       " 'special': 608,\n",
       " 'may': 609,\n",
       " 'cookers': 610,\n",
       " 'mixed': 611,\n",
       " 'piece': 612,\n",
       " 'choose': 613,\n",
       " 'printers': 614,\n",
       " '59': 615,\n",
       " 'so': 616,\n",
       " 'colour': 617,\n",
       " 'tanning': 618,\n",
       " 'case': 619,\n",
       " 'heart': 620,\n",
       " 'support': 621,\n",
       " 'hob': 622,\n",
       " 'brushes': 623,\n",
       " '€1': 624,\n",
       " '55': 625,\n",
       " 'phone': 626,\n",
       " 'want': 627,\n",
       " 'round': 628,\n",
       " 'sec': 629,\n",
       " '39': 630,\n",
       " 'books': 631,\n",
       " 'south': 632,\n",
       " 'sound': 633,\n",
       " 'secs': 634,\n",
       " 'photos': 635,\n",
       " 'what': 636,\n",
       " 'speakers': 637,\n",
       " 'self': 638,\n",
       " 'pet': 639,\n",
       " 'bodysuit': 640,\n",
       " 'apply': 641,\n",
       " 'mice': 642,\n",
       " 'basic': 643,\n",
       " 'notice': 644,\n",
       " 'sheet': 645,\n",
       " 'pink': 646,\n",
       " 'pre': 647,\n",
       " 'ribbed': 648,\n",
       " 'sellers': 649,\n",
       " '4pcs': 650,\n",
       " 'chunky': 651,\n",
       " 'basics': 652,\n",
       " 'sales': 653,\n",
       " 'ovens': 654,\n",
       " 'collect': 655,\n",
       " 'vintage': 656,\n",
       " 'hardware': 657,\n",
       " 'music': 658,\n",
       " 'fine': 659,\n",
       " 'if': 660,\n",
       " 'call': 661,\n",
       " 'male': 662,\n",
       " 'monitors': 663,\n",
       " 'coupon': 664,\n",
       " 'desktop': 665,\n",
       " 'show': 666,\n",
       " 'casual': 667,\n",
       " '57': 668,\n",
       " 'm': 669,\n",
       " 'inch': 670,\n",
       " 'picture': 671,\n",
       " 'tech': 672,\n",
       " 'hand': 673,\n",
       " 'dvd': 674,\n",
       " 'results': 675,\n",
       " 'holder': 676,\n",
       " 'sunglasses': 677,\n",
       " 'any': 678,\n",
       " 'basket': 679,\n",
       " 'capacity': 680,\n",
       " 'container': 681,\n",
       " 'apple': 682,\n",
       " 'games': 683,\n",
       " 'fitted': 684,\n",
       " 'life': 685,\n",
       " 'corset': 686,\n",
       " 'networking': 687,\n",
       " 'travel': 688,\n",
       " 'buyer': 689,\n",
       " 'trendy': 690,\n",
       " 'request': 691,\n",
       " 'heating': 692,\n",
       " 'thermal': 693,\n",
       " '07': 694,\n",
       " '65': 695,\n",
       " 'ready': 696,\n",
       " 'customs': 697,\n",
       " '27': 698,\n",
       " '877': 699,\n",
       " 'tattoo': 700,\n",
       " 'sway': 701,\n",
       " 'location': 702,\n",
       " 'foldable': 703,\n",
       " 'gone': 704,\n",
       " 'lipsticks': 705,\n",
       " 'roll': 706,\n",
       " 'purchase': 707,\n",
       " 'bodycon': 708,\n",
       " 'feedback': 709,\n",
       " 'cardigan': 710,\n",
       " 'burner': 711,\n",
       " '21': 712,\n",
       " 'expires': 713,\n",
       " 'selected': 714,\n",
       " 'floor': 715,\n",
       " 'replacement': 716,\n",
       " 'guides': 717,\n",
       " '3d': 718,\n",
       " 'bento': 719,\n",
       " 'questions': 720,\n",
       " 'content': 721,\n",
       " 'ship': 722,\n",
       " '56': 723,\n",
       " 'bulbs': 724,\n",
       " '53': 725,\n",
       " '6pcs': 726,\n",
       " 'original': 727,\n",
       " 'signature': 728,\n",
       " 'looked': 729,\n",
       " 'colorblock': 730,\n",
       " 'chain': 731,\n",
       " 'warranty': 732,\n",
       " 'ceramic': 733,\n",
       " 'smock': 734,\n",
       " 'miss': 735,\n",
       " 'average': 736,\n",
       " 'costs': 737,\n",
       " 'money': 738,\n",
       " '51': 739,\n",
       " '42': 740,\n",
       " 'must': 741,\n",
       " 'rechargeable': 742,\n",
       " 'knitted': 743,\n",
       " 'reading': 744,\n",
       " 'dazy': 745,\n",
       " 'secure': 746,\n",
       " 'using': 747,\n",
       " 'l': 748,\n",
       " 'd6': 749,\n",
       " 'message': 750,\n",
       " 'electronics': 751,\n",
       " 'motf': 752,\n",
       " 'rpm': 753,\n",
       " 'dual': 754,\n",
       " 'local': 755,\n",
       " 'app': 756,\n",
       " 'kindle': 757,\n",
       " '33': 758,\n",
       " 'q': 759,\n",
       " 'lt': 760,\n",
       " 'fire': 761,\n",
       " 'jewellery': 762,\n",
       " 'tablet': 763,\n",
       " 'crystal': 764,\n",
       " 'click': 765,\n",
       " 'door': 766,\n",
       " '1999': 767,\n",
       " '2004': 768,\n",
       " '75': 769,\n",
       " 'posted': 770,\n",
       " 'eu': 771,\n",
       " 'freeview': 772,\n",
       " 'currys': 773,\n",
       " 'swimsuit': 774,\n",
       " 'kids': 775,\n",
       " 'zipper': 776,\n",
       " 'tool': 777,\n",
       " 'school': 778,\n",
       " 'good': 779,\n",
       " 'bulb': 780,\n",
       " 'return': 781,\n",
       " 'maxi': 782,\n",
       " 'swimwear': 783,\n",
       " 'perfect': 784,\n",
       " 'sun': 785,\n",
       " 'trainers': 786,\n",
       " 'image': 787,\n",
       " 'allover': 788,\n",
       " 'again': 789,\n",
       " 'short': 790,\n",
       " 'conditions': 791,\n",
       " 'silver': 792,\n",
       " 'track': 793,\n",
       " 'open': 794,\n",
       " 'suits': 795,\n",
       " 'tee': 796,\n",
       " 'recycled': 797,\n",
       " 'acrylic': 798,\n",
       " 'v': 799,\n",
       " 'performance': 800,\n",
       " '52': 801,\n",
       " 'stands': 802,\n",
       " '41': 803,\n",
       " 'categories': 804,\n",
       " 'mouse': 805,\n",
       " 'global': 806,\n",
       " 'leggings': 807,\n",
       " 'foot': 808,\n",
       " 'jacquard': 809,\n",
       " 'fitness': 810,\n",
       " 'rose': 811,\n",
       " '38': 812,\n",
       " 'classic': 813,\n",
       " 'balance': 814,\n",
       " 'jumpers': 815,\n",
       " 'start': 816,\n",
       " '90': 817,\n",
       " 'features': 818,\n",
       " 'watching': 819,\n",
       " 'tea': 820,\n",
       " 'grill': 821,\n",
       " 'trending': 822,\n",
       " '88': 823,\n",
       " 'data': 824,\n",
       " '85': 825,\n",
       " 'question': 826,\n",
       " 'bathroom': 827,\n",
       " 'wifi': 828,\n",
       " 'medical': 829,\n",
       " 'side': 830,\n",
       " 'puff': 831,\n",
       " 'program': 832,\n",
       " 'plate': 833,\n",
       " 'accessory': 834,\n",
       " 'mask': 835,\n",
       " 'bamboo': 836,\n",
       " 'compatible': 837,\n",
       " 'adjustable': 838,\n",
       " 'knitwear': 839,\n",
       " 'playsuits': 840,\n",
       " 'address': 841,\n",
       " 'charm': 842,\n",
       " 'chance': 843,\n",
       " 'received': 844,\n",
       " '64': 845,\n",
       " 'masks': 846,\n",
       " '3pcs': 847,\n",
       " 'keyboards': 848,\n",
       " 'hoodie': 849,\n",
       " 'better': 850,\n",
       " 'rated': 851,\n",
       " 'tab': 852,\n",
       " 'material': 853,\n",
       " '400': 854,\n",
       " 'going': 855,\n",
       " '69': 856,\n",
       " 'label': 857,\n",
       " 'there': 858,\n",
       " 'midi': 859,\n",
       " 'policies': 860,\n",
       " 'old': 861,\n",
       " 'includes': 862,\n",
       " 'website': 863,\n",
       " 'sexy': 864,\n",
       " 'others': 865,\n",
       " '03': 866,\n",
       " 'h': 867,\n",
       " 'bottle': 868,\n",
       " 'per': 869,\n",
       " 'cleaner': 870,\n",
       " 'green': 871,\n",
       " 'speed': 872,\n",
       " 'ink': 873,\n",
       " 'trunk': 874,\n",
       " '01': 875,\n",
       " 'rovos': 876,\n",
       " 'cape': 877,\n",
       " 'town': 878,\n",
       " 'live': 879,\n",
       " 'zmo': 880,\n",
       " 'category': 881,\n",
       " 'tissue': 882,\n",
       " 'smoke': 883,\n",
       " 'fiber': 884,\n",
       " '–': 885,\n",
       " 'straight': 886,\n",
       " 'salon': 887,\n",
       " 'entertainment': 888,\n",
       " 'complete': 889,\n",
       " '02': 890,\n",
       " 'colors': 891,\n",
       " 'blouses': 892,\n",
       " 'colombo': 893,\n",
       " 'treatments': 894,\n",
       " 'chargers': 895,\n",
       " 'clothes': 896,\n",
       " 'luggage': 897,\n",
       " 'fluffy': 898,\n",
       " 'tracksuits': 899,\n",
       " 'surface': 900,\n",
       " 'dining': 901,\n",
       " \"it's\": 902,\n",
       " 'building': 903,\n",
       " 'years': 904,\n",
       " 'fi': 905,\n",
       " 'consoles': 906,\n",
       " 'agree': 907,\n",
       " 'latest': 908,\n",
       " 'thank': 909,\n",
       " 'pure': 910,\n",
       " '58': 911,\n",
       " 'half': 912,\n",
       " 'cooling': 913,\n",
       " '83': 914,\n",
       " 'tank': 915,\n",
       " 'bodysuits': 916,\n",
       " 'function': 917,\n",
       " 'monitor': 918,\n",
       " 'almost': 919,\n",
       " 'lightweight': 920,\n",
       " 'tax': 921,\n",
       " 'animal': 922,\n",
       " 'holders': 923,\n",
       " 'cream': 924,\n",
       " 'australia': 925,\n",
       " 'lipstick': 926,\n",
       " 'name': 927,\n",
       " 'audi': 928,\n",
       " 'autumn': 929,\n",
       " 'racks': 930,\n",
       " 'equal': 931,\n",
       " 'appliance': 932,\n",
       " 'charge': 933,\n",
       " 'plaid': 934,\n",
       " 'skater': 935,\n",
       " 'end': 936,\n",
       " 'usd': 937,\n",
       " 'shaving': 938,\n",
       " '08': 939,\n",
       " 'industrial': 940,\n",
       " 'summer': 941,\n",
       " 'blocking': 942,\n",
       " 'arrivals': 943,\n",
       " 'female': 944,\n",
       " 'import': 945,\n",
       " 'ear': 946,\n",
       " 'friendly': 947,\n",
       " 'love': 948,\n",
       " 'answers': 949,\n",
       " '26': 950,\n",
       " 'elastic': 951,\n",
       " 'when': 952,\n",
       " 'country': 953,\n",
       " 'magnesium': 954,\n",
       " 'vision': 955,\n",
       " 'manicure': 956,\n",
       " 'hub': 957,\n",
       " 'fragrances': 958,\n",
       " 'ask': 959,\n",
       " 'factory': 960,\n",
       " 'weight': 961,\n",
       " 'fabric': 962,\n",
       " 'real': 963,\n",
       " 'settings': 964,\n",
       " 'suppliers': 965,\n",
       " 'tape': 966,\n",
       " 'sizes': 967,\n",
       " 'fuel': 968,\n",
       " 'gloves': 969,\n",
       " 'bracelet': 970,\n",
       " 'dryers': 971,\n",
       " 'room': 972,\n",
       " 'buckle': 973,\n",
       " 'frill': 974,\n",
       " 'bra': 975,\n",
       " 'checked': 976,\n",
       " 'needs': 977,\n",
       " 'testing': 978,\n",
       " 'computing': 979,\n",
       " 'subscribe': 980,\n",
       " 'tube': 981,\n",
       " 'vat': 982,\n",
       " 'synthetic': 983,\n",
       " 'pearl': 984,\n",
       " 'nightwear': 985,\n",
       " 'main': 986,\n",
       " 'essentials': 987,\n",
       " 'explore': 988,\n",
       " 'unisex': 989,\n",
       " 'outdoor': 990,\n",
       " 'points': 991,\n",
       " 'warm': 992,\n",
       " 'brushed': 993,\n",
       " 'household': 994,\n",
       " 'opens': 995,\n",
       " 'carpets': 996,\n",
       " 'rugs': 997,\n",
       " '72': 998,\n",
       " 'décor': 999,\n",
       " 'butterfly': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Presence_Tokenizer.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Tokenizer to disk\n",
    "import joblib\n",
    "\n",
    "joblib.dump(tokenizer, 'Presence_Tokenizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence in training:\n",
      " ([5664, 5665], 31)\n",
      "Longest sentence in validation:\n",
      " ([5681, 2746], 27)\n"
     ]
    }
   ],
   "source": [
    "def FindMaxLength(lst):\n",
    "    maxList = max((x) for x in lst)\n",
    "    maxLength = max(len(x) for x in lst )\n",
    "  \n",
    "    return maxList, maxLength\n",
    "\n",
    "print('Longest sentence in training:\\n',FindMaxLength(X_train))\n",
    "print('Longest sentence in validation:\\n',FindMaxLength(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 171, 2685, 115, 71, 1837, 4, 2686, 10, 2687, 2688, 115, 305]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 53, 65, 26, 15, 526]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6321, 20), (1581, 20))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 20\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVzFu49CbNc3"
   },
   "source": [
    "## Load pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzfS4Ob3dJCb"
   },
   "source": [
    "dict mapping words (strings) to their NumPy vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOiYidHncPu1",
    "outputId": "5bc83673-cf33-4e77-815c-15de470380a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21935 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YGVBng-fWzr",
    "outputId": "8ee124a6-c883-41a8-e262-1b1b4866dd10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 3343 words (2343 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = vocab_size\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WeoUNYKjw0rm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSNmFTh-aY8R"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCCQAwRQf4ow",
    "outputId": "9e7b71ed-3e66-47b8-8490-1d26e4c8cb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         1706100   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 64)          38464     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,746,677\n",
      "Trainable params: 40,577\n",
      "Non-trainable params: 1,706,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)  # input_length is the length of the sequence\n",
    "x = layers.Conv1D(64, 2, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iK4zR4zKg6k3",
    "outputId": "4164b1a0-8b73-4031-fde6-d1b4e45abcde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.2518 - acc: 0.9057 - val_loss: 0.0664 - val_acc: 0.9798\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0595 - acc: 0.9804 - val_loss: 0.0543 - val_acc: 0.9804\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0284 - acc: 0.9918 - val_loss: 0.0538 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0210 - acc: 0.9944 - val_loss: 0.0425 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0151 - acc: 0.9957 - val_loss: 0.0672 - val_acc: 0.9817\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd6fee02f10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"]\n",
    ")\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "model.fit(X_train,y_train, batch_size=16, epochs=10, validation_data=(X_val,y_val),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3RtovmuJwR-",
    "outputId": "01842be7-da99-4d0b-f9b9-f7b982866740",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9994099e-01],\n",
       "       [9.9989748e-01],\n",
       "       [9.9966818e-01],\n",
       "       ...,\n",
       "       [9.5296907e-01],\n",
       "       [2.2819931e-06],\n",
       "       [9.9987322e-01]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X_val)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1581, 1),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]], dtype=int32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dark = (prediction>0.5).astype('int32')\n",
    "\n",
    "dark.shape,dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1581,), array([1, 1, 1, ..., 1, 0, 1], dtype=int32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dark.flatten()\n",
    "\n",
    "pred.shape, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1581,), array([1, 1, 1, ..., 1, 0, 1]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.93896496e-08 1.00000000e+00]\n",
      " [1.72616396e-07 2.00000000e+00]\n",
      " [1.73851163e-07 1.00000000e+00]\n",
      " ...\n",
      " [9.99999821e-01 5.00000000e+00]\n",
      " [9.99999881e-01 9.00000000e+00]\n",
      " [1.00000000e+00 1.83000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(prediction, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  172]\n",
      " [   1 1409]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of the prediction results:\n",
      " [[ 169   26]\n",
      " [   3 1383]]\n",
      "FN Rate: 0.0164; FP Rate:0.0019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val, pred, labels=[0,1])\n",
    "FN = cm[0][1]/y_val.shape[0]\n",
    "FP = cm[1][0]/y_val.shape[0]\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print('FN Rate: {:.4f}; FP Rate:{:.4f}'.format(FN,FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### Threshold setting to be 0.75\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1581, 1),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]], dtype=int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr_75 = (prediction>0.75).astype('int32')\n",
    "\n",
    "thr_75.shape,thr_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1581,), array([1, 1, 1, ..., 1, 0, 1], dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred75 = thr_75.flatten()\n",
    "\n",
    "pred75.shape, pred75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  174]\n",
      " [   1 1407]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(pred75, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of the prediction results:\n",
      " [[ 170   25]\n",
      " [   4 1382]]\n",
      "FN Rate: 0.0158; FP Rate:0.0025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val, pred75, labels=[0,1])\n",
    "FN = cm[0][1]/y_val.shape[0]\n",
    "FP = cm[1][0]/y_val.shape[0]\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print('FN Rate: {:.4f}; FP Rate:{:.4f}'.format(FN,FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### Threshold setting to be 0.9\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1581, 1),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [1]], dtype=int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr_90 = (prediction>0.90).astype('int32')\n",
    "\n",
    "thr_90.shape,thr_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1581,), array([1, 1, 1, ..., 1, 0, 1], dtype=int32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred90 = thr_90.flatten()\n",
    "\n",
    "pred90.shape, pred90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  183]\n",
      " [   1 1398]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(pred90, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of the prediction results:\n",
      " [[ 175   20]\n",
      " [   8 1378]]\n",
      "FN Rate: 0.0127; FP Rate:0.0051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val, pred90, labels=[0,1])\n",
    "FN = cm[0][1]/y_val.shape[0]\n",
    "FP = cm[1][0]/y_val.shape[0]\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print('FN Rate: {:.4f}; FP Rate:{:.4f}'.format(FN,FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### Threshold of 0.5\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9972\n",
      "Validation Accuracy:  0.9817\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=False)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "1mjUgZ0zJ_NH",
    "outputId": "fae51928-0d5d-433d-c442-31ed3b7bf4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot_keras_history in /opt/anaconda3/lib/python3.8/site-packages (1.1.29)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from plot_keras_history) (1.5.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (from plot_keras_history) (1.1.3)\n",
      "Requirement already satisfied: sanitize-ml-labels in /opt/anaconda3/lib/python3.8/site-packages (from plot_keras_history) (1.0.26)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from plot_keras_history) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/anaconda3/lib/python3.8/site-packages (from scipy->plot_keras_history) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->plot_keras_history) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->plot_keras_history) (2020.1)\n",
      "Requirement already satisfied: compress-json in /opt/anaconda3/lib/python3.8/site-packages (from sanitize-ml-labels->plot_keras_history) (1.0.4)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->plot_keras_history) (1.15.0)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-596c59526884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplot_keras_history\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "!pip install plot_keras_history\n",
    "from plot_keras_history import plot_history\n",
    "\n",
    "plot_history(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "YlrjNOHWcrXT"
   },
   "outputs": [],
   "source": [
    "model.save('model_preEmb_CNN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uykmb_xMdak-"
   },
   "outputs": [],
   "source": [
    "model_reload=load_model('model_preEmb_CNN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Yl7T74saUCx"
   },
   "source": [
    "# CNN as an additional layer before a LSTM\n",
    "--------\n",
    "# Didn't change from here\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_Rsr1f5Ws3h",
    "outputId": "fd574b07-a26c-4f7f-9c90-8352cd024df6"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Embedding, SimpleRNN\n",
    "from tensorflow.keras import layers\n",
    "## create model\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.LSTM(embedding_dim)(x)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "preds = layers.Dense(len(lyrics_train), activation=\"softmax\")(x)\n",
    "model= keras.Model(int_sequences_input, preds)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMFoMe2lje43",
    "outputId": "07f8b0bf-7060-4cb4-98f9-820de57a6fe2"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "mod_1=model.fit(X_train,y_train, batch_size=128, epochs=10, validation_data=(X_val,y_val),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpO6CrG_mtGX",
    "outputId": "7d046448-c686-4613-f160-dd7f3558c401"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=False)\n",
    "print(\"validation Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "4CacQBGhmxc7",
    "outputId": "b7303451-9059-48bc-fe84-63b0b4ebcf77"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "!pip install plot_keras_history\n",
    "from plot_keras_history import plot_history\n",
    "plot_history(mod_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xK_cwtgjbL5N"
   },
   "outputs": [],
   "source": [
    "\n",
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ANB9l7b36jv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "reload_model=load_model('model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gf3c8tqTdigi",
    "outputId": "e97822a8-2edc-4b9f-bdde-0405a4ee72f5"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = reload_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8jRc_lPq16u"
   },
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cG8uesCgjXBb",
    "outputId": "2d04de49-c5ce-4023-e911-cbcfa53ef6a7"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Embedding, SimpleRNN\n",
    "from keras.callbacks import EarlyStopping\n",
    "## create model\n",
    "\n",
    "vocab_size=5000\n",
    "\n",
    "\n",
    "#int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "#embedded_sequences = embedding_layer(int_sequences_input)\n",
    "          # input_length is the length of the sequence\n",
    "modelRNN = Sequential()\n",
    "#modelCNN.add(tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "#                         batch_input_shape=[None,]))\n",
    "modelRNN.add(Embedding(input_dim=vocab_size,          # input_dim is the size of the vocabulary\n",
    "                           output_dim=embedding_dim,      # output_dim is the size of the dense vector\n",
    "                           input_length=400))\n",
    "modelRNN.add(SimpleRNN(embedding_dim))\n",
    "modelRNN.add(Dense(200, activation='relu'))\n",
    "modelRNN.add(Dropout(0.2))\n",
    "modelRNN.add(Dense(10, activation='softmax'))\n",
    "\n",
    "modelRNN.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u60v-A9ejaJc",
    "outputId": "956a6674-6076-4446-f680-f277711d027e"
   },
   "outputs": [],
   "source": [
    "modelRNN.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "mod_2=modelRNN.fit(X_train,y_train, batch_size=128, epochs=10, validation_data=(X_val,y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_1KgGtWjeL2",
    "outputId": "558005cf-feed-4676-a9d6-ec3dad352a30"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = modelRNN.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = modelRNN.evaluate(X_val, y_val, verbose=False)\n",
    "print(\"validation Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gAG25PBTBmy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "modelRNN.save('model_RNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msqdbpM0TCWm"
   },
   "outputs": [],
   "source": [
    "reload_model= keras.models.load_model(\"model_RNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4N0dm1rTN4q",
    "outputId": "d41cd703-0b51-4410-f08f-b0c8d5242172"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = reload_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68ZlmurqjlSi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "!pip install plot_keras_history\n",
    "from plot_keras_history import plot_history\n",
    "plot_history(mod_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQPog-lM3F9H"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "!pip install plot_keras_history\n",
    "from plot_keras_history import plot_history\n",
    "plot_history(mod_testRNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNpwS4FKrSCW"
   },
   "source": [
    "LSTM Muliple Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlyedgTLDVMZ",
    "outputId": "58c53eb8-fd9c-4712-8ce7-ab5588ba9bef"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Embedding, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "vocab_size = 5000\n",
    "\n",
    "model06 = Sequential()\n",
    "model06.add(Embedding(input_dim=vocab_size,          # input_dim is the size of the vocabulary\n",
    "                           output_dim=embedding_dim,      # output_dim is the size of the dense vector\n",
    "                           input_length=400))          # input_length is the length of the sequence\n",
    "model06.add(LSTM(embedding_dim,return_sequences=True))\n",
    "model06.add(LSTM(100, return_sequences=True))\n",
    "model06.add(LSTM(100))\n",
    "model06.add(Dense(200, activation='relu'))\n",
    "model06.add(Dropout(0.2))\n",
    "model06.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model06.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3C_jLuNDgKD",
    "outputId": "0150d850-8f72-45bf-e336-078b7e1d2b48"
   },
   "outputs": [],
   "source": [
    "model06.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "mod6=model06.fit(X_train,y_train, batch_size=128, epochs=10, validation_data=(X_val,y_val),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOX3bM5mDlR2",
    "outputId": "ccffc6af-ddaf-4d29-c7da-933cc74d365f"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model06.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model06.evaluate(X_val, y_val, verbose=False)\n",
    "print(\"validation Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "grUu1nFzTf5c",
    "outputId": "3dcd6dcc-e23f-47d9-a7b1-ea44a2561700"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "!pip install plot_keras_history\n",
    "from plot_keras_history import plot_history\n",
    "plot_history(mod6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8s-2tW2AIWF"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model06.save('model_MultiL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsBxvZJ2p0SO"
   },
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"model_MultiL.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-j-um6Qqp1Db",
    "outputId": "97f325a8-9439-49fa-832d-88f2f401422c"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model06.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYz0siQGE7qG"
   },
   "outputs": [],
   "source": [
    "prediction= reconstructed_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xekk1BmpFjNn",
    "outputId": "39ab4c12-87ba-4515-8a95-cb7c084928b9"
   },
   "outputs": [],
   "source": [
    "labels=['County','Electric','Folk','Hip-hop','Indie','Jazz','Metal','Pop','R&B','Rock']\n",
    "print(prediction)\n",
    "pred_str=[]\n",
    "for i in range (5000):\n",
    "  pred_str.append(labels[np.argmax(prediction[i])])\n",
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "_tFCQ8UrqJ3s",
    "outputId": "b64e272f-0b2c-4ec2-e316-ca9fe38447a1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "!pip install plot_keras_history\n",
    "from plot_keras_history import plot_history\n",
    "plot_history(mod_test6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZMQeIv3s0sP"
   },
   "source": [
    "LSTM Single Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-An9sUfs5Cl",
    "outputId": "9431fcf0-bec0-4ada-c5a8-d1edf9c91262"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Embedding, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "vocab_size = 5000\n",
    "\n",
    "model05 = Sequential()\n",
    "model05.add(Embedding(input_dim=vocab_size,          # input_dim is the size of the vocabulary\n",
    "                           output_dim=embedding_dim,      # output_dim is the size of the dense vector\n",
    "                           input_length=400))          # input_length is the length of the sequence\n",
    "model05.add(LSTM(embedding_dim))\n",
    "model05.add(Dense(200, activation='relu'))\n",
    "model05.add(Dropout(0.2))\n",
    "model05.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model05.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoZsKCcDs5wN",
    "outputId": "996e7601-43d1-4a5d-82d6-c8abdae40342"
   },
   "outputs": [],
   "source": [
    "model05.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "mod3=model05.fit(X_train,y_train, batch_size=128, epochs=10, validation_data=(X_val,y_val),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyLDhaDgs-pt",
    "outputId": "b48dcaf2-779b-4b38-c4a0-a57bbf55e13d"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model05.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model05.evaluate(X_val, y_val, verbose=False)\n",
    "print(\"validation Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "tIP4eMQhtCNw",
    "outputId": "92989fd6-0a5b-42f4-b520-3f7f9336fb3a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot\n",
    "!pip install plot_keras_history\n",
    "from plot_keras_history import plot_history\n",
    "plot_history(mod3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7faULTbZ4tQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model05.save('model_SingleL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6RqSU6BZ_yt"
   },
   "outputs": [],
   "source": [
    "reconstructed_model1 = keras.models.load_model(\"model_SingleL.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nML5KaTEaEof",
    "outputId": "506c4276-9f18-41de-d0cf-6cbc802880fe"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = reconstructed_model1.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "withembfinal_0205.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
