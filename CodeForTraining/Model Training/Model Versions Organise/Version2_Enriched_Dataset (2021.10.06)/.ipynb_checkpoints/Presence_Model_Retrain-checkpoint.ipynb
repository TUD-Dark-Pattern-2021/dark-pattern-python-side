{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# systematically compute word counts using CountVectorizer and them compute the Inverse Document Frequency (IDF) values and only then compute the Tf-idf scores.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1603\n",
      "1    1202\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------      Dataset Import      --------------------------------------\n",
    "\n",
    "presence = pd.read_csv('final_presence.csv')\n",
    "\n",
    "print(presence['classification'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "[[  0 949]\n",
      " [  1 734]]\n",
      "[[  0 949]\n",
      " [  1 734]]\n",
      "[[  0 654]\n",
      " [  1 468]]\n"
     ]
    }
   ],
   "source": [
    "# --------------------- Training Preparation ------------------\n",
    "\n",
    "# split the dataset into train and test dataset as a ratio of 60%/40% (train/test).\n",
    "\n",
    "string_train, string_test, dark_train, dark_test = train_test_split(\n",
    "    presence['Pattern String'], presence[\"classification\"], train_size = .6)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dark_train)\n",
    "y_train = encoder.transform(dark_train)\n",
    "y_test = encoder.transform(dark_test)\n",
    "\n",
    "# check the mapping of encoding results (from 0 to 1 representing 'Dark', 'Not Dark')\n",
    "\n",
    "integer_mapping = {label: encoding for encoding, label in enumerate(encoder.classes_)}\n",
    "print(integer_mapping)\n",
    "\n",
    "# Check the frequency distribution of the training pattern classification with pattern classification names.\n",
    "\n",
    "(unique, counts) = np.unique(dark_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)\n",
    "\n",
    "\n",
    "# Check the frequency distribution of the encoded training pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)\n",
    "\n",
    "\n",
    "# Check the frequency distribution of the encoded testing pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presence_CountVectorizer.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # First get the word count vector of the pattern string to encode the pattern string.\n",
    "\n",
    "cv = CountVectorizer()\n",
    "string_train_counts = cv.fit_transform(string_train)\n",
    "\n",
    "# Then use the tf-idf score to transform the encoded word count pattern string vectors.\n",
    "\n",
    "tfidf_tf = TfidfTransformer()\n",
    "X_train = tfidf_tf.fit_transform(string_train_counts)\n",
    "\n",
    "# save the CountVectorizer to disk\n",
    "\n",
    "joblib.dump(cv, 'presence_CountVectorizer.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.8556149732620321\n",
      "LinearSVC() accuracy: 0.857397504456328\n",
      "RandomForestClassifier() accuracy: 0.8618538324420677\n",
      "MultinomialNB() accuracy: 0.8342245989304813\n",
      "BernoulliNB() accuracy: 0.8458110516934046\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifiers = [LogisticRegression(),LinearSVC(), RandomForestClassifier(), MultinomialNB(), BernoulliNB()]\n",
    "\n",
    "\n",
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(cv.transform(string_test))\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    cm.append(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    " # List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(f\"{classifiers[i]} accuracy: {acc[i]}\")\n",
    "    # print(f\"Confusion Matris: {cm[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8458110516934046\n",
      "Confusion Matrix:\n",
      " [[613  41]\n",
      " [132 336]]\n",
      "[[  0 745]\n",
      " [  1 377]]\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank_test_score  mean_test_score param_alpha param_fit_prior\n",
      "0                1         0.858577           0           False\n",
      "1                2         0.857385           0            True\n",
      "2                3         0.850869           1           False\n",
      "3                4         0.847289           1            True\n",
      "{'alpha': 0, 'fit_prior': False}\n",
      "[[  0 658]\n",
      " [  1 464]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    1.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.8s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bnb_presence_classifier.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- Bernoulli Naive Bayes Classifier ------------------\n",
    "\n",
    "clf_bnb = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_bnb.predict(cv.transform(string_test))\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "\n",
    "# Parameter tunning\n",
    "\n",
    "param_grid = {'alpha': [0, 1],\n",
    "              'fit_prior': [True, False]}\n",
    "\n",
    "gs = GridSearchCV(clf_bnb,param_grid,cv=5,\n",
    "                      verbose = 1, n_jobs = -1)\n",
    "\n",
    "best_bnb = gs.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_bnb.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "print(scores_df[['rank_test_score', 'mean_test_score', 'param_alpha', 'param_fit_prior']])\n",
    "\n",
    "print(best_bnb.best_params_)\n",
    "\n",
    "y_pred_best = best_bnb.predict(cv.transform(string_test))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    " # save the model to local disk\n",
    "\n",
    "joblib.dump(best_bnb, 'bnb_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8672014260249554\n",
      "Confusion Matrix:\n",
      " [[586  68]\n",
      " [ 81 387]]\n",
      "[[  0 667]\n",
      " [  1 455]]\n",
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank_test_score  mean_test_score param_bootstrap param_criterion  \\\n",
      "0                  1         0.879972           False            gini   \n",
      "1                  2         0.879379           False            gini   \n",
      "2                  3         0.876999            True         entropy   \n",
      "3                  4         0.875814            True         entropy   \n",
      "4                  5         0.875217           False         entropy   \n",
      "..               ...              ...             ...             ...   \n",
      "535              536         0.835407            True         entropy   \n",
      "536              537         0.834225            True            gini   \n",
      "537              538         0.833030           False            gini   \n",
      "538              539         0.831850            True            gini   \n",
      "539              540         0.830645            True         entropy   \n",
      "\n",
      "    param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
      "0              None                      1                       5   \n",
      "1              None                      1                       2   \n",
      "2              None                      1                       5   \n",
      "3              None                      1                       2   \n",
      "4              None                      1                      10   \n",
      "..              ...                    ...                     ...   \n",
      "535              10                      4                       5   \n",
      "536              10                      4                      10   \n",
      "537              10                      4                      10   \n",
      "538              10                      4                       5   \n",
      "539              10                      2                       2   \n",
      "\n",
      "    param_n_estimators  \n",
      "0                  100  \n",
      "1                  100  \n",
      "2                  200  \n",
      "3                  300  \n",
      "4                  100  \n",
      "..                 ...  \n",
      "535                200  \n",
      "536                200  \n",
      "537                200  \n",
      "538                200  \n",
      "539                100  \n",
      "\n",
      "[540 rows x 8 columns]\n",
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.8618538324420677\n",
      "Confusion Matrix:\n",
      " [[594  60]\n",
      " [ 95 373]]\n",
      "[[  0 689]\n",
      " [  1 433]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_presence_classifier.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------- Random Forest Classifier -------------\n",
    "clf_rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_rf.predict(cv.transform(string_test))\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'bootstrap':[True,False],\n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[10,20,30,40,None],\n",
    "              'min_samples_leaf':[1,2,4],\n",
    "              'min_samples_split':[2,5,10],\n",
    "              'n_estimators':[100,200,300]}\n",
    "\n",
    "gs = GridSearchCV(clf_rf, param_grid, cv=5,\n",
    "                  verbose=1, n_jobs=-1)\n",
    "\n",
    "best_rf = gs.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_rf.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "print(scores_df [['rank_test_score', 'mean_test_score', 'param_bootstrap', 'param_criterion','param_max_depth','param_min_samples_leaf','param_min_samples_split','param_n_estimators']])\n",
    "\n",
    "print(best_rf.best_params_)\n",
    "\n",
    "y_pred_best = best_rf.predict(cv.transform(string_test))\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_rf, 'rf_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
