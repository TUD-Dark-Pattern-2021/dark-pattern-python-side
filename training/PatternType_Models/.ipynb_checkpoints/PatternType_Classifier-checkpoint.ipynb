{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to encode text, aka tokenize documents, to learn the vocabulary and inverse document frequency weightings.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# systematically compute word counts using CountVectorizer and them compute the Inverse Document Frequency (IDF) values and only then compute the Tf-idf scores.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# MultinomialNB (multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts, however, in practice, fractional counts such as tf-idf may also work.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Pattern Category</th>\n",
       "      <th>Pattern Type</th>\n",
       "      <th>Where in website?</th>\n",
       "      <th>Deceptive?</th>\n",
       "      <th>Website Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collin P. from Grandview Missouri just bought ...</td>\n",
       "      <td>Periodic popup</td>\n",
       "      <td>Social Proof</td>\n",
       "      <td>Activity Notification</td>\n",
       "      <td>Product Page</td>\n",
       "      <td>No</td>\n",
       "      <td>https://alaindupetit.com/collections/all-suits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Faith in Glendale, United States purchased a C...</td>\n",
       "      <td>Periodic popup</td>\n",
       "      <td>Social Proof</td>\n",
       "      <td>Activity Notification</td>\n",
       "      <td>Product Page</td>\n",
       "      <td>No</td>\n",
       "      <td>https://bonescoffee.com/products/strawberry-ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sharmeen Atif From Karachi just bought Stylish...</td>\n",
       "      <td>Periodic popup</td>\n",
       "      <td>Social Proof</td>\n",
       "      <td>Activity Notification</td>\n",
       "      <td>Product Page</td>\n",
       "      <td>No</td>\n",
       "      <td>https://brandsego.com/collections/under-rs-99/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 people are viewing this.</td>\n",
       "      <td>Product detail</td>\n",
       "      <td>Social Proof</td>\n",
       "      <td>Activity Notification</td>\n",
       "      <td>Product Page</td>\n",
       "      <td>No</td>\n",
       "      <td>https://brightechshop.com/products/ambience-so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5338 people viewed this in the last hour</td>\n",
       "      <td>Periodic popup</td>\n",
       "      <td>Social Proof</td>\n",
       "      <td>Activity Notification</td>\n",
       "      <td>Product Page</td>\n",
       "      <td>No</td>\n",
       "      <td>https://bumpboxes.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pattern String         Comment  \\\n",
       "0  Collin P. from Grandview Missouri just bought ...  Periodic popup   \n",
       "1  Faith in Glendale, United States purchased a C...  Periodic popup   \n",
       "2  Sharmeen Atif From Karachi just bought Stylish...  Periodic popup   \n",
       "3                         9 people are viewing this.  Product detail   \n",
       "4           5338 people viewed this in the last hour  Periodic popup   \n",
       "\n",
       "  Pattern Category           Pattern Type Where in website? Deceptive?  \\\n",
       "0     Social Proof  Activity Notification      Product Page         No   \n",
       "1     Social Proof  Activity Notification      Product Page         No   \n",
       "2     Social Proof  Activity Notification      Product Page         No   \n",
       "3     Social Proof  Activity Notification      Product Page         No   \n",
       "4     Social Proof  Activity Notification      Product Page         No   \n",
       "\n",
       "                                        Website Page  \n",
       "0  https://alaindupetit.com/collections/all-suits...  \n",
       "1  https://bonescoffee.com/products/strawberry-ch...  \n",
       "2  https://brandsego.com/collections/under-rs-99/...  \n",
       "3  https://brightechshop.com/products/ambience-so...  \n",
       "4                             https://bumpboxes.com/  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- import dataset from the Princeton Article\n",
    "df = pd.read_csv('dark_patterns.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1818 entries, 0 to 1817\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Pattern String     1512 non-null   object\n",
      " 1   Comment            1798 non-null   object\n",
      " 2   Pattern Category   1818 non-null   object\n",
      " 3   Pattern Type       1818 non-null   object\n",
      " 4   Where in website?  1818 non-null   object\n",
      " 5   Deceptive?         1818 non-null   object\n",
      " 6   Website Page       1818 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 99.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# ---- information of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1512 entries, 0 to 1817\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Pattern String     1512 non-null   object\n",
      " 1   Comment            1494 non-null   object\n",
      " 2   Pattern Category   1512 non-null   object\n",
      " 3   Pattern Type       1512 non-null   object\n",
      " 4   Where in website?  1512 non-null   object\n",
      " 5   Deceptive?         1512 non-null   object\n",
      " 6   Website Page       1512 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# ---- select from the dataset when 'Pattern String' is not NaN values.\n",
    "df = df[pd.notnull(df[\"Pattern String\"])]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>Pattern Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collin P. from Grandview Missouri just bought ...</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Faith in Glendale, United States purchased a C...</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sharmeen Atif From Karachi just bought Stylish...</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 people are viewing this.</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5338 people viewed this in the last hour</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pattern String           Pattern Type\n",
       "0  Collin P. from Grandview Missouri just bought ...  Activity Notification\n",
       "1  Faith in Glendale, United States purchased a C...  Activity Notification\n",
       "2  Sharmeen Atif From Karachi just bought Stylish...  Activity Notification\n",
       "3                         9 people are viewing this.  Activity Notification\n",
       "4           5338 people viewed this in the last hour  Activity Notification"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- select only \"Pattern String\" and \"Pattern Category\" 2 columns to be the sub-dataset.\n",
    "col = [\"Pattern String\", \"Pattern Type\"]\n",
    "df = df[col]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-stock Message                   631\n",
      "Activity Notification               313\n",
      "Confirmshaming                      169\n",
      "Countdown Timer                     149\n",
      "Limited-time Message                 88\n",
      "High-demand Message                  47\n",
      "Pressured Selling                    45\n",
      "Hard to Cancel                       30\n",
      "Visual Interference                  14\n",
      "Trick Questions                       9\n",
      "Hidden Subscription                   6\n",
      "Forced Enrollment                     4\n",
      "Sneak into Basket                     3\n",
      "Hidden Costs                          3\n",
      "Testimonials of Uncertain Origin      1\n",
      "Name: Pattern Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of Pattern Type\n",
    "\n",
    "print(df['Pattern Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>Pattern Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collin P. from Grandview Missouri just bought ...</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Faith in Glendale, United States purchased a C...</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sharmeen Atif From Karachi just bought Stylish...</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 people are viewing this.</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5338 people viewed this in the last hour</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pattern String           Pattern Type\n",
       "0  Collin P. from Grandview Missouri just bought ...  Activity Notification\n",
       "1  Faith in Glendale, United States purchased a C...  Activity Notification\n",
       "2  Sharmeen Atif From Karachi just bought Stylish...  Activity Notification\n",
       "3                         9 people are viewing this.  Activity Notification\n",
       "4           5338 people viewed this in the last hour  Activity Notification"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep the Pattern Type we need to train the model\n",
    "\n",
    "types = ['Low-stock Message','Activity Notification',\n",
    "         'Countdown Timer','Limited-time Message','High-demand Message']\n",
    "\n",
    "data = df[df['Pattern Type'].isin(types)]\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1228 entries, 0 to 1697\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Pattern String  1228 non-null   object\n",
      " 1   Pattern Type    1228 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 28.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the information of the data\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-stock Message        631\n",
      "Activity Notification    313\n",
      "Countdown Timer          149\n",
      "Limited-time Message      88\n",
      "High-demand Message       47\n",
      "Name: Pattern Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of Pattern Type\n",
    "\n",
    "print(data['Pattern Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Activity Notification': 0, 'Countdown Timer': 1, 'High-demand Message': 2, 'Limited-time Message': 3, 'Low-stock Message': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-9099e0b2947f>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"type_id\"] = data['Pattern Type'].factorize()[0]\n"
     ]
    }
   ],
   "source": [
    "# ---- encode the pattern category type into integers (7 types in total, encoded into integers from 0-6).\n",
    "\n",
    "data[\"type_id\"] = data['Pattern Type'].factorize()[0]\n",
    "\n",
    "# ---- Get the mapping of the encoding integers and the pattern categories.\n",
    "# ---- {'Social Proof': 0, 'Misdirection': 1, 'Urgency': 2, 'Forced Action': 3, 'Obstruction': 4, 'Sneaking': 5, 'Scarcity': 6}\n",
    "\n",
    "type_id_df = data[['Pattern Type', 'type_id']\n",
    "                    ].drop_duplicates().sort_values('type_id')\n",
    "type_to_id = dict(type_id_df.values)\n",
    "id_to_type = dict(\n",
    "    type_id_df[['type_id', 'Pattern Type']].values)\n",
    "\n",
    "\n",
    "# ---- result of the mapping\n",
    "\n",
    "print(type_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 195)\n"
     ]
    }
   ],
   "source": [
    "# ---- convert a collection of raw documents to a matrix of TF-IDF features; Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "# 'sublinear_tf=True' is used to normalise bias of term frequency (\"where a term that is more frequent shouldn't be X times as important\"). It is set to True to use a logarithmic form for frequency.\n",
    "# 'norm='l2'' is the default setting of 'norm', used to reduce document length bias, to ensure all our feature vectors have a enclidian norm of 1.\n",
    "# 'min_df=5', means when building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold (which is 5 here), which is the minimum numbers of documents a word must be present in to be kept.\n",
    "# 'ngram_range=(1,2)' means unigrams and bigrams will be extracted, means we want to consider both unigrams and bigrams.\n",
    "# 'stop_words='english'', if a string, it is passed to _check_stop_list and the appropriate stop list is returned. To remove all common pronouns (\"a\", \"the\" ...), reducing the number of noisy features.\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(data['Pattern String']).toarray()\n",
    "labels = data.type_id\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern Type: 'Activity Notification':\n",
      "  . Most correlated unigrams:\n",
      "     . bought\n",
      "     . left\n",
      "     . purchased\n",
      "  . Most correlated bigrams:\n",
      "     . just bought\n",
      "     . states purchased\n",
      "     . united states\n",
      "Pattern Type: 'Countdown Timer':\n",
      "  . Most correlated unigrams:\n",
      "     . minutes\n",
      "     . 09\n",
      "     . ends\n",
      "  . Most correlated bigrams:\n",
      "     . sale ends\n",
      "     . reserved 09\n",
      "     . order reserved\n",
      "Pattern Type: 'High-demand Message':\n",
      "  . Most correlated unigrams:\n",
      "     . worries\n",
      "     . high\n",
      "     . demand\n",
      "  . Most correlated bigrams:\n",
      "     . ordered high\n",
      "     . reserved order\n",
      "     . high demand\n",
      "Pattern Type: 'Limited-time Message':\n",
      "  . Most correlated unigrams:\n",
      "     . offer\n",
      "     . limited\n",
      "     . time\n",
      "  . Most correlated bigrams:\n",
      "     . free shipping\n",
      "     . time offer\n",
      "     . limited time\n",
      "Pattern Type: 'Low-stock Message':\n",
      "  . Most correlated unigrams:\n",
      "     . purchased\n",
      "     . stock\n",
      "     . left\n",
      "  . Most correlated bigrams:\n",
      "     . hurry left\n",
      "     . limited time\n",
      "     . left stock\n"
     ]
    }
   ],
   "source": [
    "# The result means each of the 1512 pattern strings is represented by 303 features, representing the tf-idf score for different unigrams and bigrams.\n",
    "\n",
    "N = 3   # every n-gram will give 3 examples\n",
    "\n",
    "for Type, type_id in sorted(type_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == type_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"Pattern Type: '{}':\".format(Type))\n",
    "  print(\"  . Most correlated unigrams:\\n     . {}\".format('\\n     . '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n     . {}\".format('\\n     . '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Preparation\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Split the dataset into training and testing ------\n",
    "String_train, String_test, Type_train, Type_test = train_test_split(\n",
    "    data['Pattern String'], data['Pattern Type'], train_size=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-stock Message        378\n",
      "Activity Notification    183\n",
      "Countdown Timer           96\n",
      "Limited-time Message      50\n",
      "High-demand Message       29\n",
      "Name: Pattern Type, dtype: int64\n",
      "Low-stock Message        253\n",
      "Activity Notification    130\n",
      "Countdown Timer           53\n",
      "Limited-time Message      38\n",
      "High-demand Message       18\n",
      "Name: Pattern Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of training data\n",
    "\n",
    "print(Type_train.value_counts())\n",
    "\n",
    "# Distribution of testing data\n",
    "\n",
    "print(Type_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Activity Notification', 'Countdown Timer', 'High-demand Message', 'Limited-time Message', 'Low-stock Message']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Type_train)\n",
    "y_train = encoder.transform(Type_train)\n",
    "y_test = encoder.transform(Type_test)\n",
    "\n",
    "# check the mapping of encoding results (from 0 to 6 representing 'Forced Action', 'Misdirection'......)\n",
    "\n",
    "print(list(encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Activity Notification' 183]\n",
      " ['Countdown Timer' 96]\n",
      " ['High-demand Message' 29]\n",
      " ['Limited-time Message' 50]\n",
      " ['Low-stock Message' 378]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the training pattern category with pattern category names.\n",
    "\n",
    "(unique, counts) = np.unique(Type_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 183]\n",
      " [  1  96]\n",
      " [  2  29]\n",
      " [  3  50]\n",
      " [  4 378]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded training pattern category with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 130]\n",
      " [  1  53]\n",
      " [  2  18]\n",
      " [  3  38]\n",
      " [  4 253]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded testing pattern category with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Encoding\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word count vector of the pattern string to encode the pattern string.\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(String_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_CountVectorizer.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# save the CountVectorizer to disk\n",
    "joblib.dump(cv, 'category_CountVectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.975609756097561\n",
      "Confusion Matris: [[127   1   0   2   0]\n",
      " [  0  51   0   0   2]\n",
      " [  1   1  16   0   0]\n",
      " [  0   2   0  36   0]\n",
      " [  1   2   0   0 250]]\n",
      "LinearSVC() accuracy: 0.967479674796748\n",
      "Confusion Matris: [[127   1   0   1   1]\n",
      " [  0  50   0   1   2]\n",
      " [  0   1  16   0   1]\n",
      " [  0   1   0  35   2]\n",
      " [  1   3   0   1 248]]\n",
      "RandomForestClassifier() accuracy: 0.9735772357723578\n",
      "Confusion Matris: [[128   1   0   1   0]\n",
      " [  0  50   0   0   3]\n",
      " [  1   1  16   0   0]\n",
      " [  0   2   0  35   1]\n",
      " [  1   2   0   0 250]]\n",
      "DecisionTreeClassifier() accuracy: 0.9573170731707317\n",
      "Confusion Matris: [[124   4   1   0   1]\n",
      " [  3  47   1   0   2]\n",
      " [  0   1  16   0   1]\n",
      " [  0   1   0  35   2]\n",
      " [  3   1   0   0 249]]\n",
      "MultinomialNB() accuracy: 0.9654471544715447\n",
      "Confusion Matris: [[126   0   0   2   2]\n",
      " [  0  47   0   1   5]\n",
      " [  1   1  16   0   0]\n",
      " [  0   1   0  35   2]\n",
      " [  0   1   1   0 251]]\n"
     ]
    }
   ],
   "source": [
    "# Five models are tested:\n",
    "# -- Logistic Regression\n",
    "# -- Linear Support Vector Machine\n",
    "# -- Random Forest\n",
    "# -- Decision Tree\n",
    "# -- Multinomial Naive Bayes\n",
    "\n",
    "classifiers = [LogisticRegression(),LinearSVC(), RandomForestClassifier(), DecisionTreeClassifier(), MultinomialNB()]\n",
    "\n",
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(cv.transform(String_test))\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    cm.append(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(f\"{classifiers[i]} accuracy: {acc[i]}\")\n",
    "    print(f\"Confusion Matris: {cm[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Accuracy:0.975609756097561\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 129]\n",
      " [  1  57]\n",
      " [  2  16]\n",
      " [  3  38]\n",
      " [  4 252]]\n",
      "\n",
      "Confusion Matrix of the result:[[127   1   0   2   0]\n",
      " [  0  51   0   0   2]\n",
      " [  1   1  16   0   0]\n",
      " [  0   2   0  36   0]\n",
      " [  1   2   0   0 250]]\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.2s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.974177</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.970105</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.970105</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_solver\n",
       "0                1         0.974177            l2          sag\n",
       "1                2         0.970105            l2        lbfgs\n",
       "2                2         0.970105            l2    newton-cg\n",
       "3                4              NaN            l1        lbfgs\n",
       "4                5              NaN            l1    newton-cg\n",
       "5                6              NaN            l1          sag"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_lr.get_params()))\n",
    "\n",
    "y_pred = clf_lr.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}\\n'.format(frequencies))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of the result:{}\\n'.format(cm))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'penalty':['l1','l2'], \n",
    "              'solver':['lbfgs','newton-cg','sag']}\n",
    "\n",
    "gs = GridSearchCV(clf_lr, param_grid, cv=5,\n",
    "                  verbose=1, n_jobs=-1)\n",
    "\n",
    "best_lr = gs.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_lr.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_solver']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'penalty': 'l2', 'solver': 'sag'}\n",
      "\n",
      "Accuracy:0.9735772357723578\n",
      "\n",
      "The distribution of predicted result of best model:[[  0 129]\n",
      " [  1  56]\n",
      " [  2  16]\n",
      " [  3  39]\n",
      " [  4 252]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lr_category_classifier.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters of the best model\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(best_lr.best_params_))\n",
    "\n",
    "y_pred_best = best_lr.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of best model:{}'.format(frequencies))\n",
    "\n",
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_lr, 'lr_category_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Accuracy:0.9715447154471545\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 130]\n",
      " [  1  58]\n",
      " [  2  15]\n",
      " [  3  36]\n",
      " [  4 253]]\n",
      "\n",
      "Confusion Matrix of the result:[[127   2   0   1   0]\n",
      " [  0  51   0   0   2]\n",
      " [  2   1  15   0   0]\n",
      " [  0   2   0  35   1]\n",
      " [  1   2   0   0 250]]\n",
      "\n",
      "Fitting 5 folds for each of 2376 candidates, totalling 11880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6026 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8426 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9776 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11226 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11880 out of 11880 | elapsed: 25.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.978250</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.978250</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.976898</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.976898</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.976898</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>2372</td>\n",
       "      <td>0.846442</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>2373</td>\n",
       "      <td>0.846415</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>2374</td>\n",
       "      <td>0.845155</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>2375</td>\n",
       "      <td>0.845109</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>2376</td>\n",
       "      <td>0.842361</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2376 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank_test_score  mean_test_score param_bootstrap param_criterion  \\\n",
       "0                   1         0.978250           False            gini   \n",
       "1                   1         0.978250            True            gini   \n",
       "2                   3         0.976898            True            gini   \n",
       "3                   4         0.976898           False         entropy   \n",
       "4                   4         0.976898           False            gini   \n",
       "...               ...              ...             ...             ...   \n",
       "2371             2372         0.846442            True         entropy   \n",
       "2372             2373         0.846415            True            gini   \n",
       "2373             2374         0.845155            True         entropy   \n",
       "2374             2375         0.845109            True            gini   \n",
       "2375             2376         0.842361            True            gini   \n",
       "\n",
       "     param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0                 50                      1                       2   \n",
       "1                100                      1                       2   \n",
       "2                 60                      1                       2   \n",
       "3                 60                      1                       2   \n",
       "4                 60                      1                       2   \n",
       "...              ...                    ...                     ...   \n",
       "2371              10                      4                       2   \n",
       "2372              10                      4                       2   \n",
       "2373              60                      4                       2   \n",
       "2374              10                      4                       2   \n",
       "2375              10                      4                      10   \n",
       "\n",
       "     param_n_estimators  \n",
       "0                   300  \n",
       "1                   100  \n",
       "2                   200  \n",
       "3                   500  \n",
       "4                   500  \n",
       "...                 ...  \n",
       "2371                300  \n",
       "2372                500  \n",
       "2373                100  \n",
       "2374                200  \n",
       "2375                200  \n",
       "\n",
       "[2376 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_rf.get_params()))\n",
    "\n",
    "y_pred = clf_rf.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}\\n'.format(frequencies))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of the result:{}\\n'.format(cm))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'bootstrap':[True,False], \n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[10,20,30,40,50,60,70,80,90,100, None],\n",
    "              'min_samples_leaf':[1,2,4],\n",
    "              'min_samples_split':[2,5,10],\n",
    "              'n_estimators':[100,200,300,400,500,600]}\n",
    "\n",
    "gs = GridSearchCV(clf_rf, param_grid, cv=5,\n",
    "                  verbose=1, n_jobs=-1)\n",
    "\n",
    "best_rf = gs.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_rf.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_bootstrap', 'param_criterion',\n",
    "            'param_max_depth','param_min_samples_leaf','param_min_samples_split','param_n_estimators']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Accuracy:0.967479674796748\n",
      "\n",
      "The distribution of predicted result of best model:[[  0 127]\n",
      " [  1  57]\n",
      " [  2  16]\n",
      " [  3  39]\n",
      " [  4 253]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_category_classifier.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters of the best model\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(best_rf.best_params_))\n",
    "\n",
    "y_pred_best = best_rf.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of best model:{}'.format(frequencies))\n",
    "\n",
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_rf, 'rf_category_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Accuracy:0.967479674796748\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 128]\n",
      " [  1  56]\n",
      " [  2  16]\n",
      " [  3  38]\n",
      " [  4 254]]\n",
      "\n",
      "Confusion Matrix of the result:[[127   1   0   1   1]\n",
      " [  0  50   0   1   2]\n",
      " [  0   1  16   0   1]\n",
      " [  0   1   0  35   2]\n",
      " [  1   3   0   1 248]]\n",
      "\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank_test_score  mean_test_score param_penalty param_C\n",
      "0                1         0.978259            l2       5\n",
      "1                1         0.978259            l2      10\n",
      "2                3         0.976898            l2       1\n",
      "3                4         0.971465            l2     0.1\n",
      "4                5              NaN            l1     0.1\n",
      "5                6              NaN            l1       1\n",
      "6                7              NaN            l1       5\n",
      "7                8              NaN            l1      10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "clf_svm = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_svm.get_params()))\n",
    "\n",
    "y_pred = clf_svm.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}\\n'.format(frequencies))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of the result:{}\\n'.format(cm))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.1, 1, 5, 10]}\n",
    "\n",
    "gs = GridSearchCV(clf_svm, param_grid, cv=5,\n",
    "                  verbose=1, n_jobs=-1)\n",
    "\n",
    "best_svm = gs.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_svm.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "print(scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_C']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'C': 5, 'penalty': 'l2'}\n",
      "\n",
      "Accuracy:0.9715447154471545\n",
      "\n",
      "The distribution of predicted result of best model:[[  0 128]\n",
      " [  1  56]\n",
      " [  2  16]\n",
      " [  3  39]\n",
      " [  4 253]]\n"
     ]
    }
   ],
   "source": [
    "print('Parameters of the classifier:\\n{}\\n'.format(best_svm.best_params_))\n",
    "\n",
    "y_pred_best = best_svm.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of best model:{}'.format(frequencies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_category_classifier.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_svm, 'svm_category_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n",
      "\n",
      "Accuracy:0.9654471544715447\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 127]\n",
      " [  1  50]\n",
      " [  2  17]\n",
      " [  3  38]\n",
      " [  4 260]]\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    2.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_fit_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966051</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.957933</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.955157</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.953806</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_alpha param_fit_prior\n",
       "0                1         0.966051           1            True\n",
       "1                2         0.957933           1           False\n",
       "2                3         0.955157           0            True\n",
       "3                4         0.953806           0           False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mnb = MultinomialNB().fit(X_train, y_train)\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_mnb.get_params()))\n",
    "\n",
    "y_pred = clf_mnb.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}'.format(frequencies))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'alpha':[0,1],\n",
    "              'fit_prior':[True, False]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(clf_mnb,param_grid,cv=5,\n",
    "                      verbose = 1, n_jobs = -1)\n",
    "\n",
    "best_mnb = gs.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_mnb.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_alpha', 'param_fit_prior']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9654471544715447\n",
      "\n",
      "The distribution of predicted result of the best model:[[  0 127]\n",
      " [  1  50]\n",
      " [  2  17]\n",
      " [  3  38]\n",
      " [  4 260]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mnb_category_classifier.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_best = best_mnb.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of the best model:{}'.format(frequencies))\n",
    "\n",
    " # save the model to local disk\n",
    "\n",
    "joblib.dump(best_mnb, 'mnb_category_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
