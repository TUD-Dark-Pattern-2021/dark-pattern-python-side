{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import metrics\n",
    "\n",
    "#!pip install h5py pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3694 entries, 0 to 3693\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         3694 non-null   object\n",
      " 1   Classification  3694 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 57.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('test_data.csv')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your price for this item is $ 89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your price for this item is $ 79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your price for this item is $ 55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your price for this item is $ 49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your price for this item is $ 21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            content  Classification\n",
       "0  Your price for this item is $ 89               1\n",
       "1  Your price for this item is $ 79               1\n",
       "2  Your price for this item is $ 55               1\n",
       "3  Your price for this item is $ 49               1\n",
       "4  Your price for this item is $ 21               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['content'].values\n",
    "Y = data['Classification'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding mapping: {0: 0, 1: 1}\n",
      "\n",
      "The frequency distribution of testing y labels:\n",
      " [[   0  350]\n",
      " [   1 3344]]\n",
      "The frequency distribution of testing encoded y labels:\n",
      " [[   0  350]\n",
      " [   1 3344]]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "y = encoder.transform(Y)\n",
    "\n",
    "# check the mapping of encoding results (from 0 to 1 representing 'Dark', 'Not Dark')\n",
    "\n",
    "integer_mapping = {label: encoding for encoding, label in enumerate(encoder.classes_)}\n",
    "print(\"Label encoding mapping: {}\\n\".format(integer_mapping))\n",
    "\n",
    "(unique, counts) = np.unique(Y, return_counts=True)\n",
    "frequencies_y_label = np.asarray((unique, counts)).T\n",
    "\n",
    "print('The frequency distribution of testing y labels:\\n',frequencies_y_label)\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies_y_encode_label = np.asarray((unique, counts)).T\n",
    "\n",
    "print('The frequency distribution of testing encoded y labels:\\n',frequencies_y_encode_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Test the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Embedding on the Fly --- Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: \n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 20)            100000    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 19, 64)            2624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 104,737\n",
      "Trainable params: 104,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[   0  368]\n",
      " [   1 3326]]\n",
      "Confusion Matrix of the prediction results:\n",
      " [[ 344    6]\n",
      " [  24 3320]]\n",
      "\n",
      "Precison: 0.935\n",
      "Recall: 0.983\n",
      "F1 Score: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# ---- Load the vectorizer\n",
    "cv = joblib.load(\"V10/EmbOTF_HO/Presence_Tokenizer.joblib\")\n",
    "\n",
    "# ---- Load the model\n",
    "clf = keras.models.load_model('V10/EmbOTF_HO/CNN_model1.h5')\n",
    "\n",
    "print('Model Summary: \\n')\n",
    "print(clf.summary())\n",
    "\n",
    "# ---- Text Vectorization\n",
    "# Vectorization\n",
    "content = cv.texts_to_sequences(data['content'])\n",
    "# Padding\n",
    "maxlen = 20\n",
    "pad_content = pad_sequences(content, padding='post', maxlen=maxlen)\n",
    "\n",
    "# ---- Make Prediction\n",
    "pred = clf.predict_classes(pad_content)\n",
    "pred_list = pred.flatten()\n",
    "\n",
    "data['prediction'] = pred_list.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-EmbOTF-model1.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-EmbOTF-model1.csv', index = False, header = True)\n",
    "\n",
    "# ---- Print out the prediction distribution\n",
    "(unique, counts) = np.unique(pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "# ---- Evaluation metrics\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred, labels=[0,1])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Embedding on the Fly --- Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: \n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 20, 20)            100000    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 19, 32)            1312      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 102,401\n",
      "Trainable params: 102,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[   0  359]\n",
      " [   1 3335]]\n",
      "Confusion Matrix of the prediction results:\n",
      " [[ 343    7]\n",
      " [  16 3328]]\n",
      "\n",
      "Precison: 0.955\n",
      "Recall: 0.980\n",
      "F1 Score: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# ---- Load the vectorizer\n",
    "cv = joblib.load(\"V10/EmbOTF_HO/Presence_Tokenizer.joblib\")\n",
    "\n",
    "# ---- Load the model\n",
    "clf = keras.models.load_model('V10/EmbOTF_HO/CNN_model2.h5')\n",
    "\n",
    "print('Model Summary: \\n')\n",
    "print(clf.summary())\n",
    "\n",
    "# ---- Text Vectorization\n",
    "# Vectorization\n",
    "content = cv.texts_to_sequences(data['content'])\n",
    "# Padding\n",
    "maxlen = 20\n",
    "pad_content = pad_sequences(content, padding='post', maxlen=maxlen)\n",
    "\n",
    "# ---- Make Prediction\n",
    "pred = clf.predict_classes(pad_content)\n",
    "pred_list = pred.flatten()\n",
    "\n",
    "data['prediction'] = pred_list.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-EmbOTF-model2.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-EmbOTF-model2.csv', index = False, header = True)\n",
    "\n",
    "# ---- Print out the prediction distribution\n",
    "(unique, counts) = np.unique(pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "# ---- Evaluation metrics\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred, labels=[0,1])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Embedding on the Fly --- Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: \n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 20, 20)            100000    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 20, 32)            672       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 101,761\n",
      "Trainable params: 101,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[   0  377]\n",
      " [   1 3317]]\n",
      "Confusion Matrix of the prediction results:\n",
      " [[ 343    7]\n",
      " [  34 3310]]\n",
      "\n",
      "Precison: 0.910\n",
      "Recall: 0.980\n",
      "F1 Score: 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# ---- Load the vectorizer\n",
    "cv = joblib.load(\"V10/EmbOTF_HO/Presence_Tokenizer.joblib\")\n",
    "\n",
    "# ---- Load the model\n",
    "clf = keras.models.load_model('V10/EmbOTF_HO/CNN_model3.h5')\n",
    "\n",
    "print('Model Summary: \\n')\n",
    "print(clf.summary())\n",
    "\n",
    "# ---- Text Vectorization\n",
    "# Vectorization\n",
    "content = cv.texts_to_sequences(data['content'])\n",
    "# Padding\n",
    "maxlen = 20\n",
    "pad_content = pad_sequences(content, padding='post', maxlen=maxlen)\n",
    "\n",
    "# ---- Make Prediction\n",
    "pred = clf.predict_classes(pad_content)\n",
    "pred_list = pred.flatten()\n",
    "\n",
    "data['prediction'] = pred_list.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-EmbOTF-model3.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-EmbOTF-model3.csv', index = False, header = True)\n",
    "\n",
    "# ---- Print out the prediction distribution\n",
    "(unique, counts) = np.unique(pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "# ---- Evaluation metrics\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred, labels=[0,1])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Pre-trained Embedding --- Cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: \n",
      "\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 300)         1706100   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 64)          38464     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,746,677\n",
      "Trainable params: 40,577\n",
      "Non-trainable params: 1,706,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[   0  257]\n",
      " [   1 3437]]\n",
      "Confusion Matrix of the prediction results:\n",
      " [[ 254   96]\n",
      " [   3 3341]]\n",
      "\n",
      "Precison: 0.988\n",
      "Recall: 0.726\n",
      "F1 Score: 0.837\n"
     ]
    }
   ],
   "source": [
    "# ---- Load the vectorizer\n",
    "cv = joblib.load(\"V10/PreEmb_HO/Cased/Presence_Tokenizer.joblib\")\n",
    "\n",
    "# ---- Load the model\n",
    "clf = keras.models.load_model('V10/PreEmb_HO/Cased/model_preEmb_CNN1.h5')\n",
    "\n",
    "print('Model Summary: \\n')\n",
    "print(clf.summary())\n",
    "\n",
    "# ---- Text Vectorization\n",
    "# Vectorization\n",
    "content = cv.texts_to_sequences(data['content'])\n",
    "# Padding\n",
    "maxlen = 20\n",
    "pad_content = pad_sequences(content, padding='post', maxlen=maxlen)\n",
    "\n",
    "# ---- Make Prediction\n",
    "prediction = clf.predict(pad_content)\n",
    "pred = (prediction>0.5).astype('int32')\n",
    "pred_list = pred.flatten()\n",
    "\n",
    "data['prediction'] = pred_list.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-PreEmb-Cased.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-PreEmb-Cased.csv', index = False, header = True)\n",
    "\n",
    "# ---- Print out the prediction distribution\n",
    "(unique, counts) = np.unique(pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "# ---- Evaluation metrics\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred, labels=[0,1])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Pre-trained Embedding --- Uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: \n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         1706100   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 64)          38464     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,746,677\n",
      "Trainable params: 40,577\n",
      "Non-trainable params: 1,706,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[   0  280]\n",
      " [   1 3414]]\n",
      "Confusion Matrix of the prediction results:\n",
      " [[ 275   75]\n",
      " [   5 3339]]\n",
      "\n",
      "Precison: 0.982\n",
      "Recall: 0.786\n",
      "F1 Score: 0.873\n"
     ]
    }
   ],
   "source": [
    "# ---- Load the vectorizer\n",
    "cv = joblib.load(\"V10/PreEmb_HO/Uncased/Presence_Tokenizer.joblib\")\n",
    "\n",
    "# ---- Load the model\n",
    "clf = keras.models.load_model('V10/PreEmb_HO/Uncased/model_preEmb_CNN1.h5')\n",
    "\n",
    "print('Model Summary: \\n')\n",
    "print(clf.summary())\n",
    "\n",
    "# ---- Text Vectorization\n",
    "# Vectorization\n",
    "content = cv.texts_to_sequences(data['content'].str.lower())\n",
    "# Padding\n",
    "maxlen = 20\n",
    "pad_content = pad_sequences(content, padding='post', maxlen=maxlen)\n",
    "\n",
    "# ---- Make Prediction\n",
    "prediction = clf.predict(pad_content)\n",
    "pred = (prediction>0.5).astype('int32')\n",
    "pred_list = pred.flatten()\n",
    "\n",
    "data['prediction'] = pred_list.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/V10-PreEmb-Uncased.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/V10-PreEmb-Uncased.csv', index = False, header = True)\n",
    "\n",
    "# ---- Print out the prediction distribution\n",
    "(unique, counts) = np.unique(pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "# ---- Evaluation metrics\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred, labels=[0,1])\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print('Confusion Matrix of the prediction results:\\n', cm)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# DP Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: \n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         1706100   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 64)          38464     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,746,677\n",
      "Trainable params: 40,577\n",
      "Non-trainable params: 1,706,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:11 out of the last 126 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb07fc64c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Load the vectorizer\n",
    "cv = joblib.load(\"V10/PreEmb_HO/Uncased/Presence_Tokenizer.joblib\")\n",
    "\n",
    "# ---- Load the model\n",
    "clf = keras.models.load_model('V10/PreEmb_HO/Uncased/model_preEmb_CNN1.h5')\n",
    "\n",
    "print('Model Summary: \\n')\n",
    "print(clf.summary())\n",
    "\n",
    "# ---- Text Vectorization\n",
    "# Vectorization\n",
    "content = cv.texts_to_sequences(pd.Series('ends soon'))\n",
    "# Padding\n",
    "maxlen = 20\n",
    "pad_content = pad_sequences(content, padding='post', maxlen=maxlen)\n",
    "\n",
    "# ---- Make Prediction\n",
    "prediction = clf.predict(pad_content)\n",
    "pred = (prediction<0.5).astype('int32')\n",
    "pred_list = pred.flatten()\n",
    "\n",
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
