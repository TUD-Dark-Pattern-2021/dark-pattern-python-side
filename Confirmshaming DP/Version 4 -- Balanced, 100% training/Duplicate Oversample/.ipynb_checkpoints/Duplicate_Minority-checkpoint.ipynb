{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Formation\n",
    "\n",
    "Given a Pattern String as an input, we want to know if it contains dark pattern in it. We use a balanced dataset cotaining all the instances in the Princeton dataset which are all dark patterns, and the instances in the 'normie.csv' file which are labeled as NOT dark patterns. Hence we have a balanced dataset consisting of pattern strings with dark pattern and without park patterns.\n",
    "\n",
    "Then we use this labeled dataset to build and train supervised machine learning models, and select most suitable ones for our project.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "---\n",
    "Import the merged dataset, and explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('enriched_confirm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ends in 07:42:09</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ends in 07:37:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ends in 02:27:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ends in 04:17:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ends in 01:57:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pattern String classification\n",
       "0  Ends in 07:42:09       Not_Dark\n",
       "1  Ends in 07:37:10       Not_Dark\n",
       "2  Ends in 02:27:10       Not_Dark\n",
       "3  Ends in 04:17:10       Not_Dark\n",
       "4  Ends in 01:57:10       Not_Dark"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`check the dataset information`\n",
    "\n",
    "There are 7952 NOT NULL instances of pattern strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8187 entries, 0 to 8186\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Pattern String  8187 non-null   object\n",
      " 1   classification  8187 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 128.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "Not_Dark    7994\n",
      "Dark         193\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the content into lowercase\n",
    "\n",
    "data['Pattern String'] = data['Pattern String'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the tags:\n",
      "Not_Dark    7755\n",
      "Dark         180\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For later training the model, we should remove the duplicate input to reduce overfitting.\n",
    "\n",
    "data = data.drop_duplicates(subset=\"Pattern String\")\n",
    "\n",
    "print('\\nDistribution of the tags:\\n{}'.format(data['classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ends in 07:42:09</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ends in 07:37:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ends in 02:27:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ends in 04:17:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ends in 01:57:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pattern String classification\n",
       "0  ends in 07:42:09       Not_Dark\n",
       "1  ends in 07:37:10       Not_Dark\n",
       "2  ends in 02:27:10       Not_Dark\n",
       "3  ends in 04:17:10       Not_Dark\n",
       "4  ends in 01:57:10       Not_Dark"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='classification'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution graph\n",
    "\n",
    "target = data.groupby('classification')['classification'].count()\n",
    "target.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Pattern String']\n",
    "Y = data[\"classification\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the target vales into integers` --- 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "y = encoder.transform(Y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dark': 0, 'Not_Dark': 1}\n"
     ]
    }
   ],
   "source": [
    "# check the mapping of encoding results (from 0 to 1 representing 'Dark', 'Not Dark')\n",
    "\n",
    "integer_mapping = {label: encoding for encoding, label in enumerate(encoder.classes_)}\n",
    "print(integer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  180]\n",
      " [   1 7755]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded testing pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the textual features into series of vector of numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the word count vector of the pattern string to encode the pattern string.\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "x = tv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presence_TfidfVectorizer.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the CountVectorizer to disk\n",
    "\n",
    "joblib.dump(tv, 'presence_TfidfVectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## RandomOverSampler\n",
    "\n",
    "Random versampling involves randomly duplicating examples from the minority class and adding them to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy = 'minority', random_state = 22)\n",
    "\n",
    "x_ros, y_ros = ros.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (15510, 6350), numpy.ndarray, (15510,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_ros), x_ros.shape, type(y_ros), y_ros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 7755]\n",
      " [   1 7755]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded training pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_ros, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Rough Idea about the effect of different classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four models are tested:\n",
    "# -- Logistic Regression\n",
    "# -- Linear Support Vector Machine\n",
    "# -- Random Forest\n",
    "# -- Bernoulli Naive Bayes\n",
    "\n",
    "classifiers = [LogisticRegression(), LinearSVC(), RandomForestClassifier(), BernoulliNB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### `Using Not Oversampled Training Data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "pre = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    y_pred = cross_val_predict(clf, x, y, cv=5, n_jobs = -1)\n",
    "    acc.append(metrics.accuracy_score(y, y_pred))\n",
    "    pre.append(metrics.precision_score(y,y_pred, pos_label=0))\n",
    "    cm.append(metrics.confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.991\n",
      "LogisticRegression() precision: 0.982\n",
      "Confusion Matrix: [[ 111   69]\n",
      " [   2 7753]]\n",
      "LinearSVC() accuracy: 0.995\n",
      "LinearSVC() precision: 0.955\n",
      "Confusion Matrix: [[ 150   30]\n",
      " [   7 7748]]\n",
      "RandomForestClassifier() accuracy: 0.996\n",
      "RandomForestClassifier() precision: 0.980\n",
      "Confusion Matrix: [[ 150   30]\n",
      " [   3 7752]]\n",
      "BernoulliNB() accuracy: 0.976\n",
      "BernoulliNB() precision: 0.067\n",
      "Confusion Matrix: [[   1  179]\n",
      " [  14 7741]]\n"
     ]
    }
   ],
   "source": [
    "# List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(\"{} accuracy: {:.3f}\".format(classifiers[i],acc[i]))\n",
    "    print(\"{} precision: {:.3f}\".format(classifiers[i],pre[i]))\n",
    "    print(\"Confusion Matrix: {}\".format(cm[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### `Using Oversampled Training Data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "pre = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    y_pred = cross_val_predict(clf, x_ros, y_ros, cv=5, n_jobs = -1)\n",
    "    acc.append(metrics.accuracy_score(y_ros, y_pred))\n",
    "    pre.append(metrics.precision_score(y_ros,y_pred, pos_label=0))\n",
    "    cm.append(metrics.confusion_matrix(y_ros, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.999\n",
      "LogisticRegression() precision: 0.998\n",
      "Confusion Matrix: [[7755    0]\n",
      " [  15 7740]]\n",
      "LinearSVC() accuracy: 0.999\n",
      "LinearSVC() precision: 0.997\n",
      "Confusion Matrix: [[7755    0]\n",
      " [  21 7734]]\n",
      "RandomForestClassifier() accuracy: 0.999\n",
      "RandomForestClassifier() precision: 0.998\n",
      "Confusion Matrix: [[7755    0]\n",
      " [  12 7743]]\n",
      "BernoulliNB() accuracy: 0.991\n",
      "BernoulliNB() precision: 0.984\n",
      "Confusion Matrix: [[7747    8]\n",
      " [ 125 7630]]\n"
     ]
    }
   ],
   "source": [
    "# List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(\"{} accuracy: {:.3f}\".format(classifiers[i],acc[i]))\n",
    "    print(\"{} precision: {:.3f}\".format(classifiers[i],pre[i]))\n",
    "    print(\"Confusion Matrix: {}\".format(cm[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bernoulli Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bnb = BernoulliNB()\n",
    "\n",
    "y_pred = cross_val_predict(clf_bnb, x_ros, y_ros, cv=5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bnb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Bernoulli Naive Bayes classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991424887169568\n",
      "Precision: 0.9841209349593496\n",
      "Confusion Matrix:\n",
      " [[7747    8]\n",
      " [ 125 7630]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_ros, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_ros,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_ros, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precison: 0.984\n",
      "Recall: 0.999\n",
      "F1 Score: 0.991\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_ros, y_pred)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 7872],\n",
       "       [   1, 7638]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of BernoulliNB classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0,1], \n",
    "              'fit_prior':[True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_bnb,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:555: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_bnb = gs.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_fit_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995487</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995487</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_alpha param_fit_prior\n",
       "0                1         0.995487           0            True\n",
       "1                1         0.995487           0           False\n",
       "2                3         0.991425           1            True\n",
       "3                3         0.991425           1           False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_bnb.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_alpha', 'param_fit_prior']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0, 'fit_prior': True}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:555: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use the best hyperparamter setting to fit on the whole dataset\n",
    "bnb_model = best_bnb.best_estimator_.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best BernoulliNB model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bnb_presence_classifier.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(bnb_model, 'bnb_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SVM Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = LinearSVC()\n",
    "\n",
    "y_pred = cross_val_predict(clf_svm, x_ros, y_ros, cv=5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': True,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Random Forest classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9986460348162476\n",
      "Precision: 0.9972993827160493\n",
      "Confusion Matrix:\n",
      " [[7755    0]\n",
      " [  21 7734]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_ros, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_ros,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_ros, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precison: 0.997\n",
      "Recall: 1.000\n",
      "F1 Score: 0.999\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_ros, y_pred)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 7776],\n",
       "       [   1, 7734]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of SVM classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.1,1,10,100],\n",
    "              'penalty':['l1','l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_svm,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.99903288        nan 0.99864603        nan 0.99838814\n",
      "        nan 0.99813024]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_svm = gs.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.998646</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.998130</td>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_C\n",
       "0                1         0.999033            l2     0.1\n",
       "1                2         0.998646            l2       1\n",
       "2                3         0.998388            l2      10\n",
       "3                4         0.998130            l2     100\n",
       "4                5              NaN            l1     0.1\n",
       "5                6              NaN            l1       1\n",
       "6                7              NaN            l1      10\n",
       "7                8              NaN            l1     100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_svm.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best hyperparamter setting to fit on the whole dataset\n",
    "svm_model = best_svm.best_estimator_.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best SVM model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_presence_classifier.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(svm_model, 'svm_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression()\n",
    "\n",
    "y_pred = cross_val_predict(clf_lr, x_ros, y_ros, cv=5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Logistic Regression classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9990328820116054\n",
      "Precision: 0.9980694980694981\n",
      "Confusion Matrix:\n",
      " [[7755    0]\n",
      " [  15 7740]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_ros, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_ros,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_ros, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precison: 0.998\n",
      "Recall: 1.000\n",
      "F1 Score: 0.999\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_ros, y_pred)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 7770],\n",
       "       [   1, 7740]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of Logistic Regression classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty':['l1','l2'], \n",
    "              'solver':['lbfgs','newton-cg','sag']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_lr,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.99903288 0.99903288 0.99903288]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_lr = gs.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_solver\n",
       "0                1         0.999033            l2        lbfgs\n",
       "1                1         0.999033            l2    newton-cg\n",
       "2                1         0.999033            l2          sag\n",
       "3                4              NaN            l1        lbfgs\n",
       "4                5              NaN            l1    newton-cg\n",
       "5                6              NaN            l1          sag"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_lr.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_solver']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best hyperparamter setting to fit on the whole dataset\n",
    "lr_model = best_lr.best_estimator_.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best Logistic Regression model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_presence_classifier.joblib']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_lr, 'lr_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "y_pred = cross_val_predict(clf_rf, x_ros, y_ros, cv=5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Random Forest classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999290780141844\n",
      "Precision: 0.9985835694050992\n",
      "Confusion Matrix:\n",
      " [[7755    0]\n",
      " [  11 7744]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_ros, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_ros,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_ros, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precison: 0.999\n",
      "Recall: 1.000\n",
      "F1 Score: 0.999\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_ros, y_pred)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 7766],\n",
       "       [   1, 7744]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of Random Forest classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'bootstrap':[True,False], \n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[10,20,30,40,50, None],\n",
    "              'min_samples_leaf':[1,2,4],\n",
    "              'min_samples_split':[2,5,10],\n",
    "              'n_estimators':[100,200,300]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_rf,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    }
   ],
   "source": [
    "best_rf = gs.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999549</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>644</td>\n",
       "      <td>0.950484</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>645</td>\n",
       "      <td>0.950226</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>0.950097</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>647</td>\n",
       "      <td>0.949452</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>648</td>\n",
       "      <td>0.948549</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank_test_score  mean_test_score param_bootstrap param_criterion  \\\n",
       "0                  1         0.999613           False         entropy   \n",
       "1                  2         0.999549           False            gini   \n",
       "2                  3         0.999484           False         entropy   \n",
       "3                  3         0.999484           False         entropy   \n",
       "4                  3         0.999484           False         entropy   \n",
       "..               ...              ...             ...             ...   \n",
       "643              644         0.950484           False         entropy   \n",
       "644              645         0.950226           False            gini   \n",
       "645              646         0.950097            True            gini   \n",
       "646              647         0.949452           False         entropy   \n",
       "647              648         0.948549           False            gini   \n",
       "\n",
       "    param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0              None                      1                      10   \n",
       "1              None                      1                       2   \n",
       "2              None                      1                       2   \n",
       "3              None                      1                       5   \n",
       "4              None                      1                       5   \n",
       "..              ...                    ...                     ...   \n",
       "643              10                      4                       2   \n",
       "644              10                      2                      10   \n",
       "645              10                      2                       2   \n",
       "646              10                      2                      10   \n",
       "647              10                      4                      10   \n",
       "\n",
       "    param_n_estimators  \n",
       "0                  200  \n",
       "1                  300  \n",
       "2                  200  \n",
       "3                  100  \n",
       "4                  300  \n",
       "..                 ...  \n",
       "643                200  \n",
       "644                100  \n",
       "645                100  \n",
       "646                100  \n",
       "647                100  \n",
       "\n",
       "[648 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_rf.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_bootstrap', 'param_criterion','param_max_depth','param_min_samples_leaf','param_min_samples_split','param_n_estimators']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best hyperparamter setting to fit on the whole dataset\n",
    "rf_model = best_rf.best_estimator_.fit(x_ros,y_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best Random Forest model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_presence_classifier.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(rf_model, 'rf_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Check original training data and the oversampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 48)\t0.4691794964736476\n",
      "  (0, 407)\t0.5262810016864964\n",
      "  (0, 41)\t0.5262810016864964\n",
      "  (0, 3062)\t0.24355977438934603\n",
      "  (0, 2282)\t0.40817379988904395\n",
      "  (1, 57)\t0.37760570768168616\n",
      "  (1, 375)\t0.55667375244458\n",
      "  (1, 41)\t0.5491368872064922\n",
      "  (1, 3062)\t0.2541373447422181\n",
      "  (1, 2282)\t0.4259004014814059\n",
      "  (2, 294)\t0.5417747438402124\n",
      "  (2, 22)\t0.5645321713950354\n",
      "  (2, 57)\t0.37722677871330085\n",
      "  (2, 3062)\t0.2538823168125224\n",
      "  (2, 2282)\t0.4254730085779483\n",
      "  (3, 166)\t0.5355167174096335\n",
      "  (3, 33)\t0.5355167174096335\n",
      "  (3, 57)\t0.3955839550186312\n",
      "  (3, 3062)\t0.2662371195824374\n",
      "  (3, 2282)\t0.4461780154130034\n",
      "  (4, 482)\t0.5399293315285835\n",
      "  (4, 16)\t0.5606555981034347\n",
      "  (4, 57)\t0.3803066930277499\n",
      "  (4, 3062)\t0.25595517013540553\n",
      "  (4, 2282)\t0.4289468351551618\n",
      "  :\t:\n",
      "  (7931, 4338)\t0.4415150244791213\n",
      "  (7931, 2522)\t0.605701823999922\n",
      "  (7931, 3467)\t0.4924489725358683\n",
      "  (7931, 2106)\t0.4423616088798126\n",
      "  (7932, 3130)\t0.5044318622615386\n",
      "  (7932, 4057)\t0.3984881951795599\n",
      "  (7932, 1310)\t0.5352186165724686\n",
      "  (7932, 2458)\t0.5044318622615386\n",
      "  (7932, 3062)\t0.2141148837598686\n",
      "  (7933, 5787)\t0.49031217246871345\n",
      "  (7933, 3757)\t0.43230420728983443\n",
      "  (7933, 2045)\t0.46890315846532626\n",
      "  (7933, 3507)\t0.3528872281075681\n",
      "  (7933, 2881)\t0.29619935982066603\n",
      "  (7933, 5704)\t0.2723948324155705\n",
      "  (7933, 4041)\t0.2576324370560459\n",
      "  (7934, 726)\t0.4783515851025228\n",
      "  (7934, 4705)\t0.3442789602341803\n",
      "  (7934, 5629)\t0.4138178758157958\n",
      "  (7934, 4057)\t0.3405978871792407\n",
      "  (7934, 4106)\t0.3215187836437311\n",
      "  (7934, 4104)\t0.2674391871925831\n",
      "  (7934, 5704)\t0.2657500816340402\n",
      "  (7934, 4041)\t0.25134779750435277\n",
      "  (7934, 5727)\t0.23812336129316128\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 48)\t0.4691794964736476\n",
      "  (0, 407)\t0.5262810016864964\n",
      "  (0, 41)\t0.5262810016864964\n",
      "  (0, 3062)\t0.24355977438934603\n",
      "  (0, 2282)\t0.40817379988904395\n",
      "  (1, 57)\t0.37760570768168616\n",
      "  (1, 375)\t0.55667375244458\n",
      "  (1, 41)\t0.5491368872064922\n",
      "  (1, 3062)\t0.2541373447422181\n",
      "  (1, 2282)\t0.4259004014814059\n",
      "  (2, 294)\t0.5417747438402124\n",
      "  (2, 22)\t0.5645321713950354\n",
      "  (2, 57)\t0.37722677871330085\n",
      "  (2, 3062)\t0.2538823168125224\n",
      "  (2, 2282)\t0.4254730085779483\n",
      "  (3, 166)\t0.5355167174096335\n",
      "  (3, 33)\t0.5355167174096335\n",
      "  (3, 57)\t0.3955839550186312\n",
      "  (3, 3062)\t0.2662371195824374\n",
      "  (3, 2282)\t0.4461780154130034\n",
      "  (4, 482)\t0.5399293315285835\n",
      "  (4, 16)\t0.5606555981034347\n",
      "  (4, 57)\t0.3803066930277499\n",
      "  (4, 3062)\t0.25595517013540553\n",
      "  (4, 2282)\t0.4289468351551618\n",
      "  :\t:\n",
      "  (15505, 2663)\t0.39456987692503326\n",
      "  (15505, 4538)\t0.36818170600988037\n",
      "  (15505, 5704)\t0.34085688379418916\n",
      "  (15505, 4041)\t0.3223841982628108\n",
      "  (15505, 5769)\t0.2736321668186535\n",
      "  (15506, 2060)\t0.6926805328509326\n",
      "  (15506, 3467)\t0.5365530245168554\n",
      "  (15506, 2106)\t0.4819798038208271\n",
      "  (15507, 4705)\t0.4827371179568276\n",
      "  (15507, 4057)\t0.4775756332226999\n",
      "  (15507, 5704)\t0.37262639697048716\n",
      "  (15507, 4041)\t0.3524319676390185\n",
      "  (15507, 3409)\t0.5251929797375017\n",
      "  (15508, 3467)\t0.4154296290894266\n",
      "  (15508, 2106)\t0.37317596207789294\n",
      "  (15508, 3882)\t0.4659026405897524\n",
      "  (15508, 5704)\t0.3555376572763961\n",
      "  (15508, 4041)\t0.3362693495211815\n",
      "  (15508, 5006)\t0.38748596137788466\n",
      "  (15508, 5769)\t0.28541755842874544\n",
      "  (15509, 3507)\t0.5036408469916721\n",
      "  (15509, 4307)\t0.4819617602643478\n",
      "  (15509, 2663)\t0.45002405301051673\n",
      "  (15509, 4538)\t0.41992719990222027\n",
      "  (15509, 4041)\t0.3676931565567557\n"
     ]
    }
   ],
   "source": [
    "print(x_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
