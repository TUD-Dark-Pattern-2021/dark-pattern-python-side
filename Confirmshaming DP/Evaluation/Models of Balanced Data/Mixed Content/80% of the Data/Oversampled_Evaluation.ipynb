{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirmshaming Classifier Evaluation\n",
    "\n",
    "This script is used for the model evaluation for Confirmshaming Classifier.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Testing Dataset \"new_confirm.csv\"\n",
    "\n",
    "---\n",
    "Import the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YES! YOU HAD ME AT FREE</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>START MY FREE TRIAL NOW</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>See FREE Summary</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Continue —&gt;</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNLOCK THE BEST CARS NOBODY BUYS</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            content Classification\n",
       "0           YES! YOU HAD ME AT FREE       Not_Dark\n",
       "1           START MY FREE TRIAL NOW       Not_Dark\n",
       "2                  See FREE Summary       Not_Dark\n",
       "3                       Continue —>       Not_Dark\n",
       "4  UNLOCK THE BEST CARS NOBODY BUYS       Not_Dark"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('new_confirm.csv')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`check the dataset information`\n",
    "\n",
    "There are 3694 NOT NULL instances of content strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   content         208 non-null    object\n",
      " 1   Classification  208 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "Dark        105\n",
      "Not_Dark    103\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['Classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the target vales into integers` --- 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YES! YOU HAD ME AT FREE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>START MY FREE TRIAL NOW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>See FREE Summary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Continue —&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNLOCK THE BEST CARS NOBODY BUYS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            content  Classification\n",
       "0           YES! YOU HAD ME AT FREE               1\n",
       "1           START MY FREE TRIAL NOW               1\n",
       "2                  See FREE Summary               1\n",
       "3                       Continue —>               1\n",
       "4  UNLOCK THE BEST CARS NOBODY BUYS               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Classification'].replace({\"Dark\": 0, \"Not_Dark\": 1}, inplace = True)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "0    105\n",
      "1    103\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['Classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bernoulli Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Duplicate Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  69]\n",
      " [  1 139]]\n",
      "\n",
      "Accuracy: 0.7307692307692307\n",
      "Precision: 0.855072463768116\n",
      "Confusion Matrix:\n",
      " [[59 46]\n",
      " [10 93]]\n",
      "\n",
      "Precison: 0.855\n",
      "Recall: 0.562\n",
      "F1 Score: 0.678\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### SMOTE Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__binarize': 0.0, 'estimator__class_prior': None, 'estimator__fit_prior': True, 'estimator': BernoulliNB(), 'n_jobs': -1, 'param_grid': {'alpha': [0, 1], 'fit_prior': [True, False]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  57]\n",
      " [  1 151]]\n",
      "\n",
      "Accuracy: 0.7307692307692307\n",
      "Precision: 0.9298245614035088\n",
      "Confusion Matrix:\n",
      " [[53 52]\n",
      " [ 4 99]]\n",
      "\n",
      "Precison: 0.930\n",
      "Recall: 0.505\n",
      "F1 Score: 0.654\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/bnb_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-bnb.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Duplicate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 100, 'estimator__multi_class': 'auto', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(), 'n_jobs': -1, 'param_grid': {'penalty': ['l1', 'l2'], 'solver': ['lbfgs', 'newton-cg', 'sag']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  97]\n",
      " [  1 111]]\n",
      "\n",
      "Accuracy: 0.9519230769230769\n",
      "Precision: 0.9896907216494846\n",
      "Confusion Matrix:\n",
      " [[ 96   9]\n",
      " [  1 102]]\n",
      "\n",
      "Precison: 0.990\n",
      "Recall: 0.914\n",
      "F1 Score: 0.950\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/lr_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### SMOTE Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 100, 'estimator__multi_class': 'auto', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(), 'n_jobs': -1, 'param_grid': {'penalty': ['l1', 'l2'], 'solver': ['lbfgs', 'newton-cg', 'sag']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  93]\n",
      " [  1 115]]\n",
      "\n",
      "Accuracy: 0.9423076923076923\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      " [[ 93  12]\n",
      " [  0 103]]\n",
      "\n",
      "Precison: 1.000\n",
      "Recall: 0.886\n",
      "F1 Score: 0.939\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/lr_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-lr.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Support Vector Machine Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### Duplicate Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': True, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 1000, 'estimator__multi_class': 'ovr', 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator': LinearSVC(), 'n_jobs': -1, 'param_grid': {'C': [0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  87]\n",
      " [  1 121]]\n",
      "\n",
      "Accuracy: 0.9134615384615384\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      " [[ 87  18]\n",
      " [  0 103]]\n",
      "\n",
      "Precison: 1.000\n",
      "Recall: 0.829\n",
      "F1 Score: 0.906\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/svm_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### SMOTE Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': True, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 1000, 'estimator__multi_class': 'ovr', 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator': LinearSVC(), 'n_jobs': -1, 'param_grid': {'C': [0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  85]\n",
      " [  1 123]]\n",
      "\n",
      "Accuracy: 0.9038461538461539\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      " [[ 85  20]\n",
      " [  0 103]]\n",
      "\n",
      "Precison: 1.000\n",
      "Recall: 0.810\n",
      "F1 Score: 0.895\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/svm_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-svm.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Duplicate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  89]\n",
      " [  1 119]]\n",
      "\n",
      "Accuracy: 0.9230769230769231\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      " [[ 89  16]\n",
      " [  0 103]]\n",
      "\n",
      "Precison: 1.000\n",
      "Recall: 0.848\n",
      "F1 Score: 0.918\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"Duplicate/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"Duplicate/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/duplicate-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/duplicate-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### SMOTE Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters of the model:\n",
      "{'cv': 5, 'error_score': nan, 'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 100, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(), 'n_jobs': -1, 'param_grid': {'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, None], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100, 200, 300]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 1}\n",
      "\n",
      "The distribution of the prediction: \n",
      "[[  0  87]\n",
      " [  1 121]]\n",
      "\n",
      "Accuracy: 0.9134615384615384\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      " [[ 87  18]\n",
      " [  0 103]]\n",
      "\n",
      "Precison: 1.000\n",
      "Recall: 0.829\n",
      "F1 Score: 0.906\n"
     ]
    }
   ],
   "source": [
    "# -----Text Vectorizer Loading\n",
    "cv = joblib.load(\"SMOTE/presence_TfidfVectorizer.joblib\")\n",
    "\n",
    "# -----Model Loading'\n",
    "clf = joblib.load(\"SMOTE/rf_presence_classifier.joblib\")\n",
    "\n",
    "# -----Print the model parameters\n",
    "print(\"The hyperparameters of the model:\\n{}\\n\".format(clf.get_params()))\n",
    "\n",
    "\n",
    "# -----Make predictions on the testing dataset\n",
    "# apply the pretrained model to the new content data\n",
    "pred_vec = clf.predict(cv.transform(data['content'].str.lower()))\n",
    "\n",
    "# ---------- apply threshold to be 0.8\n",
    "# pre_pred_vec = (presence_model.predict_proba(presence_cv.transform(presence_pred['content']))[ : , 1] >= 0.8).astype(int)\n",
    "\n",
    "data['prediction'] = pred_vec.tolist()\n",
    "\n",
    "# ----dark pattern content are those where the predicted result equals to 0.\n",
    "dark = data.loc[data['prediction']==0]\n",
    "\n",
    "dark.to_csv('DP/smote-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----misclassification dataframe\n",
    "mis = data.loc[data['Classification'] != data['prediction']]\n",
    "\n",
    "mis.to_csv('Misclassification/smote-rf.csv', index = False, header = True)\n",
    "\n",
    "# ----print the distribution of the prediction\n",
    "(unique, counts) = np.unique(pred_vec, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(\"The distribution of the prediction: \\n{}\\n\".format(frequencies))\n",
    "\n",
    "# ----Overview of the prediction results\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data['Classification'], pred_vec))\n",
    "print(\"Precision:\", metrics.precision_score(data['Classification'],pred_vec, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(data['Classification'], pred_vec))\n",
    "\n",
    "cm = metrics.confusion_matrix(data['Classification'], pred_vec)\n",
    "precision = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "recall = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"\\nPrecison: {0:.3f}\".format(precision))\n",
    "print(\"Recall: {0:.3f}\".format(recall))\n",
    "print(\"F1 Score: {0:.3f}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
