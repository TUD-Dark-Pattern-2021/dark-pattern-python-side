{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Formation\n",
    "\n",
    "Given a Pattern String as an input, we want to know if it contains dark pattern in it. We use a balanced dataset cotaining all the instances in the Princeton dataset which are all dark patterns, and the instances in the 'normie.csv' file which are labeled as NOT dark patterns. Hence we have a balanced dataset consisting of pattern strings with dark pattern and without park patterns.\n",
    "\n",
    "Then we use this labeled dataset to build and train supervised machine learning models, and select most suitable ones for our project.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Bernoulli Naive Bayes (Similar as  MultinomialNB), this classifier is suitable for discrete data. The difference between MultinomialNB and BernoulliNB is that while  MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolen features, which means in the case of text classification, word occurrence vectores (rather than word count vectors) may be more suitable to be used to train and use this classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "---\n",
    "Import the merged dataset, and explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('enriched_confirm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ends in 07:42:09</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ends in 07:37:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ends in 02:27:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ends in 04:17:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ends in 01:57:10</td>\n",
       "      <td>Not_Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pattern String classification\n",
       "0  Ends in 07:42:09       Not_Dark\n",
       "1  Ends in 07:37:10       Not_Dark\n",
       "2  Ends in 02:27:10       Not_Dark\n",
       "3  Ends in 04:17:10       Not_Dark\n",
       "4  Ends in 01:57:10       Not_Dark"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`check the dataset information`\n",
    "\n",
    "There are 7952 NOT NULL instances of pattern strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8187 entries, 0 to 8186\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Pattern String  8187 non-null   object\n",
      " 1   classification  8187 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 128.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the tags:\n",
      "Not_Dark    7994\n",
      "Dark         193\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target value --- classification.\n",
    "\n",
    "print('Distribution of the tags:\\n{}'.format(data['classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the content into lowercase\n",
    "\n",
    "data['Pattern String'] = data['Pattern String'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the tags:\n",
      "Not_Dark    7755\n",
      "Dark         180\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For later training the model, we should remove the duplicate input to reduce overfitting.\n",
    "\n",
    "data = data.drop_duplicates(subset=\"Pattern String\")\n",
    "\n",
    "print('\\nDistribution of the tags:\\n{}'.format(data['classification'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test dataset as a ratio of 80%/20% (train/test).\n",
    "\n",
    "string_train, string_test, dark_train, dark_test = train_test_split(\n",
    "    data['Pattern String'], data[\"classification\"], train_size = .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the target vales into integers` --- 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(dark_train)\n",
    "y_train = encoder.transform(dark_train)\n",
    "y_test = encoder.transform(dark_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dark': 0, 'Not_Dark': 1}\n"
     ]
    }
   ],
   "source": [
    "# check the mapping of encoding results (from 0 to 1 representing 'Dark', 'Not Dark')\n",
    "\n",
    "integer_mapping = {label: encoding for encoding, label in enumerate(encoder.classes_)}\n",
    "print(integer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Dark' 133]\n",
      " ['Not_Dark' 6215]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the training pattern classification with pattern classification names.\n",
    "\n",
    "(unique, counts) = np.unique(dark_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  133]\n",
      " [   1 6215]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded training pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   47]\n",
      " [   1 1540]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded testing pattern classification with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Encode the textual features into series of vector of numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6348, 5594), (1587, 5594))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the word count vector of the pattern string to encode the pattern string.\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "tv.fit(string_train)\n",
    "\n",
    "x_train = tv.transform(string_train)\n",
    "x_test = tv.transform(string_test)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presence_TfidfVectorizer.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the CountVectorizer to disk\n",
    "\n",
    "joblib.dump(tv, 'presence_TfidfVectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Rough Idea about the effect of different classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four models are tested:\n",
    "# -- Logistic Regression\n",
    "# -- Linear Support Vector Machine\n",
    "# -- Random Forest\n",
    "# -- Bernoulli Naive Bayes\n",
    "\n",
    "classifiers = [LogisticRegression(), LinearSVC(), RandomForestClassifier(), BernoulliNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "pre = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    pre.append(metrics.precision_score(y_test, y_pred, pos_label=0))\n",
    "    cm.append(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.988\n",
      "LogisticRegression() precision: 0.967\n",
      "Confusion Matrix: [[  29   18]\n",
      " [   1 1539]]\n",
      "LinearSVC() accuracy: 0.992\n",
      "LinearSVC() precision: 0.947\n",
      "Confusion Matrix: [[  36   11]\n",
      " [   2 1538]]\n",
      "RandomForestClassifier() accuracy: 0.992\n",
      "RandomForestClassifier() precision: 0.972\n",
      "Confusion Matrix: [[  35   12]\n",
      " [   1 1539]]\n",
      "BernoulliNB() accuracy: 0.970\n",
      "BernoulliNB() precision: 0.000\n",
      "Confusion Matrix: [[   0   47]\n",
      " [   0 1540]]\n"
     ]
    }
   ],
   "source": [
    "# List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(\"{} accuracy: {:.3f}\".format(classifiers[i],acc[i]))\n",
    "    print(\"{} precision: {:.3f}\".format(classifiers[i],pre[i]))\n",
    "    print(\"Confusion Matrix: {}\".format(cm[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bernoulli Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bnb = BernoulliNB().fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf_bnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bnb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Bernoulli Naive Bayes classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9703843730308759\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0   47]\n",
      " [   0 1540]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1, 1587]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of BernoulliNB classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0,1], \n",
    "              'fit_prior':[True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_bnb,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    1.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "best_bnb = gs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_fit_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.978576</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.978103</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.972118</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.963927</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_alpha param_fit_prior\n",
       "0                1         0.978576           1            True\n",
       "1                2         0.978103           1           False\n",
       "2                3         0.972118           0            True\n",
       "3                4         0.963927           0           False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_bnb.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_alpha', 'param_fit_prior']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'fit_prior': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1 1587]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_bnb.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9703843730308759\n",
      "Precision: 0.0\n",
      "Confusion Matrix:\n",
      " [[   0   47]\n",
      " [   0 1540]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best BernoulliNB model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bnb_presence_classifier.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_bnb, 'bnb_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier().fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Random Forest classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9911783238815375\n",
      "Precision: 0.9714285714285714\n",
      "Confusion Matrix:\n",
      " [[  34   13]\n",
      " [   1 1539]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   35],\n",
       "       [   1, 1552]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of Random Forest classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'bootstrap':[True,False], \n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[10,20,30,40,50, None],\n",
    "              'min_samples_leaf':[1,2,4],\n",
    "              'min_samples_split':[2,5,10],\n",
    "              'n_estimators':[100,200,300]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_rf,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3240 out of 3240 | elapsed: 35.8min finished\n"
     ]
    }
   ],
   "source": [
    "best_rf = gs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997795</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.997637</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.997637</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.997637</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.997637</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>627</td>\n",
       "      <td>0.979049</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>627</td>\n",
       "      <td>0.979049</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>627</td>\n",
       "      <td>0.979049</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>627</td>\n",
       "      <td>0.979049</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>627</td>\n",
       "      <td>0.979049</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank_test_score  mean_test_score param_bootstrap param_criterion  \\\n",
       "0                  1         0.997795           False         entropy   \n",
       "1                  2         0.997637           False         entropy   \n",
       "2                  3         0.997637           False            gini   \n",
       "3                  3         0.997637           False         entropy   \n",
       "4                  5         0.997637           False         entropy   \n",
       "..               ...              ...             ...             ...   \n",
       "643              627         0.979049            True         entropy   \n",
       "644              627         0.979049            True         entropy   \n",
       "645              627         0.979049            True            gini   \n",
       "646              627         0.979049           False            gini   \n",
       "647              627         0.979049            True         entropy   \n",
       "\n",
       "    param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0              None                      2                       2   \n",
       "1              None                      2                       2   \n",
       "2              None                      2                       5   \n",
       "3              None                      2                      10   \n",
       "4              None                      2                       2   \n",
       "..              ...                    ...                     ...   \n",
       "643              10                      2                      10   \n",
       "644              10                      2                      10   \n",
       "645              10                      4                      10   \n",
       "646              10                      2                       2   \n",
       "647              10                      4                      10   \n",
       "\n",
       "    param_n_estimators  \n",
       "0                  100  \n",
       "1                  200  \n",
       "2                  100  \n",
       "3                  300  \n",
       "4                  300  \n",
       "..                 ...  \n",
       "643                100  \n",
       "644                200  \n",
       "645                100  \n",
       "646                200  \n",
       "647                300  \n",
       "\n",
       "[648 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_rf.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_bootstrap', 'param_criterion','param_max_depth','param_min_samples_leaf','param_min_samples_split','param_n_estimators']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   35]\n",
      " [   1 1552]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_rf.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9911783238815375\n",
      "Precision: 0.9714285714285714\n",
      "Confusion Matrix:\n",
      " [[  34   13]\n",
      " [   1 1539]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best Random Forest model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_presence_classifier.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_rf, 'rf_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SVM Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = LinearSVC().fit(x_train,y_train)\n",
    "\n",
    "y_pred = clf_svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': True,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Random Forest classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9918084436042848\n",
      "Precision: 0.9473684210526315\n",
      "Confusion Matrix:\n",
      " [[  36   11]\n",
      " [   2 1538]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   38],\n",
       "       [   1, 1549]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of SVM classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.1,1,10,100],\n",
    "              'penalty':['l1','l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_svm,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "best_svm = gs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997007</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.997007</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.996534</td>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.993541</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_C\n",
       "0                1         0.997007            l2       1\n",
       "1                2         0.997007            l2      10\n",
       "2                3         0.996534            l2     100\n",
       "3                4         0.993541            l2     0.1\n",
       "4                5              NaN            l1     0.1\n",
       "5                6              NaN            l1       1\n",
       "6                7              NaN            l1      10\n",
       "7                8              NaN            l1     100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_svm.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   38]\n",
      " [   1 1549]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_svm.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9918084436042848\n",
      "Precision: 0.9473684210526315\n",
      "Confusion Matrix:\n",
      " [[  36   11]\n",
      " [   2 1538]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best SVM model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_presence_classifier.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_svm, 'svm_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Use default setting of classifier hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf_lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`use the default setting of hyperparameters of the Logistic Regression classifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9880277252678009\n",
      "Precision: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[  29   18]\n",
      " [   1 1539]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   30],\n",
       "       [   1, 1557]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Parameter Tunning of Logistic Regression classifier`\n",
    "`Define the combination of parameters to be considered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty':['l1','l2'], \n",
    "              'solver':['lbfgs','newton-cg','sag']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run the Grid Search`\n",
    "\n",
    "Use cross validation on the training dataset to find optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf_lr,param_grid,cv=5, \n",
    "                      verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "best_lr = gs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.990863</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.990863</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.990863</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_solver\n",
       "0                1         0.990863            l2        lbfgs\n",
       "1                1         0.990863            l2    newton-cg\n",
       "2                1         0.990863            l2          sag\n",
       "3                4              NaN            l1        lbfgs\n",
       "4                5              NaN            l1    newton-cg\n",
       "5                6              NaN            l1          sag"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(best_lr.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_solver']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   30]\n",
      " [   1 1557]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_lr.predict(x_test)\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9880277252678009\n",
      "Precision: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[  29   18]\n",
      " [   1 1539]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", metrics.precision_score(y_test,y_pred_best, pos_label=0))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Save the best Logistic Regression model for future use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_presence_classifier.joblib']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_lr, 'lr_presence_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
