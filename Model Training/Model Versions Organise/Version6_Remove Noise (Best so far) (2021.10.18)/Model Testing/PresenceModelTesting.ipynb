{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/94.0.4606.61/chromedriver_mac64.zip\n",
      "Driver has been saved in cache [/Users/zenglan/.wdm/drivers/chromedriver/mac64/94.0.4606.61]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Websites/pcworld.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af5bacfb7f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# New dataset to predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mpresence_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Websites/pcworld.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Websites/pcworld.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------- Load Packages -------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# web scraper\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import lxml.html\n",
    "import re\n",
    "import time\n",
    "\n",
    "# write to csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ----------------------------- Web Scrapper -------------------------------------------\n",
    "\n",
    "\n",
    "url = 'https://www.currys.ie/ieen/computing/laptops/laptops/dell-inspiron-15-5502-15-6-laptop-intel-core-i5-256-gb-ssd-silver-10217071-pdt.html'\n",
    "#url='https://www.currys.ie/ieen/search-keywords/xx_xx_xx_xx_xx/-wk22_headphones_ie-/xx-criteria.html'\n",
    "\n",
    "# to avoid opening browser while using selenium\n",
    "option = webdriver.ChromeOptions()\n",
    "option.add_argument('headless')\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(),options=option)\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "# get source code -- type: str\n",
    "html_source = driver.page_source\n",
    "\n",
    "# key\n",
    "html = lxml.html.fromstring(html_source)\n",
    "\n",
    "# obtain all the text under the 'div' tags\n",
    "items = html.xpath(\"//div//text()\")\n",
    "\n",
    "pattern = re.compile(\"^\\s+|\\s+$|\\n\")\n",
    "\n",
    "clause_text = \"\"\n",
    "\n",
    "for item in items:\n",
    "    line = re.sub(pattern, \"\", item)\n",
    "    if len(item) > 1:\n",
    "        clause_text += line +\"\\n\"\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# --------------------------- Generate Web Scrapping Conetnt ------------------------------------\n",
    "\n",
    "raw_text = clause_text\n",
    "\n",
    "# the beginning character of the content, which is the sign we should ignore the content\n",
    "ignore_str = ',.;{}?#/$'\n",
    "\n",
    "# the content we are going to keep to send to models.\n",
    "content_list = []\n",
    "\n",
    "# only keep the content that has words count from 2 to 20 (includes).\n",
    "for line in raw_text.split('\\n'):\n",
    "    if 1<len(line.split())<21 and line[0] not in ignore_str:\n",
    "        content_list.append([line])\n",
    "\n",
    "\n",
    "header = ['content']\n",
    "\n",
    "# create a csv file to save the filtered content for later model analysis.\n",
    "with open('Websites/bug.csv', 'a', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write the data\n",
    "    writer.writerows(content_list)\n",
    "\n",
    "        \n",
    "# ---------------------------- Check Presence --------------------------------------\n",
    "\n",
    "# Loading the saved model with joblib\n",
    "presence_model = joblib.load('rf_presence_classifier.joblib')\n",
    "presence_cv = joblib.load('presence_CountVectorizer.joblib')\n",
    "\n",
    "# New dataset to predict\n",
    "presence_pred = pd.read_csv('Websites/pcworld.csv')\n",
    "\n",
    "\n",
    "# Filter out the disturibing content to be removed\n",
    "str_list = ['low to high','high to low','high low','low high','{','ships','ship','Â®',\n",
    "            'limited edition','cart is currently empty','believe in','today\\'s deals']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "presence_pred = presence_pred[~presence_pred.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "# apply the pretrained model to the new content data\n",
    "pre_pred_vec = presence_model.predict(presence_cv.transform(presence_pred['content']))\n",
    "\n",
    "presence_pred['presence'] = pre_pred_vec.tolist()\n",
    "\n",
    "# dark pattern content are those where the predicted result equals to 0.\n",
    "dark = presence_pred.loc[presence_pred['presence']==0]\n",
    "\n",
    "# save the dark pattern csv detected\n",
    "dark.to_csv('Websites/pcworld-rf.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-de5a69d3bb62>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dark['category'] = cat_pred_vec.tolist()\n",
      "<ipython-input-2-de5a69d3bb62>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dark['category_name'] = [cat_dic[int(category)] for category in category_list]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>presence</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Have one to sell?</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>About this item</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frequently bought together</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This item:</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In Stock.</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Scarcity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In Stock.</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Scarcity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In Stock.</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Scarcity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Remaining Time</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Urgency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This is a modal window.</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This item</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Products related to this item</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13 people found this helpful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6 people found this helpful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I bought the three pack on a recommendation fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2 people found this helpful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>People follow me down the hall just to talk</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4 people found this helpful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2 people found this helpful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7 people found this helpful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>One person found this helpful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What other items do customers buy after viewin...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Social Proof</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  presence  category  \\\n",
       "0                                   Have one to sell?         0         5   \n",
       "1                                     About this item         0         5   \n",
       "2                          Frequently bought together         0         5   \n",
       "3                                          This item:         0         5   \n",
       "4                                           In Stock.         0         3   \n",
       "5                                           In Stock.         0         3   \n",
       "6                                           In Stock.         0         3   \n",
       "7                                      Remaining Time         0         6   \n",
       "8                             This is a modal window.         0         5   \n",
       "9                                           This item         0         5   \n",
       "10                      Products related to this item         0         5   \n",
       "11                       13 people found this helpful         0         5   \n",
       "12                        6 people found this helpful         0         5   \n",
       "13  I bought the three pack on a recommendation fr...         0         5   \n",
       "14                        2 people found this helpful         0         5   \n",
       "15        People follow me down the hall just to talk         0         5   \n",
       "16                        4 people found this helpful         0         5   \n",
       "17                        2 people found this helpful         0         5   \n",
       "18                        7 people found this helpful         0         5   \n",
       "19                      One person found this helpful         0         5   \n",
       "20  What other items do customers buy after viewin...         0         5   \n",
       "\n",
       "   category_name  \n",
       "0   Social Proof  \n",
       "1   Social Proof  \n",
       "2   Social Proof  \n",
       "3   Social Proof  \n",
       "4       Scarcity  \n",
       "5       Scarcity  \n",
       "6       Scarcity  \n",
       "7        Urgency  \n",
       "8   Social Proof  \n",
       "9   Social Proof  \n",
       "10  Social Proof  \n",
       "11  Social Proof  \n",
       "12  Social Proof  \n",
       "13  Social Proof  \n",
       "14  Social Proof  \n",
       "15  Social Proof  \n",
       "16  Social Proof  \n",
       "17  Social Proof  \n",
       "18  Social Proof  \n",
       "19  Social Proof  \n",
       "20  Social Proof  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the saved model with joblib\n",
    "cat_model = joblib.load('mnb_category_classifier.joblib')\n",
    "cat_cv = joblib.load('category_CountVectorizer.joblib')\n",
    "\n",
    "# mapping of the encoded dark pattern categories.\n",
    "cat_dic = {0:'Forced Action', 1:'Misdirection', 2:'Obstruction', 3:'Scarcity', 4:'Sneaking',\n",
    "           5:'Social Proof', 6:'Urgency'}\n",
    "\n",
    "# apply the model and the countvectorizer to the detected dark pattern content data\n",
    "cat_pred_vec = cat_model.predict(cat_cv.transform(dark['content']))\n",
    "\n",
    "\n",
    "dark['category'] = cat_pred_vec.tolist()\n",
    "\n",
    "category_list = dark['category'].tolist()\n",
    "\n",
    "# get the mapping of the category name and encoded category integers\n",
    "dark['category_name'] = [cat_dic[int(category)] for category in category_list]\n",
    "\n",
    "# reset the index of the detected dark pattern list on the webpage.\n",
    "dark = dark.reset_index(drop=True)\n",
    "\n",
    "dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
