{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. eBay Dataset\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First raw dataset information above (222, 1)\n",
      "\n",
      "Second raw dataset information above (502, 1)\n",
      "\n",
      "Third raw dataset information above (458, 1)\n",
      "\n",
      "Fourth raw dataset information above (538, 1)\n",
      "\n",
      "Fifth raw dataset information above (448, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- import the raw dataset\n",
    "\n",
    "raw1 = pd.read_csv('Raw/ebay-1.csv')\n",
    "raw2 = pd.read_csv('Raw/ebay-2.csv')\n",
    "raw3 = pd.read_csv('Raw/ebay-3.csv')\n",
    "raw4 = pd.read_csv('Raw/ebay-4.csv')\n",
    "raw5 = pd.read_csv('Raw/ebay-5.csv')\n",
    "\n",
    "print('First raw dataset information above {}\\n'.format(raw1.shape)),\n",
    "print('Second raw dataset information above {}\\n'.format(raw2.shape)),\n",
    "print('Third raw dataset information above {}\\n'.format(raw3.shape)),\n",
    "print('Fourth raw dataset information above {}\\n'.format(raw4.shape)),\n",
    "print('Fifth raw dataset information above {}\\n'.format(raw5.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (222, 1)\n",
      "\n",
      "Second filtered dataset information above (502, 1)\n",
      "\n",
      "Third filtered dataset information above (458, 1)\n",
      "\n",
      "Fourth filtered dataset information above (538, 1)\n",
      "\n",
      "Fifth filtered dataset information above (448, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_str = [',', '.', ';', '{', '}', '#', '/', '(', ')', '?','$']\n",
    "\n",
    "df1 = raw1[~raw1['content'].str[0].isin(ignore_str)]\n",
    "df2 = raw2[~raw2['content'].str[0].isin(ignore_str)]\n",
    "df3 = raw3[~raw3['content'].str[0].isin(ignore_str)]\n",
    "df4 = raw4[~raw4['content'].str[0].isin(ignore_str)]\n",
    "df5 = raw5[~raw5['content'].str[0].isin(ignore_str)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(df4.shape)),\n",
    "print('Fifth filtered dataset information above {}\\n'.format(df5.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (219, 1)\n",
      "\n",
      "Second filtered dataset information above (490, 1)\n",
      "\n",
      "Third filtered dataset information above (451, 1)\n",
      "\n",
      "Fourth filtered dataset information above (523, 1)\n",
      "\n",
      "Fifth filtered dataset information above (436, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the disturibing content to be removed.\n",
    "str_list = [ '{', '®','℗','©','=','\\(']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "df1 = df1[~df1.content.str.lower().str.contains(pattern)]\n",
    "df2 = df2[~df2.content.str.lower().str.contains(pattern)]\n",
    "df3 = df3[~df3.content.str.lower().str.contains(pattern)]\n",
    "df4 = df4[~df4.content.str.lower().str.contains(pattern)]\n",
    "df5 = df5[~df5.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(df4.shape)),\n",
    "print('Fifth filtered dataset information above {}\\n'.format(df5.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (0, 1)\n",
      "\n",
      "Second filtered dataset information above (38, 1)\n",
      "\n",
      "Third filtered dataset information above (0, 1)\n",
      "\n",
      "Fourth filtered dataset information above (36, 1)\n",
      "\n",
      "Fifth filtered dataset information above (3, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter out the dark pattern strings\n",
    "\n",
    "str_list = ['left','sold','watching','watchers']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "dp1 = df1[df1.content.str.lower().str.contains(pattern)]\n",
    "dp2 = df2[df2.content.str.lower().str.contains(pattern)]\n",
    "dp3 = df3[df3.content.str.lower().str.contains(pattern)]\n",
    "dp4 = df4[df4.content.str.lower().str.contains(pattern)]\n",
    "dp5 = df5[df5.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(dp1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(dp2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(dp3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(dp4.shape)),\n",
    "print('Fifth filtered dataset information above {}\\n'.format(dp5.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (0, 1)\n",
      "\n",
      "Second filtered dataset information above (38, 1)\n",
      "\n",
      "Third filtered dataset information above (0, 1)\n",
      "\n",
      "Fourth filtered dataset information above (35, 1)\n",
      "\n",
      "Fifth filtered dataset information above (3, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# after checking the dp list, remove the one that is not actually dark pattern\n",
    "\n",
    "dp4 = dp4[~dp4.content.str.lower().str.contains('anti')]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(dp1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(dp2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(dp3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(dp4.shape)),\n",
    "print('Fifth filtered dataset information above {}\\n'.format(dp5.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First normal dataset information above (219, 1)\n",
      "\n",
      "Second normal dataset information above (452, 1)\n",
      "\n",
      "Third normal dataset information above (451, 1)\n",
      "\n",
      "Fourth normal dataset information above (488, 1)\n",
      "\n",
      "Fifth normal dataset information above (433, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the normal content strings\n",
    "\n",
    "nor1 = df1[~df1.isin(dp1).any(axis=1)]\n",
    "nor2 = df2[~df2.isin(dp2).any(axis=1)]\n",
    "nor3 = df3[~df3.isin(dp3).any(axis=1)]\n",
    "nor4 = df4[~df4.isin(dp4).any(axis=1)]\n",
    "nor5 = df5[~df5.isin(dp5).any(axis=1)]\n",
    "\n",
    "print('First normal dataset information above {}\\n'.format(nor1.shape)),\n",
    "print('Second normal dataset information above {}\\n'.format(nor2.shape)),\n",
    "print('Third normal dataset information above {}\\n'.format(nor3.shape)),\n",
    "print('Fourth normal dataset information above {}\\n'.format(nor4.shape)),\n",
    "print('Fifth normal dataset information above {}\\n'.format(nor5.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the normal content and dark pattern content as csv files\n",
    "\n",
    "# dark patterns\n",
    "\n",
    "dp2.to_csv('DP/ebay1.csv', index = False, header = True)\n",
    "dp4.to_csv('DP/ebay2.csv', index = False, header = True)\n",
    "dp5.to_csv('DP/ebay3.csv', index = False, header = True)\n",
    "\n",
    "# normal content\n",
    "\n",
    "nor1.to_csv('Normal/ebay1.csv', index = False, header = True)\n",
    "nor2.to_csv('Normal/ebay2.csv', index = False, header = True)\n",
    "nor3.to_csv('Normal/ebay3.csv', index = False, header = True)\n",
    "nor4.to_csv('Normal/ebay4.csv', index = False, header = True)\n",
    "nor5.to_csv('Normal/ebay5.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Amazon Dataset\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First raw dataset information above (279, 1)\n",
      "\n",
      "Second raw dataset information above (515, 1)\n",
      "\n",
      "Third raw dataset information above (423, 1)\n",
      "\n",
      "Fourth raw dataset information above (429, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- import the raw dataset\n",
    "\n",
    "raw1 = pd.read_csv('Raw/amazon-1.csv')\n",
    "raw2 = pd.read_csv('Raw/amazon-2.csv')\n",
    "raw3 = pd.read_csv('Raw/amazon-3.csv')\n",
    "raw4 = pd.read_csv('Raw/amazon-4.csv')\n",
    "\n",
    "\n",
    "print('First raw dataset information above {}\\n'.format(raw1.shape)),\n",
    "print('Second raw dataset information above {}\\n'.format(raw2.shape)),\n",
    "print('Third raw dataset information above {}\\n'.format(raw3.shape)),\n",
    "print('Fourth raw dataset information above {}\\n'.format(raw4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (278, 1)\n",
      "\n",
      "Second filtered dataset information above (510, 1)\n",
      "\n",
      "Third filtered dataset information above (422, 1)\n",
      "\n",
      "Fourth filtered dataset information above (424, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_str = [',', '.', ';', '{', '}', '#', '/', '(', ')', '?','$']\n",
    "\n",
    "df1 = raw1[~raw1['content'].str[0].isin(ignore_str)]\n",
    "df2 = raw2[~raw2['content'].str[0].isin(ignore_str)]\n",
    "df3 = raw3[~raw3['content'].str[0].isin(ignore_str)]\n",
    "df4 = raw4[~raw4['content'].str[0].isin(ignore_str)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(df4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (219, 1)\n",
      "\n",
      "Second filtered dataset information above (433, 1)\n",
      "\n",
      "Third filtered dataset information above (390, 1)\n",
      "\n",
      "Fourth filtered dataset information above (373, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the disturibing content to be removed.\n",
    "str_list = ['{', '®','℗','©','=','\\(']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "df1 = df1[~df1.content.str.lower().str.contains(pattern)]\n",
    "df2 = df2[~df2.content.str.lower().str.contains(pattern)]\n",
    "df3 = df3[~df3.content.str.lower().str.contains(pattern)]\n",
    "df4 = df4[~df4.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(df4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (0, 1)\n",
      "\n",
      "Second filtered dataset information above (11, 1)\n",
      "\n",
      "Third filtered dataset information above (0, 1)\n",
      "\n",
      "Fourth filtered dataset information above (3, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter out the dark pattern strings\n",
    "\n",
    "str_list = ['left in stock','ends in','limited-time deal']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "dp1 = df1[df1.content.str.lower().str.contains(pattern)]\n",
    "dp2 = df2[df2.content.str.lower().str.contains(pattern)]\n",
    "dp3 = df3[df3.content.str.lower().str.contains(pattern)]\n",
    "dp4 = df4[df4.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(dp1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(dp2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(dp3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(dp4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Ends in 07:42:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Ends in 07:37:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Ends in 02:27:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Ends in 04:17:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Ends in 01:57:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Ends in 02:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Ends in 05:22:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Ends in 01:17:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Limited-time deal: Up to 80% off, select top r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Ends in 57:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Ends in 47:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "248                                   Ends in 07:42:09\n",
       "251                                   Ends in 07:37:10\n",
       "263                                   Ends in 02:27:10\n",
       "271                                   Ends in 04:17:10\n",
       "273                                   Ends in 01:57:10\n",
       "284                                   Ends in 02:32:10\n",
       "286                                   Ends in 05:22:10\n",
       "330                                   Ends in 01:17:09\n",
       "337  Limited-time deal: Up to 80% off, select top r...\n",
       "350                                      Ends in 57:09\n",
       "363                                      Ends in 47:09"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Only 16 left in stock - order soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Only 8 left in stock - order soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Only 15 left in stock - order soon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 content\n",
       "105  Only 16 left in stock - order soon.\n",
       "118   Only 8 left in stock - order soon.\n",
       "241  Only 15 left in stock - order soon."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First normal dataset information above (219, 1)\n",
      "\n",
      "Second normal dataset information above (422, 1)\n",
      "\n",
      "Third normal dataset information above (390, 1)\n",
      "\n",
      "Fourth normal dataset information above (370, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the normal content strings\n",
    "\n",
    "nor1 = df1[~df1.isin(dp1).any(axis=1)]\n",
    "nor2 = df2[~df2.isin(dp2).any(axis=1)]\n",
    "nor3 = df3[~df3.isin(dp3).any(axis=1)]\n",
    "nor4 = df4[~df4.isin(dp4).any(axis=1)]\n",
    "\n",
    "print('First normal dataset information above {}\\n'.format(nor1.shape)),\n",
    "print('Second normal dataset information above {}\\n'.format(nor2.shape)),\n",
    "print('Third normal dataset information above {}\\n'.format(nor3.shape)),\n",
    "print('Fourth normal dataset information above {}\\n'.format(nor4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the normal content and dark pattern content as csv files\n",
    "\n",
    "# dark patterns\n",
    "\n",
    "dp2.to_csv('DP/amazon1.csv', index = False, header = True)\n",
    "dp4.to_csv('DP/amazon2.csv', index = False, header = True)\n",
    "\n",
    "# normal content\n",
    "\n",
    "nor1.to_csv('Normal/amazon1.csv', index = False, header = True)\n",
    "nor2.to_csv('Normal/amazon2.csv', index = False, header = True)\n",
    "nor3.to_csv('Normal/amazon3.csv', index = False, header = True)\n",
    "nor4.to_csv('Normal/amazon4.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wish Dataset\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First raw dataset information above (68, 1)\n",
      "\n",
      "Second raw dataset information above (69, 1)\n",
      "\n",
      "Third raw dataset information above (65, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- import the raw dataset\n",
    "\n",
    "raw1 = pd.read_csv('Raw/wish-1.csv')\n",
    "raw2 = pd.read_csv('Raw/wish-2.csv')\n",
    "raw3 = pd.read_csv('Raw/wish-3.csv')\n",
    "\n",
    "print('First raw dataset information above {}\\n'.format(raw1.shape)),\n",
    "print('Second raw dataset information above {}\\n'.format(raw2.shape)),\n",
    "print('Third raw dataset information above {}\\n'.format(raw3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (68, 1)\n",
      "\n",
      "Second filtered dataset information above (69, 1)\n",
      "\n",
      "Third filtered dataset information above (65, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_str = [',', '.', ';', '{', '}', '#', '/', '(', ')', '?','$']\n",
    "\n",
    "df1 = raw1[~raw1['content'].str[0].isin(ignore_str)]\n",
    "df2 = raw2[~raw2['content'].str[0].isin(ignore_str)]\n",
    "df3 = raw3[~raw3['content'].str[0].isin(ignore_str)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (68, 1)\n",
      "\n",
      "Second filtered dataset information above (69, 1)\n",
      "\n",
      "Third filtered dataset information above (65, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the disturibing content to be removed.\n",
    "str_list = [ '{', '®','℗','©','=','\\(']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "df1 = df1[~df1.content.str.lower().str.contains(pattern)]\n",
    "df2 = df2[~df2.content.str.lower().str.contains(pattern)]\n",
    "df3 = df3[~df3.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (43, 1)\n",
      "\n",
      "Second filtered dataset information above (40, 1)\n",
      "\n",
      "Third filtered dataset information above (39, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter out the dark pattern strings\n",
    "\n",
    "str_list = ['bought this','almost gone','invites sent','like you bought']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "dp1 = df1[df1.content.str.lower().str.contains(pattern)]\n",
    "dp2 = df2[df2.content.str.lower().str.contains(pattern)]\n",
    "dp3 = df3[df3.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(dp1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(dp2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(dp3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>50,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 content\n",
       "11    1,000+ bought this\n",
       "12  100,000+ bought this\n",
       "13          Almost Gone!\n",
       "14   10,000+ bought this\n",
       "15      100+ bought this\n",
       "16          Almost Gone!\n",
       "17    5,000+ bought this\n",
       "18   20,000+ bought this\n",
       "19   20,000+ bought this\n",
       "20    1,000+ bought this\n",
       "21    1,000+ bought this\n",
       "22          Almost Gone!\n",
       "23   10,000+ bought this\n",
       "24   20,000+ bought this\n",
       "25    1,000+ bought this\n",
       "26          Almost Gone!\n",
       "27    1,000+ bought this\n",
       "28    1,000+ bought this\n",
       "29    1,000+ bought this\n",
       "30  100,000+ bought this\n",
       "31    1,000+ bought this\n",
       "32  100,000+ bought this\n",
       "33          Almost Gone!\n",
       "34    1,000+ bought this\n",
       "35    5,000+ bought this\n",
       "36          Almost Gone!\n",
       "37    5,000+ bought this\n",
       "38    1,000+ bought this\n",
       "39   50,000+ bought this\n",
       "40   10,000+ bought this\n",
       "41       50+ bought this\n",
       "42      100+ bought this\n",
       "43          Almost Gone!\n",
       "44   10,000+ bought this\n",
       "45    1,000+ bought this\n",
       "46    1,000+ bought this\n",
       "47    1,000+ bought this\n",
       "48          Almost Gone!\n",
       "49   20,000+ bought this\n",
       "50    1,000+ bought this\n",
       "51    5,000+ bought this\n",
       "52          Almost Gone!\n",
       "53    1,000+ bought this"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                content\n",
       "11     100+ bought this\n",
       "12         Almost Gone!\n",
       "13   1,000+ bought this\n",
       "14  10,000+ bought this\n",
       "15   1,000+ bought this\n",
       "17   5,000+ bought this\n",
       "18   5,000+ bought this\n",
       "19     100+ bought this\n",
       "20  10,000+ bought this\n",
       "21         Almost Gone!\n",
       "22     100+ bought this\n",
       "23  20,000+ bought this\n",
       "24     100+ bought this\n",
       "25   1,000+ bought this\n",
       "26   5,000+ bought this\n",
       "27     100+ bought this\n",
       "28   5,000+ bought this\n",
       "29  10,000+ bought this\n",
       "30   5,000+ bought this\n",
       "32     100+ bought this\n",
       "33   1,000+ bought this\n",
       "34   1,000+ bought this\n",
       "35   1,000+ bought this\n",
       "36     100+ bought this\n",
       "37         Almost Gone!\n",
       "38   1,000+ bought this\n",
       "39  20,000+ bought this\n",
       "40  10,000+ bought this\n",
       "41         Almost Gone!\n",
       "42     100+ bought this\n",
       "43  10,000+ bought this\n",
       "44  10,000+ bought this\n",
       "46  20,000+ bought this\n",
       "48     100+ bought this\n",
       "49     100+ bought this\n",
       "50   1,000+ bought this\n",
       "51   1,000+ bought this\n",
       "52         Almost Gone!\n",
       "53  20,000+ bought this\n",
       "54   1,000+ bought this"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1,000+ bought this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Almost Gone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5,000+ bought this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 content\n",
       "11   10,000+ bought this\n",
       "12    1,000+ bought this\n",
       "13          Almost Gone!\n",
       "14    1,000+ bought this\n",
       "15   10,000+ bought this\n",
       "16          Almost Gone!\n",
       "17      100+ bought this\n",
       "18   20,000+ bought this\n",
       "19      100+ bought this\n",
       "20   10,000+ bought this\n",
       "21          Almost Gone!\n",
       "22   10,000+ bought this\n",
       "23  100,000+ bought this\n",
       "24   20,000+ bought this\n",
       "26   20,000+ bought this\n",
       "27    5,000+ bought this\n",
       "28          Almost Gone!\n",
       "29   10,000+ bought this\n",
       "30    1,000+ bought this\n",
       "31   20,000+ bought this\n",
       "32    1,000+ bought this\n",
       "33          Almost Gone!\n",
       "34  100,000+ bought this\n",
       "35   10,000+ bought this\n",
       "36    1,000+ bought this\n",
       "37    1,000+ bought this\n",
       "38          Almost Gone!\n",
       "39   10,000+ bought this\n",
       "40   10,000+ bought this\n",
       "41  100,000+ bought this\n",
       "42          Almost Gone!\n",
       "43    5,000+ bought this\n",
       "44    1,000+ bought this\n",
       "45   10,000+ bought this\n",
       "46   10,000+ bought this\n",
       "47   10,000+ bought this\n",
       "48    1,000+ bought this\n",
       "49          Almost Gone!\n",
       "50    5,000+ bought this"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First normal dataset information above (25, 1)\n",
      "\n",
      "Second normal dataset information above (29, 1)\n",
      "\n",
      "Third normal dataset information above (26, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the normal content strings\n",
    "\n",
    "nor1 = df1[~df1.isin(dp1).any(axis=1)]\n",
    "nor2 = df2[~df2.isin(dp2).any(axis=1)]\n",
    "nor3 = df3[~df3.isin(dp3).any(axis=1)]\n",
    "\n",
    "print('First normal dataset information above {}\\n'.format(nor1.shape)),\n",
    "print('Second normal dataset information above {}\\n'.format(nor2.shape)),\n",
    "print('Third normal dataset information above {}\\n'.format(nor3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the normal content and dark pattern content as csv files\n",
    "\n",
    "# dark patterns\n",
    "\n",
    "dp1.to_csv('DP/wish1.csv', index = False, header = True)\n",
    "dp2.to_csv('DP/wish2.csv', index = False, header = True)\n",
    "dp3.to_csv('DP/wish3.csv', index = False, header = True)\n",
    "\n",
    "# normal content\n",
    "\n",
    "nor1.to_csv('Normal/wish1.csv', index = False, header = True)\n",
    "nor2.to_csv('Normal/wish2.csv', index = False, header = True)\n",
    "nor3.to_csv('Normal/wish3.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Shein Dataset\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First raw dataset information above (510, 1)\n",
      "\n",
      "Second raw dataset information above (1158, 1)\n",
      "\n",
      "Third raw dataset information above (1056, 1)\n",
      "\n",
      "Fourth raw dataset information above (1091, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- import the raw dataset\n",
    "\n",
    "raw1 = pd.read_csv('Raw/shein-1.csv')\n",
    "raw2 = pd.read_csv('Raw/shein-2.csv')\n",
    "raw3 = pd.read_csv('Raw/shein-3.csv')\n",
    "raw4 = pd.read_csv('Raw/shein-4.csv')\n",
    "\n",
    "print('First raw dataset information above {}\\n'.format(raw1.shape)),\n",
    "print('Second raw dataset information above {}\\n'.format(raw2.shape)),\n",
    "print('Third raw dataset information above {}\\n'.format(raw3.shape)),\n",
    "print('Fourth raw dataset information above {}\\n'.format(raw4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (510, 1)\n",
      "\n",
      "Second filtered dataset information above (1158, 1)\n",
      "\n",
      "Third filtered dataset information above (1056, 1)\n",
      "\n",
      "Fourth filtered dataset information above (1091, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_str = [',', '.', ';', '{', '}', '#', '/', '(', ')', '?','$']\n",
    "\n",
    "df1 = raw1[~raw1['content'].str[0].isin(ignore_str)]\n",
    "df2 = raw2[~raw2['content'].str[0].isin(ignore_str)]\n",
    "df3 = raw3[~raw3['content'].str[0].isin(ignore_str)]\n",
    "df4 = raw4[~raw4['content'].str[0].isin(ignore_str)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(df4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (505, 1)\n",
      "\n",
      "Second filtered dataset information above (1152, 1)\n",
      "\n",
      "Third filtered dataset information above (1050, 1)\n",
      "\n",
      "Fourth filtered dataset information above (1085, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the disturibing content to be removed.\n",
    "str_list = [ '{', '®','℗','©','=','\\(']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "df1 = df1[~df1.content.str.lower().str.contains(pattern)]\n",
    "df2 = df2[~df2.content.str.lower().str.contains(pattern)]\n",
    "df3 = df3[~df3.content.str.lower().str.contains(pattern)]\n",
    "df4 = df4[~df4.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(df1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(df2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(df3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(df4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First filtered dataset information above (41, 1)\n",
      "\n",
      "Second filtered dataset information above (0, 1)\n",
      "\n",
      "Third filtered dataset information above (0, 1)\n",
      "\n",
      "Fourth filtered dataset information above (0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter out the dark pattern strings\n",
    "\n",
    "str_list = ['sold','ends in']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "dp1 = df1[df1.content.str.lower().str.contains(pattern)]\n",
    "dp2 = df2[df2.content.str.lower().str.contains(pattern)]\n",
    "dp3 = df3[df3.content.str.lower().str.contains(pattern)]\n",
    "dp4 = df4[df4.content.str.lower().str.contains(pattern)]\n",
    "\n",
    "print('First filtered dataset information above {}\\n'.format(dp1.shape)),\n",
    "print('Second filtered dataset information above {}\\n'.format(dp2.shape)),\n",
    "print('Third filtered dataset information above {}\\n'.format(dp3.shape)),\n",
    "print('Fourth filtered dataset information above {}\\n'.format(dp4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Ends in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>88 Sold                22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>88 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>5 Sold                3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>5 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>20 Sold                10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>20 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>10 Sold                5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>10 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>3 Sold                2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>68 Sold                34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>68 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>46 Sold                23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>46 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>21 Sold                11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>21 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>16 Sold                8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>16 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>11 Sold                6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>11 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>47 Sold                24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>47 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>11 Sold                6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>11 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>36 Sold                18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>36 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>21 Sold                11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>21 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>5 Sold                3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>5 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3 Sold                2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>3 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>88 Sold                44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>88 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>20 Sold                10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>20 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>3 Sold                2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>3 Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>5 Sold                3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>5 Sold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        content\n",
       "305                     Ends in\n",
       "307  88 Sold                22%\n",
       "308                     88 Sold\n",
       "310    5 Sold                3%\n",
       "311                      5 Sold\n",
       "313  20 Sold                10%\n",
       "314                     20 Sold\n",
       "316   10 Sold                5%\n",
       "317                     10 Sold\n",
       "319    3 Sold                2%\n",
       "320                      3 Sold\n",
       "322  68 Sold                34%\n",
       "323                     68 Sold\n",
       "325  46 Sold                23%\n",
       "326                     46 Sold\n",
       "328  21 Sold                11%\n",
       "329                     21 Sold\n",
       "331   16 Sold                8%\n",
       "332                     16 Sold\n",
       "334   11 Sold                6%\n",
       "335                     11 Sold\n",
       "337  47 Sold                24%\n",
       "338                     47 Sold\n",
       "340   11 Sold                6%\n",
       "341                     11 Sold\n",
       "343  36 Sold                18%\n",
       "344                     36 Sold\n",
       "346  21 Sold                11%\n",
       "347                     21 Sold\n",
       "349    5 Sold                3%\n",
       "350                      5 Sold\n",
       "352    3 Sold                2%\n",
       "353                      3 Sold\n",
       "355  88 Sold                44%\n",
       "356                     88 Sold\n",
       "358  20 Sold                10%\n",
       "359                     20 Sold\n",
       "361    3 Sold                2%\n",
       "362                      3 Sold\n",
       "364    5 Sold                3%\n",
       "365                      5 Sold"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First normal dataset information above (464, 1)\n",
      "\n",
      "Second normal dataset information above (1152, 1)\n",
      "\n",
      "Third normal dataset information above (1050, 1)\n",
      "\n",
      "Fourth normal dataset information above (1085, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the normal content strings\n",
    "\n",
    "nor1 = df1[~df1.isin(dp1).any(axis=1)]\n",
    "nor2 = df2[~df2.isin(dp2).any(axis=1)]\n",
    "nor3 = df3[~df3.isin(dp3).any(axis=1)]\n",
    "nor4 = df4[~df4.isin(dp4).any(axis=1)]\n",
    "\n",
    "print('First normal dataset information above {}\\n'.format(nor1.shape)),\n",
    "print('Second normal dataset information above {}\\n'.format(nor2.shape)),\n",
    "print('Third normal dataset information above {}\\n'.format(nor3.shape)),\n",
    "print('Fourth normal dataset information above {}\\n'.format(nor4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the normal content and dark pattern content as csv files\n",
    "\n",
    "# dark patterns\n",
    "\n",
    "dp1.to_csv('DP/shein1.csv', index = False, header = True)\n",
    "\n",
    "# normal content\n",
    "\n",
    "nor1.to_csv('Normal/shein1.csv', index = False, header = True)\n",
    "nor2.to_csv('Normal/shein2.csv', index = False, header = True)\n",
    "nor3.to_csv('Normal/shein3.csv', index = False, header = True)\n",
    "nor4.to_csv('Normal/shein4.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest of dataset without DP detected\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1th of the raw datasets information is: (925, 1)\n",
      "\n",
      "The 2th of the raw datasets information is: (859, 1)\n",
      "\n",
      "The 3th of the raw datasets information is: (943, 1)\n",
      "\n",
      "The 4th of the raw datasets information is: (928, 1)\n",
      "\n",
      "The 5th of the raw datasets information is: (662, 1)\n",
      "\n",
      "The 6th of the raw datasets information is: (1224, 1)\n",
      "\n",
      "The 7th of the raw datasets information is: (1029, 1)\n",
      "\n",
      "The 8th of the raw datasets information is: (809, 1)\n",
      "\n",
      "The 9th of the raw datasets information is: (771, 1)\n",
      "\n",
      "The 10th of the raw datasets information is: (806, 1)\n",
      "\n",
      "The 11th of the raw datasets information is: (869, 1)\n",
      "\n",
      "The 12th of the raw datasets information is: (897, 1)\n",
      "\n",
      "The 13th of the raw datasets information is: (628, 1)\n",
      "\n",
      "The 14th of the raw datasets information is: (938, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- import the raw dataset\n",
    "\n",
    "raw1 = pd.read_csv('Raw/alibaba-1.csv')\n",
    "raw2 = pd.read_csv('Raw/alibaba-2.csv')\n",
    "raw3 = pd.read_csv('Raw/alibaba-3.csv')\n",
    "raw4 = pd.read_csv('Raw/alibaba-4.csv')\n",
    "\n",
    "raw5 = pd.read_csv('Raw/boohoo-1.csv')\n",
    "raw6 = pd.read_csv('Raw/boohoo-2.csv')\n",
    "raw7 = pd.read_csv('Raw/boohoo-3.csv')\n",
    "raw8 = pd.read_csv('Raw/boohoo-4.csv')\n",
    "raw9 = pd.read_csv('Raw/boohoo-5.csv')\n",
    "\n",
    "raw10 = pd.read_csv('Raw/PC-1.csv')\n",
    "raw11 = pd.read_csv('Raw/PC-2.csv')\n",
    "raw12 = pd.read_csv('Raw/PC-3.csv')\n",
    "raw13 = pd.read_csv('Raw/PC-4.csv')\n",
    "raw14 = pd.read_csv('Raw/PC-5.csv')\n",
    "\n",
    "raw_list = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,raw11,raw12,raw13,raw14]\n",
    "\n",
    "for i,j in enumerate(raw_list):\n",
    "    print('The {}th of the raw datasets information is: {}\\n'.format(i+1,j.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1th of the filtered datasets information is: (925, 1)\n",
      "\n",
      "The 2th of the filtered datasets information is: (818, 1)\n",
      "\n",
      "The 3th of the filtered datasets information is: (875, 1)\n",
      "\n",
      "The 4th of the filtered datasets information is: (928, 1)\n",
      "\n",
      "The 5th of the filtered datasets information is: (661, 1)\n",
      "\n",
      "The 6th of the filtered datasets information is: (1223, 1)\n",
      "\n",
      "The 7th of the filtered datasets information is: (1029, 1)\n",
      "\n",
      "The 8th of the filtered datasets information is: (809, 1)\n",
      "\n",
      "The 9th of the filtered datasets information is: (771, 1)\n",
      "\n",
      "The 10th of the filtered datasets information is: (806, 1)\n",
      "\n",
      "The 11th of the filtered datasets information is: (869, 1)\n",
      "\n",
      "The 12th of the filtered datasets information is: (897, 1)\n",
      "\n",
      "The 13th of the filtered datasets information is: (628, 1)\n",
      "\n",
      "The 14th of the filtered datasets information is: (938, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_str = [',', '.', ';', '{', '}', '#', '/', '(', ')', '?','$']\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i in raw_list:\n",
    "    df_list.append(i[~i['content'].str[0].isin(ignore_str)])\n",
    "\n",
    "for i,j in enumerate(df_list):\n",
    "    print('The {}th of the filtered datasets information is: {}\\n'.format(i+1,j.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1th of the further filtered datasets information is: (889, 1)\n",
      "\n",
      "The 2th of the further filtered datasets information is: (807, 1)\n",
      "\n",
      "The 3th of the further filtered datasets information is: (863, 1)\n",
      "\n",
      "The 4th of the further filtered datasets information is: (909, 1)\n",
      "\n",
      "The 5th of the further filtered datasets information is: (655, 1)\n",
      "\n",
      "The 6th of the further filtered datasets information is: (1212, 1)\n",
      "\n",
      "The 7th of the further filtered datasets information is: (1019, 1)\n",
      "\n",
      "The 8th of the further filtered datasets information is: (799, 1)\n",
      "\n",
      "The 9th of the further filtered datasets information is: (761, 1)\n",
      "\n",
      "The 10th of the further filtered datasets information is: (798, 1)\n",
      "\n",
      "The 11th of the further filtered datasets information is: (827, 1)\n",
      "\n",
      "The 12th of the further filtered datasets information is: (870, 1)\n",
      "\n",
      "The 13th of the further filtered datasets information is: (625, 1)\n",
      "\n",
      "The 14th of the further filtered datasets information is: (902, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter out the disturibing content to be removed.\n",
    "str_list = [ '{', '®','℗','©','=','\\(']\n",
    "pattern = '|'.join(str_list)\n",
    "\n",
    "df_further_filter_list = []\n",
    "\n",
    "for i in df_list:\n",
    "    df_further_filter_list.append(i[~i.content.str.lower().str.contains(pattern)])\n",
    "\n",
    "for i,j in enumerate(df_further_filter_list):\n",
    "    print('The {}th of the further filtered datasets information is: {}\\n'.format(i+1,j.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the normal content and dark pattern content as csv files\n",
    "\n",
    "# dark patterns\n",
    "\n",
    "for i,j in enumerate(df_further_filter_list):\n",
    "    filename = 'Normal/'+'norDF'+str(i)+'.csv'\n",
    "    j.to_csv(filename, index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Rows Which Are Not common Between Two dataframes\n",
    "\n",
    "pd.concat([sub1,sub2]).drop_duplicates(keep=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
