{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to encode text, aka tokenize documents, to learn the vocabulary and inverse document frequency weightings.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# systematically compute word counts using CountVectorizer and them compute the Inverse Document Frequency (IDF) values and only then compute the Tf-idf scores.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# MultinomialNB (multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts, however, in practice, fractional counts such as tf-idf may also work.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# joblib is a set of tools to provide lightweight pipelining in Python. It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>Pattern Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only 2 left</td>\n",
       "      <td>Low-stock Message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only 3 left</td>\n",
       "      <td>Low-stock Message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9 people are viewing this.</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5338 people viewed this in the last hour</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crystal Li in Flushing, United States purchased a</td>\n",
       "      <td>Activity Notification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Pattern String           Pattern Type\n",
       "0                                        Only 2 left      Low-stock Message\n",
       "1                                        Only 3 left      Low-stock Message\n",
       "2                         9 people are viewing this.  Activity Notification\n",
       "3           5338 people viewed this in the last hour  Activity Notification\n",
       "4  Crystal Li in Flushing, United States purchased a  Activity Notification"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- import dataset of the enriched pattern type dataset\n",
    "df = pd.read_csv('enriched_type_df.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1057 entries, 0 to 1056\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Pattern String  1057 non-null   object\n",
      " 1   Pattern Type    1057 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 16.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# ---- information of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1057 entries, 0 to 1056\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Pattern String  1057 non-null   object\n",
      " 1   Pattern Type    1057 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 24.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# ---- select from the dataset when 'Pattern String' is not NaN values.\n",
    "df = df[pd.notnull(df[\"Pattern String\"])]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity Notification    412\n",
      "Low-stock Message        398\n",
      "Countdown Timer          140\n",
      "Limited-time Message      83\n",
      "High-demand Message       24\n",
      "Name: Pattern Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of Pattern Type\n",
    "\n",
    "print(df['Pattern Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Low-stock Message': 0, 'Activity Notification': 1, 'Countdown Timer': 2, 'High-demand Message': 3, 'Limited-time Message': 4}\n"
     ]
    }
   ],
   "source": [
    "# ---- encode the pattern category type into integers (7 types in total, encoded into integers from 0-6).\n",
    "\n",
    "df[\"type_id\"] = df['Pattern Type'].factorize()[0]\n",
    "\n",
    "# ---- Get the mapping of the encoding integers and the pattern categories.\n",
    "# ---- {'Social Proof': 0, 'Misdirection': 1, 'Urgency': 2, 'Forced Action': 3, 'Obstruction': 4, 'Sneaking': 5, 'Scarcity': 6}\n",
    "\n",
    "type_id_df = df[['Pattern Type', 'type_id']\n",
    "                    ].drop_duplicates().sort_values('type_id')\n",
    "type_to_id = dict(type_id_df.values)\n",
    "id_to_type = dict(\n",
    "    type_id_df[['type_id', 'Pattern Type']].values)\n",
    "\n",
    "\n",
    "# ---- result of the mapping\n",
    "\n",
    "print(type_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1057, 297)\n"
     ]
    }
   ],
   "source": [
    "# ---- convert a collection of raw documents to a matrix of TF-IDF features; Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "# 'sublinear_tf=True' is used to normalise bias of term frequency (\"where a term that is more frequent shouldn't be X times as important\"). It is set to True to use a logarithmic form for frequency.\n",
    "# 'norm='l2'' is the default setting of 'norm', used to reduce document length bias, to ensure all our feature vectors have a enclidian norm of 1.\n",
    "# 'min_df=5', means when building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold (which is 5 here), which is the minimum numbers of documents a word must be present in to be kept.\n",
    "# 'ngram_range=(1,2)' means unigrams and bigrams will be extracted, means we want to consider both unigrams and bigrams.\n",
    "# 'stop_words='english'', if a string, it is passed to _check_stop_list and the appropriate stop list is returned. To remove all common pronouns (\"a\", \"the\" ...), reducing the number of noisy features.\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2))\n",
    "\n",
    "features = tfidf.fit_transform(df['Pattern String']).toarray()\n",
    "labels = df.type_id\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern Type: 'Activity Notification':\n",
      "  . Most correlated unigrams:\n",
      "     . only\n",
      "     . left\n",
      "     . sold\n",
      "  . Most correlated bigrams:\n",
      "     . left in\n",
      "     . in stock\n",
      "     . only left\n",
      "Pattern Type: 'Countdown Timer':\n",
      "  . Most correlated unigrams:\n",
      "     . 09\n",
      "     . 00\n",
      "     . ends\n",
      "  . Most correlated bigrams:\n",
      "     . offer ends\n",
      "     . reserved for\n",
      "     . ends in\n",
      "Pattern Type: 'High-demand Message':\n",
      "  . Most correlated unigrams:\n",
      "     . fast\n",
      "     . high\n",
      "     . demand\n",
      "  . Most correlated bigrams:\n",
      "     . selling fast\n",
      "     . in high\n",
      "     . high demand\n",
      "Pattern Type: 'Limited-time Message':\n",
      "  . Most correlated unigrams:\n",
      "     . free\n",
      "     . limited\n",
      "     . time\n",
      "  . Most correlated bigrams:\n",
      "     . time offer\n",
      "     . time only\n",
      "     . limited time\n",
      "Pattern Type: 'Low-stock Message':\n",
      "  . Most correlated unigrams:\n",
      "     . stock\n",
      "     . only\n",
      "     . left\n",
      "  . Most correlated bigrams:\n",
      "     . left in\n",
      "     . in stock\n",
      "     . only left\n"
     ]
    }
   ],
   "source": [
    "# The result means each of the 1512 pattern strings is represented by 303 features, representing the tf-idf score for different unigrams and bigrams.\n",
    "\n",
    "N = 3   # every n-gram will give 3 examples\n",
    "\n",
    "for Type, type_id in sorted(type_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == type_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"Pattern Type: '{}':\".format(Type))\n",
    "  print(\"  . Most correlated unigrams:\\n     . {}\".format('\\n     . '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n     . {}\".format('\\n     . '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Preparation\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Split the dataset into training and testing ------\n",
    "String_train, String_test, Type_train, Type_test = train_test_split(\n",
    "    df['Pattern String'], df['Pattern Type'], train_size=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity Notification    261\n",
      "Low-stock Message        228\n",
      "Countdown Timer           77\n",
      "Limited-time Message      55\n",
      "High-demand Message       13\n",
      "Name: Pattern Type, dtype: int64\n",
      "Low-stock Message        170\n",
      "Activity Notification    151\n",
      "Countdown Timer           63\n",
      "Limited-time Message      28\n",
      "High-demand Message       11\n",
      "Name: Pattern Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of training data\n",
    "\n",
    "print(Type_train.value_counts())\n",
    "\n",
    "# Distribution of testing data\n",
    "\n",
    "print(Type_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Activity Notification', 'Countdown Timer', 'High-demand Message', 'Limited-time Message', 'Low-stock Message']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Type_train)\n",
    "y_train = encoder.transform(Type_train)\n",
    "y_test = encoder.transform(Type_test)\n",
    "\n",
    "# check the mapping of encoding results (from 0 to 6 representing 'Forced Action', 'Misdirection'......)\n",
    "\n",
    "print(list(encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Activity Notification' 261]\n",
      " ['Countdown Timer' 77]\n",
      " ['High-demand Message' 13]\n",
      " ['Limited-time Message' 55]\n",
      " ['Low-stock Message' 228]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the training pattern category with pattern category names.\n",
    "\n",
    "(unique, counts) = np.unique(Type_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 261]\n",
      " [  1  77]\n",
      " [  2  13]\n",
      " [  3  55]\n",
      " [  4 228]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded training pattern category with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 151]\n",
      " [  1  63]\n",
      " [  2  11]\n",
      " [  3  28]\n",
      " [  4 170]]\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency distribution of the encoded testing pattern category with encoded integers.\n",
    "\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Encoding\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word count vector of the pattern string to encode the pattern string.\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(String_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type_CountVectorizer.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# save the CountVectorizer to disk\n",
    "joblib.dump(cv, 'type_CountVectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() accuracy: 0.9645390070921985\n",
      "Confusion Matris: [[150   0   0   0   1]\n",
      " [  2  59   1   0   1]\n",
      " [  2   0   8   0   1]\n",
      " [  1   2   0  24   1]\n",
      " [  2   0   0   1 167]]\n",
      "LinearSVC() accuracy: 0.9716312056737588\n",
      "Confusion Matris: [[149   0   0   1   1]\n",
      " [  1  60   1   1   0]\n",
      " [  0   0  10   0   1]\n",
      " [  1   1   0  25   1]\n",
      " [  1   0   1   1 167]]\n",
      "RandomForestClassifier() accuracy: 0.9574468085106383\n",
      "Confusion Matris: [[149   0   0   1   1]\n",
      " [  2  56   1   2   2]\n",
      " [  2   1   8   0   0]\n",
      " [  1   2   0  25   0]\n",
      " [  2   0   0   1 167]]\n",
      "DecisionTreeClassifier() accuracy: 0.9314420803782506\n",
      "Confusion Matris: [[145   6   0   0   0]\n",
      " [  9  50   1   0   3]\n",
      " [  1   2   7   0   1]\n",
      " [  2   1   0  25   0]\n",
      " [  1   1   0   1 167]]\n",
      "MultinomialNB() accuracy: 0.9574468085106383\n",
      "Confusion Matris: [[150   0   0   1   0]\n",
      " [  1  60   0   1   1]\n",
      " [  1   3   2   0   5]\n",
      " [  0   0   0  26   2]\n",
      " [  1   0   0   2 167]]\n"
     ]
    }
   ],
   "source": [
    "# Five models are tested:\n",
    "# -- Logistic Regression\n",
    "# -- Linear Support Vector Machine\n",
    "# -- Random Forest\n",
    "# -- Decision Tree\n",
    "# -- Multinomial Naive Bayes\n",
    "\n",
    "classifiers = [LogisticRegression(),LinearSVC(), RandomForestClassifier(), DecisionTreeClassifier(), MultinomialNB()]\n",
    "\n",
    "# Calculate the accuracies of different classifiers using default settings.\n",
    "\n",
    "acc = []\n",
    "cm = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(cv.transform(String_test))\n",
    "    acc.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    cm.append(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# List the accuracies of different classifiers.\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    print(f\"{classifiers[i]} accuracy: {acc[i]}\")\n",
    "    print(f\"Confusion Matris: {cm[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Accuracy:0.9645390070921985\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 157]\n",
      " [  1  61]\n",
      " [  2   9]\n",
      " [  3  25]\n",
      " [  4 171]]\n",
      "\n",
      "Confusion Matrix of the result:[[150   0   0   0   1]\n",
      " [  2  59   1   0   1]\n",
      " [  2   0   8   0   1]\n",
      " [  1   2   0  24   1]\n",
      " [  2   0   0   1 167]]\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.1s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955793</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955793</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_penalty param_solver\n",
       "0                1         0.963680            l2          sag\n",
       "1                2         0.955793            l2        lbfgs\n",
       "2                2         0.955793            l2    newton-cg\n",
       "3                4              NaN            l1        lbfgs\n",
       "4                5              NaN            l1    newton-cg\n",
       "5                6              NaN            l1          sag"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_lr.get_params()))\n",
    "\n",
    "y_pred = clf_lr.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}\\n'.format(frequencies))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of the result:{}\\n'.format(cm))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'penalty':['l1','l2'], \n",
    "              'solver':['lbfgs','newton-cg','sag']}\n",
    "\n",
    "gs = GridSearchCV(clf_lr, param_grid, cv=5,\n",
    "                  verbose=1, n_jobs=-1)\n",
    "\n",
    "best_lr = gs.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_lr.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_solver']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'penalty': 'l2', 'solver': 'sag'}\n",
      "\n",
      "Accuracy:0.9645390070921985\n",
      "\n",
      "The distribution of predicted result of best model:[[  0 154]\n",
      " [  1  60]\n",
      " [  2  10]\n",
      " [  3  28]\n",
      " [  4 171]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lr_type_classifier.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters of the best model\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(best_lr.best_params_))\n",
    "\n",
    "y_pred_best = best_lr.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of best model:{}'.format(frequencies))\n",
    "\n",
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_lr, 'lr_type_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Accuracy:0.9739952718676123\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 151]\n",
      " [  1  66]\n",
      " [  2  10]\n",
      " [  3  26]\n",
      " [  4 170]]\n",
      "\n",
      "Confusion Matrix of the result:[[149   1   0   0   1]\n",
      " [  0  61   1   0   1]\n",
      " [  2   0   9   0   0]\n",
      " [  0   3   0  25   0]\n",
      " [  0   1   0   1 168]]\n",
      "\n",
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3240 out of 3240 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.968416</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.966829</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.965254</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.965254</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.965254</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>644</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>645</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>0.843845</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>647</td>\n",
       "      <td>0.839145</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>648</td>\n",
       "      <td>0.832796</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank_test_score  mean_test_score param_bootstrap param_criterion  \\\n",
       "0                  1         0.968416           False         entropy   \n",
       "1                  2         0.966829           False         entropy   \n",
       "2                  3         0.965254           False         entropy   \n",
       "3                  3         0.965254           False            gini   \n",
       "4                  3         0.965254           False         entropy   \n",
       "..               ...              ...             ...             ...   \n",
       "643              644         0.845382            True         entropy   \n",
       "644              645         0.845369            True            gini   \n",
       "645              646         0.843845            True            gini   \n",
       "646              647         0.839145            True            gini   \n",
       "647              648         0.832796            True         entropy   \n",
       "\n",
       "    param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0              None                      1                       5   \n",
       "1              None                      1                       5   \n",
       "2              None                      1                       2   \n",
       "3              None                      1                       5   \n",
       "4              None                      1                       5   \n",
       "..              ...                    ...                     ...   \n",
       "643              20                      4                       5   \n",
       "644              10                      4                      10   \n",
       "645              40                      4                       5   \n",
       "646              30                      4                      10   \n",
       "647            None                      4                       5   \n",
       "\n",
       "    param_n_estimators  \n",
       "0                  100  \n",
       "1                  200  \n",
       "2                  100  \n",
       "3                  200  \n",
       "4                  300  \n",
       "..                 ...  \n",
       "643                100  \n",
       "644                200  \n",
       "645                100  \n",
       "646                100  \n",
       "647                100  \n",
       "\n",
       "[648 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_rf.get_params()))\n",
    "\n",
    "y_pred = clf_rf.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}\\n'.format(frequencies))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of the result:{}\\n'.format(cm))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'bootstrap':[True,False], \n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[10,20,30,40,50, None],\n",
    "              'min_samples_leaf':[1,2,4],\n",
    "              'min_samples_split':[2,5,10],\n",
    "              'n_estimators':[100,200,300]}\n",
    "\n",
    "gs = GridSearchCV(clf_rf, param_grid, cv=5,\n",
    "                  verbose=1, n_jobs=-1)\n",
    "\n",
    "best_rf = gs.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_rf.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_bootstrap', 'param_criterion',\n",
    "            'param_max_depth','param_min_samples_leaf','param_min_samples_split','param_n_estimators']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "Accuracy:0.966903073286052\n",
      "\n",
      "The distribution of predicted result of best model:[[  0 155]\n",
      " [  1  62]\n",
      " [  2   9]\n",
      " [  3  27]\n",
      " [  4 170]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_type_classifier.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters of the best model\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(best_rf.best_params_))\n",
    "\n",
    "y_pred_best = best_rf.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of best model:{}'.format(frequencies))\n",
    "\n",
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_rf, 'rf_type_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Accuracy:0.9716312056737588\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 152]\n",
      " [  1  61]\n",
      " [  2  12]\n",
      " [  3  28]\n",
      " [  4 170]]\n",
      "\n",
      "Confusion Matrix of the result:[[149   0   0   1   1]\n",
      " [  1  60   1   1   0]\n",
      " [  0   0  10   0   1]\n",
      " [  1   1   0  25   1]\n",
      " [  1   0   1   1 167]]\n",
      "\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "   rank_test_score  mean_test_score param_penalty param_C\n",
      "0                1         0.962105            l2       1\n",
      "1                1         0.962105            l2       5\n",
      "2                1         0.962105            l2      10\n",
      "3                4         0.954218            l2     0.1\n",
      "4                5              NaN            l1     0.1\n",
      "5                6              NaN            l1       1\n",
      "6                7              NaN            l1       5\n",
      "7                8              NaN            l1      10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "clf_svm = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_svm.get_params()))\n",
    "\n",
    "y_pred = clf_svm.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}\\n'.format(frequencies))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix of the result:{}\\n'.format(cm))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.1, 1, 5, 10]}\n",
    "\n",
    "gs = GridSearchCV(clf_svm, param_grid, cv=5,\n",
    "                  verbose=1, n_jobs=-1)\n",
    "\n",
    "best_svm = gs.fit(X_train, y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_svm.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "print(scores_df [['rank_test_score', 'mean_test_score', 'param_penalty', 'param_C']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'C': 1, 'penalty': 'l2'}\n",
      "\n",
      "Accuracy:0.9716312056737588\n",
      "\n",
      "The distribution of predicted result of best model:[[  0 152]\n",
      " [  1  61]\n",
      " [  2  12]\n",
      " [  3  28]\n",
      " [  4 170]]\n"
     ]
    }
   ],
   "source": [
    "print('Parameters of the classifier:\\n{}\\n'.format(best_svm.best_params_))\n",
    "\n",
    "y_pred_best = best_svm.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of best model:{}'.format(frequencies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_type_classifier.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to local disk\n",
    "\n",
    "joblib.dump(best_svm, 'svm_type_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the classifier:\n",
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n",
      "\n",
      "Accuracy:0.9574468085106383\n",
      "\n",
      "The distribution of predicted result of default model:[[  0 153]\n",
      " [  1  63]\n",
      " [  2   2]\n",
      " [  3  30]\n",
      " [  4 175]]\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_fit_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.941620</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.941595</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.930546</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score param_alpha param_fit_prior\n",
       "0                1         0.943195           0            True\n",
       "1                2         0.941620           0           False\n",
       "2                3         0.941595           1            True\n",
       "3                4         0.930546           1           False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mnb = MultinomialNB().fit(X_train, y_train)\n",
    "print('Parameters of the classifier:\\n{}\\n'.format(clf_mnb.get_params()))\n",
    "\n",
    "y_pred = clf_mnb.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of default model:{}'.format(frequencies))\n",
    "\n",
    "# Parameter tunning\n",
    "param_grid = {'alpha':[0,1],\n",
    "              'fit_prior':[True, False]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(clf_mnb,param_grid,cv=5,\n",
    "                      verbose = 1, n_jobs = -1)\n",
    "\n",
    "best_mnb = gs.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(best_mnb.cv_results_)\n",
    "scores_df = scores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df [['rank_test_score', 'mean_test_score', 'param_alpha', 'param_fit_prior']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9432624113475178\n",
      "\n",
      "The distribution of predicted result of the best model:[[  0 156]\n",
      " [  1  64]\n",
      " [  2   9]\n",
      " [  3  26]\n",
      " [  4 168]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mnb_type_classifier.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_best = best_mnb.predict(cv.transform(String_test))\n",
    "\n",
    "print(\"Accuracy:{}\\n\".format(metrics.accuracy_score(y_pred_best, y_test)))\n",
    "\n",
    "(unique, counts) = np.unique(y_pred_best, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('The distribution of predicted result of the best model:{}'.format(frequencies))\n",
    "\n",
    " # save the model to local disk\n",
    "\n",
    "joblib.dump(best_mnb, 'mnb_type_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
